<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Table of Contents</title>
    <meta content="Greedy algorithms are the â€œmake progress nowâ€ strategy: build a solution one step at a time, and at each step take the option that looks best right now according to a simple rule (highest value, earliest finish, smallest weight, smallest distance label, etc.)." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <link href="https://adamdjellouli.com/articles/algorithms_and_data_structures/greedy_algorithms" rel="canonical" />
    <script id="structured-data" type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "Article",
            "headline": "Table of Contents",
            "author": {
                "@type": "Person",
                "name": "Adam Djellouli"
            },
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://adamdjellouli.com/articles/algorithms_and_data_structures/greedy_algorithms"
            },
            "url": "https://adamdjellouli.com/articles/algorithms_and_data_structures/greedy_algorithms",
            "description": "Greedy algorithms are the \u201cmake progress now\u201d strategy: build a solution one step at a time, and at each step take the option that looks best right now according to a simple rule (highest value, earliest finish, smallest weight, smallest distance label, etc.).",
            "dateModified": "2025-12-31"
        }
    </script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="../../index.html">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a href="../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../core/courses.html" title="Browse Courses by Adam Djellouli"> Courses </a>
            </li>
            <li role="menuitem">
                <a href="../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <aside id="article-sidebar">
            <div id="table-of-contents">
                <h2>Table of Contents</h2>
                <ol><a href="#greedy-algorithms">Greedy algorithms</a>
                    <ol>
                        <li><a href="#the-greedy-proof-toolkit">The Greedy Proof Toolkit</a>
                            <ol>
                                <li><a href="#the-universal-greedy-checklist">The Universal Greedy Checklist</a></li>
                                <li><a href="#exchange-argument-template">Exchange Argument Template</a></li>
                                <li><a href="#loop-invariant-template">Loop Invariant Template</a></li>
                                <li><a href="#cut-and-cycle-rules-graph-specializations-">Cut and Cycle Rules (Graph Specializations)</a></li>
                            </ol>
                        </li>
                        <li><a href="#examples-grouped-by-pattern">Examples Grouped by Pattern</a>
                            <ol>
                                <li><a href="#reachability-on-a-line">Reachability on a line</a></li>
                                <li><a href="#minimum-spanning-trees">Minimum spanning trees</a></li>
                                <li><a href="#kruskal-s-method">Kruskalâ€™s method</a></li>
                                <li><a href="#prim-s-method">Primâ€™s method</a></li>
                                <li><a href="#shortest-paths-with-non-negative-weights-dijkstra-">Shortest paths with non-negative weights (Dijkstra)</a></li>
                                <li><a href="#scheduling-themes">Scheduling themes</a></li>
                                <li><a href="#interval-scheduling-maximum-number-of-non-overlapping-intervals-">Interval scheduling (maximum number of non-overlapping intervals)</a></li>
                                <li><a href="#minimize-the-maximum-lateness-unit-time-jobs-">Minimize the maximum lateness (unit-time jobs)</a></li>
                                <li><a href="#huffman-coding">Huffman coding</a></li>
                                <li><a href="#maximum-contiguous-sum-kadane-">Maximum contiguous sum (Kadane)</a></li>
                            </ol>
                        </li>
                        <li><a href="#when-greedy-is-guaranteed-matroids">When Greedy Is Guaranteed: Matroids</a></li>
                        <li><a href="#common-failure-modes">Common Failure Modes</a>
                            <ol>
                                <li><a href="#coin-change-with-non-canonical-coins">Coin change with non-canonical coins</a></li>
                            </ol>
                        </li>
                        <li><a href="#interval-scheduling-by-earliest-start-time-wrong-rule-">Interval scheduling by earliest start time (wrong rule)</a>
                            <ol>
                                <li><a href="#fractional-vs-0-1-knapsack">Fractional vs 0/1 knapsack</a></li>
                            </ol>
                        </li>
                    </ol>
                </ol>
            </div>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/backtracking.html">Backtracking</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/basic_concepts.html">Basic Concepts</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/brain_teasers.html">Brain Teasers</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/data_structures.html">Data Structures</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/dynamic_programming.html">Dynamic Programming</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/graphs.html">Graphs</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/greedy_algorithms.html">Greedy Algorithms</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/math_set_relationship.html">Math Set Relationship</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/matrices.html">Matrices</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/searching.html">Searching</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/sorting.html">Sorting</a></li>
                </ol>
            </div>
        </aside><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: December 31, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: ğŸ‡ºğŸ‡¸</i></p>
            <h2 id="greedy-algorithms">Greedy algorithms</h2>
            <p>Greedy algorithms are the â€œmake progress nowâ€ strategy: build a solution one step at a time, and at each step take the option that looks best <em>right now</em> according to a simple rule (highest value, earliest finish, smallest weight, smallest distance label, etc.). You keep the choice only if it doesnâ€™t break the problemâ€™s rules.</p>
            <p>The story you should keep in your head is <strong>greedy is fast because it refuses to look ahead</strong>, but that means it earns its correctness only when you can prove that local choices are <em>safe</em>. The fun part is that the <em>proof patterns</em> repeat across problems, so once you learn the toolkit, new greedy problems stop feeling like magic tricks and start feeling like â€œapply the template.â€</p>
            <p><strong>The general pattern:</strong></p>
            <ol>
                <li>Sort by your rule (the â€œkeyâ€).</li>
                <li>Scan items in that order.</li>
                <li>If adding this item keeps the partial answer valid, keep it.</li>
                <li>Otherwise skip it.</li>
            </ol>
            <p>Picking the best â€œnowâ€ doesnâ€™t obviously give the best â€œoverall.â€ <strong>Greedy isnâ€™t magic; you must prove the choice is safe.</strong> The real work is showing that these local choices still lead to a globally best answer.</p>
            <p>A good do/donâ€™t to internalize right away:</p>
            <ul>
                <li><strong>Do</strong> write down the constraint you must never violate (your <em>feasibility invariant</em>).</li>
                <li><strong>Donâ€™t</strong> trust a greedy rule until you can justify it with a reusable proof pattern.</li>
            </ul>
            <h3 id="the-greedy-proof-toolkit">The Greedy Proof Toolkit</h3>
            <p>This section is your reusable toolbox. The goal is to stop re-inventing proofs from scratch: the same 2â€“3 ideas show up again and again, just wearing different costumes.</p>
            <h4 id="the-universal-greedy-checklist">The Universal Greedy Checklist</h4>
            <p>For every greedy algorithm, answer these five questions:</p>
            <ol>
                <li><strong>Greedy choice</strong>: What local choice do we make at each step?</li>
                <li><strong>Feasibility</strong>: What constraint must always remain true? (the invariant)</li>
                <li><strong>Why safe</strong>: Why does this choice never hurt optimality?</li>
                <li><strong>Implementation</strong>: What data structure makes the choice fast?</li>
                <li><strong>Complexity</strong>: What dominates runtime?</li>
            </ol>
            <p>Why you should care: if you canâ€™t fill in #3, you donâ€™t have an algorithm yet, you have a hopeful heuristic. The checklist is your â€œam I actually done?â€ filter.</p>
            <h4 id="exchange-argument-template">Exchange Argument Template</h4>
            <p>The exchange argument is the workhorse of greedy correctness proofs. Itâ€™s the â€œI can transform any optimal solution into greedy without paying moreâ€ trick.</p>
            <p>Generic template:</p>
            <ol>
                <li>Take any optimal solution <strong>OPT</strong> that disagrees with greedy <strong>G</strong> at the first position.</li>
                <li>Show you can swap in the greedy choice at that position without making the solution worse or breaking feasibility.</li>
                <li>The modified solution is still optimal and now agrees with greedy for one more position.</li>
                <li>Repeat until <strong>OPT</strong> becomes <strong>G</strong> â†’ greedy is optimal.</li>
            </ol>
            <p><em>Picture it like this:</em></p>
            <div>
                <pre><code class="language-shell">position â†’   0    1    2    3    4
greedy:     [âœ“]  [âœ—]  [âœ“]  [âœ“]  [âœ—]
some optimal:
             âœ“    âœ“    âœ—    ?    ?
First mismatch at position 2 â†’ swap in greedy's pick without harm.
Repeat until both rows match â†’ greedy is optimal.</code></pre>
            </div>
            <p>Do/donâ€™t: <strong>do</strong> look for the <em>first</em> disagreement (it keeps the swap localized), and <strong>donâ€™t</strong> try to â€œcompare whole solutions at onceâ€, you usually only need one clean swap.</p>
            <h4 id="loop-invariant-template">Loop Invariant Template</h4>
            <p>Sometimes itâ€™s easier to prove that your partial solution is â€œthe best possible so far,â€ iteration by iteration.</p>
            <p>Template:</p>
            <ol>
                <li><strong>State the invariant</strong>: a sentence true after every iteration.</li>
                <li><strong>Initialization</strong>: show it holds before the loop starts.</li>
                <li><strong>Maintenance</strong>: show one iteration preserves it.</li>
                <li><strong>Termination</strong>: show the invariant implies optimality when the loop ends.</li>
            </ol>
            <p>This is especially nice when greedy isnâ€™t â€œchoose and lock forever,â€ but â€œmaintain a best frontier/labelâ€ (reachability scans, shortest paths, etc.).</p>
            <h4 id="cut-and-cycle-rules-graph-specializations-">Cut and Cycle Rules (Graph Specializations)</h4>
            <p>For graph problems, exchange arguments often become two famous â€œrulesâ€:</p>
            <ul>
                <li><strong>Cut rule (safe to add)</strong>: For any partition $(S, V\setminus S)$, the cheapest edge crossing that cut can safely be included in an MST.</li>
                <li><strong>Cycle rule (safe to skip)</strong>: In any cycle, the most expensive edge is never in an MST.</li>
            </ul>
            <p>These are exchange arguments with graph language. The cut rule says â€œswapping in the cheapest crossing edge canâ€™t hurt,â€ and the cycle rule says â€œdropping the heaviest edge in a cycle canâ€™t hurt.â€</p>
            <h3 id="examples-grouped-by-pattern">Examples Grouped by Pattern</h3>
            <p>Each example follows the same structure: <strong>Problem â†’ Greedy rule â†’ Algorithm â†’ Proof sketch â†’ Complexity â†’ Edge cases</strong>.</p>
            <p>That structure is not cosmetic. Itâ€™s the point: if you can tell the story cleanly, you understand the algorithm, and you can re-derive it under pressure.</p>
            <h4 id="reachability-on-a-line">Reachability on a line</h4>
            <p><strong>Pattern</strong>: Frontier/Reachability Greedy</p>
            <p>This pattern is the â€œdonâ€™t overthink itâ€ cousin of graph reachability. Instead of tracking <em>every</em> reachable square, you track a <em>frontier</em>: the furthest place your current knowledge guarantees you can get to. The <em>do</em> is: compress lots of reachability facts into one summary number. The <em>donâ€™t</em> is: simulate every jump or mark every square repeatedly when you only need to know how far the wave has pushed.</p>
            <div>
                <pre><code class="language-shell">Mental model: a growing flashlight beam

0 1 2 3 4 5 6 7 ...
^ start
[=======]  &lt;- everything up to F is "lit" (reachable)</code></pre>
            </div>
            <p><strong>Problem</strong></p>
            <ul>
                <li>You stand at square $0$ on squares $0,1,\ldots,n-1$.</li>
                <li>Each square $i$ has jump power $a[i]$. From $i$ you may land on any of $i+1,i+2,\dots,i+a[i]$.</li>
                <li>Goal: decide if you can reach $n-1$; if not, report the furthest reachable square.</li>
            </ul>
            <p>Why this matters: itâ€™s the simplest form of â€œcan I keep progressing?â€ problems (game levels, packet routing along hops, scheduling with ranges). The <em>do</em> is: treat each <code>a[i]</code> as â€œpotential energyâ€ you can spend once you actually reach <code>i</code>. The <em>donâ€™t</em> is: assume a large jump power somewhere helps unless you can <em>get there</em>.</p>
            <div>
                <pre><code class="language-shell">Key gotcha:

Big power at 10 is useless if you get stuck at 6.

0 ... 6 7 8 9 10
      X gap      (a[10] = 100 doesn't matter)</code></pre>
            </div>
            <p><strong>Example</strong></p>
            <p>Input: $a=[3,1,0,0,4,1]$, so $n=6$.</p>
            <p>This example is perfect because it contains both â€œearly progressâ€ and a â€œdead zone.â€ It forces the algorithm to prove it can detect getting stuck without backtracking. The <em>do</em> is: watch for the first index that lies beyond your frontier. Thatâ€™s the exact moment the game ends.</p>
            <div>
                <pre><code class="language-shell">indices:  0   1   2   3   4   5
a[i]   :  3   1   0   0   4   1
reach  :  ^ start at 0</code></pre>
            </div>
            <p>From any $i$, the allowed landings are a range:</p>
            <div>
                <pre><code class="language-shell">i=0 (a[0]=3): 1..3
i=1 (a[1]=1): 2
i=2 (a[2]=0): , 
i=3 (a[3]=0): , 
i=4 (a[4]=4): 5..8 (board ends at 5)</code></pre>
            </div>
            <p>Notice the drama: square 4 has huge power, but squares 2 and 3 are â€œdeadâ€ (power 0). If you canâ€™t reach 4, that big number is just decoration. Thatâ€™s exactly why the greedy â€œfrontierâ€ viewpoint is the right abstraction.</p>
            <div>
                <pre><code class="language-shell">Visualizing the trap:

0 can reach -&gt; 1,2,3
1 can reach -&gt; 2
2 can reach -&gt; nowhere
3 can reach -&gt; nowhere

So if frontier never reaches 4, you're done.</code></pre>
            </div>
            <p><strong>Baseline idea</strong></p>
            <p>â€œPaint everything reachable, one wave at a time.â€</p>
            <ol>
                <li>Start with ${0}$ reachable.</li>
                <li>For each already-reachable $i$, add all $i+1 \ldots i+a[i]$.</li>
                <li>Stop when nothing new appears.</li>
            </ol>
            <p>Correct, but it can reprocess many squares.</p>
            <p>This is a classic â€œwhy greedy existsâ€ moment: the baseline is correct but wasteful because it keeps rediscovering the same reachability facts. Greedy will compress â€œeverything Iâ€™ve learned so farâ€ into one number.</p>
            <p>The baseline is basically a slow-motion flood fill. Itâ€™s conceptually comforting because it mirrors how youâ€™d explain reachability to a human: â€œfrom here I can go there, and from there I can goâ€¦â€ But itâ€™s also the classic performance mistake: you keep scanning regions you already know are reachable. The <em>do</em> is: steal the baselineâ€™s correctness idea, then compress it. The <em>donâ€™t</em> is: keep â€œpaintingâ€ when the only question is â€œhow far can the paint possibly spread?â€</p>
            <div>
                <pre><code class="language-shell">Baseline flood (inefficient):

Round 1: reach {0}
Round 2: add {1,2,3}
Round 3: from 1 add {2} (already known)
Round 4: from 2 add {} ...
... lots of re-checking for no new info</code></pre>
            </div>
            <p><strong>Greedy rule</strong></p>
            <p>Carry one number while scanning leftâ†’right: the furthest frontier $F$ seen so far.</p>
            <p>Why one number is enough: on a line, if you know you can reach everything up to <code>F</code>, then youâ€™ve implicitly learned <em>all</em> the starting points that matter for future jumps. Every index â‰¤ F is a possible launchpad. So instead of tracking them individually, you treat them as a single â€œreachable prefix.â€ The <em>do</em> is: think â€œreachable prefix length.â€ The <em>donâ€™t</em> is: store per-square reachability unless youâ€™re asked for paths or counts.</p>
            <p>Rules:</p>
            <ul>
                <li>If you are at $i$ with $i&gt;F$, you hit a gap â†’ stuck forever.</li>
                <li>Otherwise extend $F\leftarrow \max(F,i+a[i])$ and continue.</li>
            </ul>
            <p>This â€œgapâ€ rule is the entire punchline. If you arrive at an index you canâ€™t even stand on, then nothing to the right can be reached either, because all jumps move forward, and youâ€™ve already accounted for all possible forward reach from all reachable places. The <em>do</em> is: stop immediately on the first gap. The <em>donâ€™t</em> is: keep scanning hoping a later jump fixes it (it canâ€™t).</p>
            <div>
                <pre><code class="language-shell">Gap logic (why stopping is correct):

reachable prefix = [0..F]

If i = F+1, then i is outside the prefix.
No reachable square can land on i, otherwise i would be â‰¤ F.
So nothing beyond i can be reached either.</code></pre>
            </div>
            <p>At the end:</p>
            <ul>
                <li>Can reach last iff $F\ge n-1$.</li>
                <li>Furthest reachable square is $F$ (capped by $n-1$).</li>
            </ul>
            <p>This gives you both answers â€œfor freeâ€: a yes/no (did we cover the last index?) and a diagnostic (how far did we get before the road ended?). The <em>do</em> is: return both in interviews / debugging, â€œno, and hereâ€™s where it fails.â€ The <em>donâ€™t</em> is: just return false and throw away the useful boundary.</p>
            <p><strong>Algorithm</strong></p>
            <div>
                <pre><code class="language-shell">F = 0
for i in 0..n-1:
    if i &gt; F: break
    F = max(F, i + a[i])

can_reach_last = (F &gt;= n-1)
furthest = min(F, n-1)</code></pre>
            </div>
            <p>What makes this feel â€œhumanâ€ is that it matches how youâ€™d actually play: you keep walking forward as long as youâ€™re within what you already know you can reach, and every time you land somewhere with jump power, you update your best possible future. The <em>do</em> is: read it like â€œkeep upgrading my maximum reach.â€ The <em>donâ€™t</em> is: interpret it as â€œI must jump at every squareâ€, youâ€™re not choosing a specific jump sequence; youâ€™re summarizing all possible sequences.</p>
            <div>
                <pre><code class="language-shell">Frontier evolution on the example a=[3,1,0,0,4,1]

Start: F=0

i=0 &lt;=F: F=max(0,0+3)=3
i=1 &lt;=F: F=max(3,1+1)=3
i=2 &lt;=F: F=max(3,2+0)=3
i=3 &lt;=F: F=max(3,3+0)=3
i=4 &gt; F  -&gt; GAP -&gt; stop

Result: furthest reachable = 3 (can't reach 5)</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>Loop invariant: â€œAfter processing index $i$, $F$ equals the furthest position reachable using jumps that start at some truly reachable square $\le i$.â€</p>
            <p>This invariant is doing a lot of work, and itâ€™s worth appreciating why itâ€™s phrased that way: youâ€™re only allowed to use jump power from squares you can actually reach, and youâ€™re only considering launch points up to the current scan index. That matches the algorithmâ€™s left-to-right processing. The <em>do</em> is: tie the invariant to what the loop has â€œseen.â€ The <em>donâ€™t</em> is: claim $F$ is â€œfurthest reachable overallâ€ mid-loop; itâ€™s â€œfurthest reachable given processed launchpads.â€</p>
            <ul>
                <li>Initialization: $F=0$ is correct at the start.</li>
                <li>Maintenance: if $i\le F$, then $i$ is reachable, so $i+a[i]$ is a valid new reach and updating $F$ is safe.</li>
                <li>If $i&gt;F$, no earlier reachable square can jump to $i$ (all such reach was already summarized in $F$), so stopping is correct.</li>
                <li>Termination: the final $F$ is exactly the furthest reachable position.</li>
            </ul>
            <p>A nice way to visualize the proof is to imagine the scan as â€œunlockingâ€ jump powers. You can only use <code>a[i]</code> after you confirm <code>i</code> is inside the unlocked zone (<code>i â‰¤ F</code>). Every time you unlock a square, you possibly expand the unlocked zone. If you ever encounter a locked square (<code>i &gt; F</code>), the unlocking process cannot continue.</p>
            <div>
                <pre><code class="language-shell">Invariant picture:

Processed launchpads: 0..i
Reachable prefix:     0..F

We only expand F using launchpads that lie inside 0..F.
If i steps beyond F, we found the first unreachable launchpad.
Forward-only jumps =&gt; no future square can fix that.</code></pre>
            </div>
            <p><strong>Complexity</strong>: time $O(n)$, space $O(1)$.</p>
            <p>This is the reward for choosing the right summary statistic. Instead of simulating many possibilities, you scan once and keep one frontier value. The <em>do</em> is: recognize this as â€œlinear scan with a running max.â€ The <em>donâ€™t</em> is: accidentally reintroduce extra work (nested loops) when implementing.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>If $n=1$, youâ€™re already at the goal.</li>
                <li>If many $a[i]=0$, the scan correctly stops at the first gap.</li>
            </ul>
            <p>These edge cases are basically the algorithmâ€™s personality check. For <code>n=1</code>, the frontier starts at the goal. For many zeros, you quickly find where progress ends, and you stop without wasted work. The <em>do</em> is: handle <code>n=1</code> cleanly. The <em>donâ€™t</em> is: try to â€œjump from nowhereâ€ past a gap, forward-only movement makes gaps final.</p>
            <div>
                <pre><code class="language-shell">Zeros create cliffs:

a = [2,0,0,0,...]
i=0 =&gt; F=2
i=1 ok
i=2 ok
i=3 =&gt; i&gt;F =&gt; stop at 2

Cliff detected exactly where it should be.</code></pre>
            </div>
            <h4 id="minimum-spanning-trees">Minimum spanning trees</h4>
            <p><strong>Pattern</strong>: Cut-Based Greedy on Graphs</p>
            <p>Before we even touch the algorithms, it helps to picture the â€œjobâ€ an MST is doing: you want <em>all</em> the vertices connected, you want to spend as little total weight as possible, and youâ€™re not allowed to waste edges making loops. This shows up everywhere, laying fiber between cities, wiring circuits on a board, connecting servers in a data center, clustering points in ML, any time â€œconnect everything cheaplyâ€ matters. The <em>do</em> here is: think â€œinfrastructure budget.â€ The <em>donâ€™t</em> is: treat it like a random graph puzzle; itâ€™s really about spending weight efficiently.</p>
            <div>
                <pre><code class="language-shell">Goal (MST): connect all nodes, no cycles, minimum total cost

   A---(3)---B
   | \       |
 (2) (6)   (4)
   |     \   |
   C---(5)---D

Bad: has a cycle (extra spend)
Good: just enough edges to connect all nodes (|V|-1 edges)</code></pre>
            </div>
            <p><strong>Problem</strong></p>
            <p>Given a connected, undirected, weighted graph, connect all vertices with minimum total edge weight without cycles: an MST.</p>
            <p>A useful way to â€œfeelâ€ this constraint is: a tree with <code>|V|</code> vertices always has exactly <code>|V|-1</code> edges. So if you ever add an edge that creates a cycle, youâ€™ve basically bought an unnecessary cable. The <em>do</em> is: keep asking â€œdoes this edge actually help me reach a new vertex/component?â€ The <em>donâ€™t</em> is: add edges just because they look cheap, cheap and <em>useful</em> is what matters.</p>
            <div>
                <pre><code class="language-shell">Why cycles are waste (intuition)

Cycle: A--B
       |  |
       D--C

You can remove the heaviest edge on the cycle
and still keep everything connected.
So that heaviest edge was never necessary.</code></pre>
            </div>
            <p><strong>Baseline</strong></p>
            <p>Enumerate all spanning trees and pick the lightest, correct but combinatorially impossible for real graphs. This baseline is important conceptually: it reminds you what â€œoptimalâ€ even means, and it highlights why a greedy shortcut is valuable.</p>
            <p>This is the â€œbrute-force North Star.â€ Itâ€™s the version youâ€™d run if graphs were tiny and time was infinite. The <em>do</em> is: keep it in your head as the definition of correctness (â€œweâ€™re trying to match what brute force would chooseâ€). The <em>donâ€™t</em> is: ever implement it outside of toy examples, its only real job is to motivate why we need smarter structure.</p>
            <div>
                <pre><code class="language-shell">Brute-force vs. greedy (scale intuition)

# of spanning trees can explode fast.

Tiny graph: feasible
Real graph: "nope"

Greedy works because we can prove certain choices are "safe".</code></pre>
            </div>
            <p><strong>Two facts that power the greedy proofs</strong></p>
            <ul>
                <li>Cut rule (safe to add)</li>
                <li>Cycle rule (safe to skip)</li>
            </ul>
            <p>These are the â€œwhy safeâ€ pieces that let greedy commit early without regret.</p>
            <p>These two rules are the emotional support system for greedy algorithms. Greedy is scary because it â€œlocks inâ€ choices without seeing the future, but MST is one of the lucky problems where we can prove some choices canâ€™t hurt. The <em>do</em> is: when you read a proof, hunt for â€œcutâ€ or â€œcycleâ€ language. The <em>donâ€™t</em> is: memorize steps without internalizing what makes them safe; the rules are the whole reason the algorithms work.</p>
            <div>
                <pre><code class="language-shell">Cut rule (picture a cut)

   [  Left side  ]  |cut|  [  Right side  ]

A ----(lightest crossing edge)---- B

If an edge is the lightest crossing SOME cut,
it is safe to include in an MST.</code></pre>
            </div>
            <div>
                <pre><code class="language-shell">Cycle rule (picture a cycle)

A --(2)-- B
|         |
(5)     (3)
|         |
D --(4)-- C

Heaviest edge on the cycle is safe to skip.
(Here: weight 5)</code></pre>
            </div>
            <h4 id="kruskal-s-method">Kruskalâ€™s method</h4>
            <p>Kruskal feels like â€œshopping with a strict budget.â€ You walk through edges from cheapest to priciest, and you only buy an edge if it doesnâ€™t create a loop. The algorithm is simple; the magic is that the <em>rules above</em> guarantee youâ€™re not painting yourself into a corner. The <em>do</em> is: think â€œmerge components.â€ The <em>donâ€™t</em> is: think â€œbuild one expanding blobâ€ (thatâ€™s Prim).</p>
            <p><strong>Greedy rule</strong></p>
            <p>Sort edges by weight. Scan from lightest to heaviest and keep an edge if it connects two different components (i.e., doesnâ€™t form a cycle). Stop when you have $|V|-1$ edges.</p>
            <p>The â€œtwo different componentsâ€ test is the entire game. Early on, every vertex is its own component; every accepted edge fuses two components into a bigger one. The <em>do</em> is: visualize components as islands and edges as bridges. The <em>donâ€™t</em> is: accept a bridge that starts and ends on the same island, congrats, you just paid for a scenic loop.</p>
            <div>
                <pre><code class="language-shell">Kruskal = "connect islands cheaply"

Start: {A} {B} {C} {D}

Pick smallest edges that connect DIFFERENT sets:

{A}-{C}   =&gt; {AC} {B} {D}
{B}-{D}   =&gt; {AC} {BD}
{C}-{D}   =&gt; {ACBD}   (done)</code></pre>
            </div>
            <p><strong>Implementation idea</strong></p>
            <p>Use a disjoint-set union-find structure to test whether two vertices are already connected.</p>
            <p>Union-find is basically your â€œisland tracker.â€ It answers: â€œAre u and v already in the same component?â€ quickly, and if not, it merges them. The <em>do</em> is: rely on union-find for speed. The <em>donâ€™t</em> is: do connectivity checks with full graph searches per edge, youâ€™ll turn a fast algorithm into a slow one.</p>
            <div>
                <pre><code class="language-shell">Union-Find (DSU) mental model

find(x) -&gt; returns component representative
union(a,b) -&gt; merges components

If find(u) == find(v): adding (u,v) makes a cycle -&gt; skip
Else: safe to add -&gt; union(u,v)</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <ul>
                <li>If an edge would create a cycle, the cycle rule says itâ€™s safe to skip.</li>
                <li>If an edge is the lightest that connects two components, it is the lightest crossing edge of some cut, and the cut rule says itâ€™s safe to include.</li>
                <li>Exchange argument: transform any optimal MST to include Kruskalâ€™s chosen edge without increasing weight.</li>
            </ul>
            <p>Hereâ€™s the flow that makes this proof feel human: every time Kruskal picks an edge, itâ€™s either (a) obviously wasteful (it would create a cycle) so you skip it, or (b) itâ€™s the cheapest way to connect two currently-separated groups, meaning itâ€™s the cheapest edge crossing the cut between those groups. The exchange argument is the â€œno hard feelingsâ€ clause: even if the optimal MST you imagined didnâ€™t include your chosen edge, you can swap edges and not increase cost. The <em>do</em> is: connect each bullet to either â€œcutâ€ or â€œcycle.â€ The <em>donâ€™t</em> is: treat â€œexchange argumentâ€ like a spell, see it as a controlled swap that keeps the tree valid and not heavier.</p>
            <div>
                <pre><code class="language-shell">Exchange argument (tiny sketch)

Your MST:      Kruskal wants:

... X ---- Y   add edge e = (U,V)

If e not in MST, adding e creates a cycle.
Remove the heaviest edge on that cycle (call it f).
Result is still a spanning tree and no heavier.
So you can "exchange" f for e safely.</code></pre>
            </div>
            <p><strong>Complexity</strong></p>
            <ul>
                <li>Sorting: $O(E\log E)$ (often written $O(E\log V)$).</li>
                <li>Union-find operations: near-constant amortized ($\alpha(V)$).</li>
                <li>Space: $O(V)$.</li>
            </ul>
            <p>Interpretation: most of the time is spent sorting edges; union-find is the lightweight bouncer at the club door. The <em>do</em> is: remember â€œsort dominates.â€ The <em>donâ€™t</em> is: overthink $\alpha(V)$, itâ€™s effectively constant for any practical input size.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>Disconnected graph â†’ minimum spanning forest.</li>
                <li>Ties are fine: multiple MSTs may exist with the same total weight.</li>
            </ul>
            <p>Practical takeaway: in real data, disconnection is common (clusters, communities, separated regions). Kruskal doesnâ€™t panic; it just builds one MST per connected component. And if weights tie, the graph is basically saying â€œyou have multiple equally good designs.â€ The <em>do</em> is: accept that MST may not be unique. The <em>donâ€™t</em> is: expect identical edge sets across runs if tie-breaking differs.</p>
            <div>
                <pre><code class="language-shell">Disconnected -&gt; forest

Component 1: A--B--C     MST1
Component 2: D--E        MST2

Output = {MST1, MST2}</code></pre>
            </div>
            <h4 id="prim-s-method">Primâ€™s method</h4>
            <p>Prim feels like â€œgrowing a single organism.â€ You start from one vertex and keep attaching the cheapest edge that reaches something new. If Kruskal is â€œmerge islands everywhere,â€ Prim is â€œexpand one territory.â€ The <em>do</em> is: think â€œfrontier/boundary.â€ The <em>donâ€™t</em> is: think â€œglobal cheapest edge anywhereâ€ (thatâ€™s Kruskalâ€™s vibe).</p>
            <p><strong>Greedy rule</strong></p>
            <p>Grow one tree: repeatedly add the lightest edge leaving the current tree to bring in a new vertex.</p>
            <p>This â€œleaving the current treeâ€ phrase is the key limiter that makes Prim different: youâ€™re only allowed to choose edges that cross from inside to outside. The <em>do</em> is: picture a boundary fence around your current tree. The <em>donâ€™t</em> is: pick an edge fully outside the tree (even if itâ€™s super cheap), because it doesnâ€™t help your current structure grow.</p>
            <div>
                <pre><code class="language-shell">Prim boundary picture

Tree (inside) vs Outside:

   inside nodes:  {A, C}
   outside nodes: {B, D, E}

Only consider edges that cross the boundary:
  A--B, C--D, A--E, ...

Pick the cheapest crossing edge, add that outside vertex.</code></pre>
            </div>
            <p><strong>Implementation idea</strong></p>
            <p>Use a min-heap (priority queue) keyed by the cheapest â€œboundary edgeâ€ to each outside vertex.</p>
            <p>The heap is your â€œbest next dealâ€ list: for every outside vertex, keep track of the cheapest known edge that would bring it into the tree. The <em>do</em> is: update keys when you find a cheaper connection. The <em>donâ€™t</em> is: try to keep the heap perfectly clean at all times, real implementations often allow duplicates and ignore stale entries later.</p>
            <div>
                <pre><code class="language-shell">Min-heap idea (keys = best known connection cost)

Outside vertex : best edge weight so far
B : 3
D : 4
E : 2   &lt;-- pop this next

When you add E, you may discover:
D can be reached with weight 1 instead of 4 -&gt; decrease-key (or push new entry)</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>At every step, Prim picks the lightest edge crossing the cut (tree vs. outside). By the cut rule, that edge belongs to some MST, so committing to it is safe.</p>
            <p>This proof is basically one clean sentence: Prim always picks the lightest edge crossing the specific cut â€œcurrent tree vs. everything else,â€ and the cut rule says thatâ€™s safe. The <em>do</em> is: explicitly name the cut each step. The <em>donâ€™t</em> is: get lost in implementation details (heap, adjacency lists) when youâ€™re trying to understand correctness.</p>
            <div>
                <pre><code class="language-shell">Prim correctness in one diagram

Current tree T        Outside V\T

   [   T   ]  --e*--   [ outside ]

e* = lightest edge crossing this cut
Cut rule =&gt; e* is safe =&gt; you can keep growing.</code></pre>
            </div>
            <p><strong>Complexity</strong></p>
            <ul>
                <li>Binary heap + adjacency lists: $O(E\log V)$.</li>
                <li>Space: $O(V)$ plus adjacency representation.</li>
            </ul>
            <p>Meaning: every edge might cause a heap update-ish operation, and the heap costs log V per meaningful push/pop. The <em>do</em> is: use adjacency lists (especially for sparse graphs). The <em>donâ€™t</em> is: use an adjacency matrix for huge sparse graphs unless you really mean it.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>Start vertex doesnâ€™t affect total MST weight (though the chosen edges may differ).</li>
                <li>Heaps may contain stale entries; skip when popped.</li>
            </ul>
            <p>If you start at a different node, you may build a different-looking MST but with the same optimal total weight (assuming ties/structure allow multiple). And if your heap has outdated offers, just ignore them when you notice they no longer match the best-known state. The <em>do</em> is: code defensively with a visited set / current best key checks. The <em>donâ€™t</em> is: assume the heap always reflects the current truth without verification.</p>
            <h4 id="shortest-paths-with-non-negative-weights-dijkstra-">Shortest paths with non-negative weights (Dijkstra)</h4>
            <p><strong>Pattern</strong>: Cut-Based Greedy on Graphs</p>
            <p>Dijkstra is the â€œno regretsâ€ version of shortest paths: you keep a boundary between what you <em>know for sure</em> and what youâ€™re still <em>guessing</em>, and you repeatedly promote the safest-looking guess into certainty. The whole reason this works is non-negativity, roads donâ€™t give you refunds. The <em>do</em> is: treat the algorithm as expanding a region of confirmed shortest distances. The <em>donâ€™t</em> is: use it when edges can be negative; a negative edge is exactly the kind of â€œrefund detourâ€ that breaks the safety logic.</p>
            <div>
                <pre><code class="language-shell">Two-zone view:

Settled (final)      Unsettled (tentative)
[  correct dist  ] | [  maybe smaller later  ]

Dijkstra repeatedly moves the boundary rightward:
it "locks in" one node at a time.</code></pre>
            </div>
            <p><strong>Problem</strong></p>
            <p>From a start node $s$, compute shortest distances $d(\cdot)$ to all nodes (and routes via parents). Edge weights must be non-negative.</p>
            <p>Why you should care: shortest paths is the backbone of routing, navigation, dependency planning, game AI, and â€œminimum cost to reach Xâ€ problems. The output isnâ€™t just numbers, itâ€™s also <em>parents</em> (how you actually get there). The <em>do</em> is: maintain both distance and predecessor for reconstruction. The <em>donâ€™t</em> is: only compute distances and then wonder how to produce the path later.</p>
            <div>
                <pre><code class="language-shell">Distances + parents =&gt; path reconstruction

parent[v] = u means: best-known path to v ends with edge u-&gt;v

To reconstruct s -&gt; t:
t &lt;- parent[t] &lt;- parent[parent[t]] &lt;- ... &lt;- s
(reverse it)</code></pre>
            </div>
            <p><strong>Baseline</strong></p>
            <p>Bellmanâ€“Ford-style repeated relaxation: about $O(|V||E|)$. It handles negatives; Dijkstra doesnâ€™t need that generality, so greedy buys speed.</p>
            <p>The baseline is â€œkeep trying to improve everyone until nothing changes.â€ Itâ€™s powerful because it works even with negative edges, but it spends time rechecking improvements that canâ€™t possibly matter when all edges are non-negative. Greedy says: â€œinstead of endlessly revisiting, letâ€™s <em>finalize</em> nodes when weâ€™re sure.â€ The <em>do</em> is: see Dijkstra as a faster specialization of relaxation. The <em>donâ€™t</em> is: forget that Bellmanâ€“Ford exists when negatives appear.</p>
            <div>
                <pre><code class="language-shell">Relaxation idea (shared by both):

If d[u] + w(u,v) &lt; d[v], then update d[v].

Difference:
- Bellman-Ford repeats relaxations many rounds.
- Dijkstra chooses an order that makes some nodes final early.</code></pre>
            </div>
            <p><strong>Greedy rule: â€œsettle the smallest labelâ€</strong></p>
            <p>Repeatedly pick the unsettled node $u$ with smallest tentative distance $d(u)$ and <strong>settle</strong> it (declare its distance final).</p>
            <p>â€œSettleâ€ is the key word: once settled, a node never changes again. Thatâ€™s the greedy commitment. The <em>do</em> is: interpret â€œsmallest labelâ€ as â€œclosest frontier point.â€ The <em>donâ€™t</em> is: settle nodes in arbitrary order; the safety proof depends on always picking the minimum tentative distance next.</p>
            <div>
                <pre><code class="language-shell">Label-setting picture:

d[ ] = current best-known distances

Unsettled nodes have labels like:
A: 7   B: 3   C: 11   D: 5

Pick the smallest (B:3), settle it, relax its outgoing edges.</code></pre>
            </div>
            <p><strong>Why safe</strong></p>
            <p>With non-negative weights, any path to $u$ that detours through other unsettled nodes can only add non-negative cost, so it cannot beat the current smallest label.</p>
            <p>This is the intuition that makes the algorithm feel â€œobviously rightâ€: if <code>u</code> is currently the cheapest unsettled node, then going from <code>s</code> to some other unsettled node <code>x</code> (which is already â‰¥ <code>d(u)</code>) and then traveling more edges to reach <code>u</code> canâ€™t magically become cheaper, because those extra edges canâ€™t subtract cost. The <em>do</em> is: remember â€œdetours only add.â€ The <em>donâ€™t</em> is: forget that a single negative edge is enough to make a detour beneficial.</p>
            <div>
                <pre><code class="language-shell">Why non-negative matters:

If all edges &gt;= 0, then detour cost &gt;= 0.

So if u is the cheapest tentative node,
any route that reaches u via another unsettled node
must be &gt;= that other node's tentative distance &gt;= d[u].

No detour can undercut d[u].</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>Loop invariant: â€œAll settled nodes have correct shortest-path distances.â€</p>
            <p>The invariant is your safety harness: weâ€™re gradually building a set <code>S</code> of nodes whose distances are finalized and correct. Each step must preserve that truth. The <em>do</em> is: keep the invariant in mind while reading the algorithm. The <em>donâ€™t</em> is: think Dijkstra is â€œjust BFS with weightsâ€, the correctness comes from this settle-min step plus non-negativity.</p>
            <ul>
                <li>Initialization: $d(s)=0$ is correct.</li>
                <li>Maintenance: settling the minimum-label node is safe by non-negativity.</li>
                <li>Termination: when all reachable nodes are settled, distances are correct.</li>
            </ul>
            <p>A cut-based way to picture the maintenance step:</p>
            <ul>
                <li>Let <code>S</code> be settled nodes, <code>V \ S</code> unsettled.</li>
                <li>Dijkstra chooses <code>u</code> in <code>V \ S</code> with minimum <code>d(u)</code>.</li>
                <li>Any path to an unsettled node must cross the cut at some edge out of <code>S</code>.</li>
                <li><code>d(u)</code> is already the best possible among those, so itâ€™s final.</li>
            </ul>
            <div>
                <pre><code class="language-shell">Cut view:

S (settled)             V\S (unsettled)
[ s, ..., ]  |cut|  [ u, v, w, ... ]

All known best routes to outside go through this boundary.
Pick the smallest boundary-reachable node u, lock it in.</code></pre>
            </div>
            <p><strong>Complexity</strong></p>
            <ul>
                <li>With binary heap: $O((V+E)\log V)$.</li>
                <li>Space: $O(V)$.</li>
            </ul>
            <p>Heap intuition: you need a fast way to repeatedly extract the smallest tentative label and to push improved distances. The <em>do</em> is: use a priority queue keyed by <code>d</code>. The <em>donâ€™t</em> is: linearly scan for the minimum each time unless <code>V</code> is tiny.</p>
            <div>
                <pre><code class="language-shell">What the heap is doing:

push (0, s)
repeat:
  pop smallest (dist, u)
  if u already settled: continue
  settle u
  for each edge (u,v,w):
      if dist + w &lt; d[v]:
          d[v] = dist + w
          parent[v] = u
          push (d[v], v)</code></pre>
            </div>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>Unreachable nodes remain at $\infty$.</li>
                <li>Stale heap entries occur; skip if already settled.</li>
            </ul>
            <p>Unreachable nodes are not a failure, theyâ€™re a real output: â€œthere is no path from s.â€ Stale heap entries happen because many implementations push a new <code>(betterDist, v)</code> instead of decreasing-key in place; later, the old worse entry resurfaces and must be ignored. The <em>do</em> is: keep a settled/visited check. The <em>donâ€™t</em> is: assume every pop is â€œthe one true current distance.â€</p>
            <div>
                <pre><code class="language-shell">Stale entry example:

Heap contains:
(10, v)   &lt;- old
(6,  v)   &lt;- newer, better

Pop (6, v): settle v
Later pop (10, v): v already settled -&gt; skip</code></pre>
            </div>
            <h4 id="scheduling-themes">Scheduling themes</h4>
            <p><strong>Pattern</strong>: Scheduling Greedy</p>
            <p>Scheduling is greedy-friendly because â€œwhat you do earlyâ€ shapes whatâ€™s possible later, and the proofs often boil down to a clean exchange: â€œfinishing earlier leaves more room.â€</p>
            <p>That â€œleaves more roomâ€ line is the whole vibe of scheduling proofs. Time is a one-way resource: once you waste a slot early, you canâ€™t buy it back later. So greedy strategies that <strong>protect future flexibility</strong> often win. The <em>do</em> is: look for a simple local choice that maximizes options later (earliest finish, earliest due date). The <em>donâ€™t</em> is: get distracted by â€œwhat feels urgentâ€ unless the objective matches that urgency.</p>
            <div>
                <pre><code class="language-shell">Scheduling = packing into time

Time ----------------------------------------------------&gt;

Every choice consumes a chunk.
Good greedy choices keep the remaining timeline usable.</code></pre>
            </div>
            <h4 id="interval-scheduling-maximum-number-of-non-overlapping-intervals-">Interval scheduling (maximum number of non-overlapping intervals)</h4>
            <p>This is the â€œfit as many meetings as possibleâ€ problem. The trick is realizing the objective is <strong>count</strong>, not total duration, not value, not â€œuse time efficiently.â€ If youâ€™re maximizing <em>how many</em>, then short/early-finishing intervals are gold because they leave space for more. The <em>do</em> is: optimize for free time after each pick. The <em>donâ€™t</em> is: pick the earliest-starting interval (thatâ€™s a classic wrong greedy).</p>
            <p><strong>Baseline</strong></p>
            <p>Try all subsets â†’ exponential.</p>
            <p>The baseline is â€œcheck every combination of meetings and see which one works.â€ Itâ€™s correct but useless at scale, and it hides the structure: feasibility depends on <em>ordering</em> in time, not arbitrary set selection. The <em>do</em> is: use it to define correctness (â€œmaximum numberâ€). The <em>donâ€™t</em> is: keep thinking in subsets once you see time order exists.</p>
            <div>
                <pre><code class="language-shell">Why subsets explode:

Intervals: n
Subsets:   2^n

Even n=50 is astronomical.</code></pre>
            </div>
            <p><strong>Greedy rule</strong></p>
            <p>Sort by finish time, take the next interval that starts after the last chosen ends.</p>
            <p>This is the â€œalways finish as early as possibleâ€ strategy. Itâ€™s not about being fast for its own sake, itâ€™s about keeping the remaining timeline as wide as possible for future intervals. The <em>do</em> is: treat the finish time as the critical decision point. The <em>donâ€™t</em> is: prioritize long intervals or early starts; those can block many later choices.</p>
            <div>
                <pre><code class="language-shell">Wrong greedy (earliest start) can fail:

A: [1---------10]
B: [2-3]
C:   [3-4]
D:     [4-5]
E:       [5-6]
F:         [6-7]
G:           [7-8]
H:             [8-9]

Earliest start picks A -&gt; total 1
Earliest finish picks B,C,D,E,F,G,H -&gt; total 7</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>Exchange argument: if an optimal schedule picks an interval that finishes later than the earliest-finishing compatible interval, swap it out. You donâ€™t reduce how many intervals fit afterward because you only <em>free up</em> time.</p>
            <p>Hereâ€™s the â€œhumanâ€ version of the exchange: suppose you and I both have a schedule, and at some step you picked a meeting that ends at 5pm, but there was another compatible meeting that ends at 3pm. If we swap yours for the 3pm one, everything after 5pm is still available, and now <em>more</em> time is available between 3pm and 5pm too. So swapping cannot make your future worse; it can only keep it the same or improve it. The <em>do</em> is: focus on the first decision where two schedules differ. The <em>donâ€™t</em> is: try to prove it by complex induction before you see the simple â€œend earlier canâ€™t hurtâ€ fact.</p>
            <div>
                <pre><code class="language-shell">Exchange picture:

Your chosen interval:     [---X---] ends late
Greedy candidate:         [--G--]   ends earlier

Timeline:  ----|----|----|----|----&gt;
                     G end   X end

Anything that starts after X end also starts after G end.
So replacing X with G keeps all later options.</code></pre>
            </div>
            <p><strong>Complexity</strong>: $O(n\log n)$ sort + $O(n)$ scan.</p>
            <p>Most work is sorting once. The scan is just â€œtake it if it fits.â€ The <em>do</em> is: implement as sort-by-end then one pass. The <em>donâ€™t</em> is: repeatedly search for the next interval in an inner loop.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>If everything overlaps, you keep 1.</li>
                <li>Equal finish times can be broken arbitrarily.</li>
            </ul>
            <p>Equal finish times donâ€™t change the â€œfree up timeâ€ logic, finishing at the same time leaves the same future. The <em>do</em> is: treat ties as harmless. The <em>donâ€™t</em> is: overfit tie-breaking rules unless you need reproducibility.</p>
            <h4 id="minimize-the-maximum-lateness-unit-time-jobs-">Minimize the maximum lateness (unit-time jobs)</h4>
            <p>Define lateness for job $i$ as $L_i=C_i-d_i$ and objective $L_{\max}=\max_i L_i$.</p>
            <p>This problem is subtle because itâ€™s not â€œmeet all deadlinesâ€ (sometimes you canâ€™t). Itâ€™s â€œif someone is late, make the worst lateness as small as possible.â€ So fairness matters: youâ€™re trying to prevent one job from being <em>catastrophically</em> late. The <em>do</em> is: think â€œminimize the worst-case pain.â€ The <em>donâ€™t</em> is: optimize average lateness; thatâ€™s a different objective.</p>
            <div>
                <pre><code class="language-shell">Unit-time jobs = each job takes 1 slot:

Slots: 1 2 3 4 5 ...
Pick an order, jobs fill slots in that order.

Completion time C_i = slot index when job finishes.
Lateness L_i = C_i - d_i
Goal: minimize max lateness across all jobs.</code></pre>
            </div>
            <p><strong>Baseline</strong></p>
            <p>Try all $n!$ orders â†’ impossible.</p>
            <p>The baseline here is â€œtry every permutation.â€ It screams that what matters is the order, and that we need a rule to choose an order without exploring all of them. The <em>do</em> is: acknowledge scheduling is about permutations. The <em>donâ€™t</em> is: brute-force except for tiny <code>n</code>.</p>
            <p><strong>Greedy rule (EDD)</strong></p>
            <p>Sort jobs by nondecreasing deadlines (Earliest Due Date first).</p>
            <p>EDD is the â€œprotect the earliest deadline from getting pushed backâ€ strategy. If a job is due sooner, delaying it tends to create large lateness spikes. Putting it earlier is like paying the urgent bills first so your â€œoverdue penaltyâ€ doesnâ€™t explode. The <em>do</em> is: sort by <code>d_i</code>. The <em>donâ€™t</em> is: sort by shortest job first here, processing times are all equal, so that idea is irrelevant.</p>
            <div>
                <pre><code class="language-shell">EDD visual:

Deadlines:  d=2  d=5  d=5  d=9  d=10
Order:      earliest deadline jobs first</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>Exchange argument on inversions: if two adjacent jobs are out of deadline order, swapping them cannot increase $L_{\max}$, and it improves (or preserves) the lateness of the earlier-deadline job. Repeatedly remove inversions â†’ sorted order is optimal.</p>
            <p>The â€œwhyâ€ is very local: consider two adjacent jobs <code>A</code> then <code>B</code> where <code>d_A &gt; d_B</code> (theyâ€™re inverted). Since both take one unit time, the pair occupies the same two slots either way, swapping only changes <em>which job gets the earlier slot</em>. Giving the earlier slot to the earlier deadline is never worse for the maximum lateness. So you bubble-sort away inversions without harming the objective, ending at EDD. The <em>do</em> is: zoom in on a two-job swap. The <em>donâ€™t</em> is: attempt a global argument without this local swap lens.</p>
            <div>
                <pre><code class="language-shell">Inversion swap diagram (unit time)

Current order:  A then B   with d_A &gt; d_B
Slots:          t     t+1

Case 1: A then B
C_A = t
C_B = t+1
L_A = t - d_A
L_B = (t+1) - d_B

Case 2: B then A
C_B = t
C_A = t+1
L_B' = t - d_B        (improves, since earlier completion for earlier deadline)
L_A' = (t+1) - d_A    (may worsen by 1)

Key: the job with the tighter deadline stops being punished.
Max lateness cannot increase by doing the swap.</code></pre>
            </div>
            <p><strong>Complexity</strong>: $O(n\log n)$.</p>
            <p>Again: sort once, then schedule in that order. The <em>do</em> is: implement as sort-by-deadline then compute completion times. The <em>donâ€™t</em> is: simulate with complicated data structures when unit-time makes it simple.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>Same deadlines â†’ any order ties.</li>
                <li>Different processing times $p_j$ requires a different model/algorithm.</li>
            </ul>
            <p>EDD is optimal for <strong>unit-time</strong> jobs (or more generally, for minimizing maximum lateness on a single machine even with varying processing times under classic results, but the proof and model shift). Your note is a good guardrail: if job lengths differ, you must be precise about which theorem/problem variant youâ€™re in. The <em>do</em> is: check assumptions (unit time? single machine? no release times?). The <em>donâ€™t</em> is: apply EDD blindly when the model changes.</p>
            <div>
                <pre><code class="language-shell">Model checklist:

- single machine?
- all jobs available at time 0?
- unit processing times?
- objective is L_max (max lateness), not #on-time?

If any change: re-evaluate the greedy rule.</code></pre>
            </div>
            <h4 id="huffman-coding">Huffman coding</h4>
            <p><strong>Pattern</strong>: Merge-the-Two-Smallest Greedy</p>
            <p>Huffman coding is what happens when you take â€œbe efficientâ€ seriously: frequent symbols should be quick to write, rare symbols can be longer, and <strong>prefix-free</strong> means decoding is unambiguous (you never get stuck wondering where one codeword ends). The <em>do</em> is: think â€œshort for common, long for rare.â€ The <em>donâ€™t</em> is: chase clever-looking bitstrings by hand, this is a tree problem wearing a binary hat.</p>
            <div>
                <pre><code class="language-shell">Prefix-free means: no codeword is the prefix of another

Good:
A: 0
B: 10
C: 110
D: 111

Bad (ambiguous):
A: 0
B: 01   &lt;- "0" is a prefix of "01"</code></pre>
            </div>
            <p><strong>Problem</strong></p>
            <p>Given symbol frequencies $f_i&gt;0$ with $\sum_i f_i=1$, find a prefix code minimizing average length:</p>
            <p>$$
                \mathbb{E}[L]=\sum_i f_i L_i.
                $$</p>
            <p>The â€œwhy careâ€ is baked into the formula: every extra bit on a high-frequency symbol costs you a lot, while extra bits on a rare symbol barely move the needle. Huffman is the clean, provably optimal way to trade length against frequency under the prefix constraint. The <em>do</em> is: keep seeing the objective as â€œweighted depth in a tree.â€ The <em>donâ€™t</em> is: treat it like arithmetic on bitstrings; the tree is the real object.</p>
            <div>
                <pre><code class="language-shell">Code tree view:

Each symbol = a leaf
Codeword length L_i = depth of that leaf

Average length = sum(f_i * depth_i)
So we want heavy leaves shallow, light leaves deep.</code></pre>
            </div>
            <p><strong>Baseline</strong></p>
            <p>Enumerate full binary trees â†’ combinatorial explosion. Fixed-length codes (like all length $\lceil\log_2 k\rceil$) are easy but usually suboptimal. Greedy is the route to â€œoptimal but still fast.â€</p>
            <p>This baseline is important for two reasons:</p>
            <ol>
                <li>It clarifies what â€œoptimalâ€ really means (best tree among all prefix trees).</li>
                <li>It shows why we need structure: there are too many trees to brute-force.</li>
            </ol>
            <p>Fixed-length coding is the â€œeasy but wastefulâ€ plan: it ignores the fact that some symbols happen way more than others. Huffmanâ€™s whole point is exploiting skew. The <em>do</em> is: compare â€œequal lengthsâ€ vs â€œfrequency-aware lengths.â€ The <em>donâ€™t</em> is: assume fixed-length is close to optimal unless frequencies are nearly uniform.</p>
            <div>
                <pre><code class="language-shell">Fixed-length code (k=8):
everyone gets length 3 bits

But if one symbol is 50% of the data,
making it length 1 can massively reduce average length.</code></pre>
            </div>
            <p><strong>Greedy rule</strong></p>
            <p>Repeatedly merge the two smallest weights $p$ and $q$ into $p+q$.</p>
            <p>This is the heart of Huffman: if two symbols are the least frequent, you can â€œbury them deepâ€ together with minimal pain. Merging is like saying: â€œin the final tree, these two will share a parent.â€ You then treat that parent as a combined pseudo-symbol with frequency <code>p+q</code> and repeat. The <em>do</em> is: see merging as â€œcommit a deepest sibling pair.â€ The <em>donâ€™t</em> is: merge something just because it looks convenient; it must be the <strong>two smallest</strong> for optimality.</p>
            <div>
                <pre><code class="language-shell">Greedy visualization (weights only):

(0.05) (0.07) (0.12) (0.15) (0.25) (0.36)

Merge two smallest:
0.05 + 0.07 -&gt; 0.12

Now weights:
(0.12) (0.12) (0.15) (0.25) (0.36)
Repeat...</code></pre>
            </div>
            <p><strong>Why the cost increases by exactly $p+q$</strong></p>
            <p>When you merge two subtrees, every leaf under them increases depth by $1$, so the objective increases by the total frequency mass under them:</p>
            <p>$$
                \Delta \mathbb{E}[L] = p+q.
                $$</p>
            <p>This is the â€œwhy this greedy is even measurableâ€ moment: every merge has an exactly quantifiable cost. If you decide two subtrees will become siblings one level deeper, youâ€™re charging every leaf underneath them one extra bit. The <em>do</em> is: remember â€œeach merge adds its combined weight once.â€ The <em>donâ€™t</em> is: think you need to build the entire codebook to compute the total cost, you can sum merge weights.</p>
            <div>
                <pre><code class="language-shell">Depth bump diagram:

Before merge:            After merge:
   T_p                     (parent)
  /...\                   /       \
 leaves                 T_p       T_q
(depth d)             (depth d+1) (depth d+1)

All leaves under T_p and T_q get +1 depth.
Total added cost = (mass under T_p) + (mass under T_q) = p + q</code></pre>
            </div>
            <p>So the final cost is the sum of merge weights.</p>
            <p>Thatâ€™s a beautiful side effect: Huffman is not just â€œconstruct a tree,â€ itâ€™s â€œpay a known fee at each merge.â€ The algorithm is like repeatedly choosing the cheapest â€œdepth increaseâ€ to apply.</p>
            <div>
                <pre><code class="language-shell">Total cost = Î£ (merge_weight at each step)

Because each merge corresponds to "add 1 bit"
to all leaves under the merged node.</code></pre>
            </div>
            <p><strong>Why safe</strong></p>
            <p>Exchange argument: in an optimal prefix tree, the two least frequent symbols can be assumed to be deepest siblings. If a heavier symbol were deeper than a lighter one, swapping them would reduce cost. Collapsing the deepest sibling pair reduces the problem size and preserves optimality â†’ induction.</p>
            <p>Hereâ€™s the flow that makes this feel human rather than mystical:</p>
            <ol>
                <li>In any prefix tree, the deepest leaves pay the most bits.</li>
                <li>So if <em>someone</em> must be deepest, it should be the least frequent symbols (cheapest to â€œpunishâ€ with extra length).</li>
                <li>Moreover, in a full binary prefix tree, the deepest leaves come in sibling pairs (they share a parent).</li>
                <li>Therefore, you can assume the two smallest frequencies are deepest siblings in an optimal tree.</li>
                <li>If you glue them into one pseudo-symbol of weight <code>p+q</code>, youâ€™ve shrunk the problem while preserving optimal structure, then repeat.</li>
            </ol>
            <p>The <em>do</em> is: connect â€œleast frequentâ€ â†’ â€œdeepestâ€ â†’ â€œsiblingsâ€ â†’ â€œmerge.â€ The <em>donâ€™t</em> is: accept â€œexchange argumentâ€ as a black box; itâ€™s just â€œput heavier stuff shallower.â€</p>
            <div>
                <pre><code class="language-shell">Exchange intuition (swap reduces cost)

Suppose:
light symbol has freq p
heavy symbol has freq r, where r &gt; p

If heavy is deeper by 1:
cost includes r*(d+1) + p*d

Swap them:
cost becomes r*d + p*(d+1)

Difference (old - new) = r - p &gt; 0
So swapping improves cost.
Therefore optimal trees push small freqs deeper.</code></pre>
            </div>
            <div>
                <pre><code class="language-shell">Induction step picture:

Deepest siblings in optimal tree:
   parent
   /   \
  p     q   (two smallest)

Collapse them into one node of weight p+q:

   (p+q)

Now solve smaller problem optimally.
Expand back =&gt; optimal for original.</code></pre>
            </div>
            <p><strong>Implementation</strong>: min-heap.</p>
            <p>The heap is how you make â€œalways pick two smallestâ€ fast. Each pop gives you the smallest remaining weight; push back the merged weight; repeat until one weight remains. The <em>do</em> is: treat it like repeatedly combining the cheapest two tasks. The <em>donâ€™t</em> is: sort once and then do linear merges incorrectly, after every merge, the new <code>p+q</code> must re-enter the â€œsmallest candidatesâ€ pool.</p>
            <div>
                <pre><code class="language-shell">Min-heap loop:

push all f_i
while heap size &gt; 1:
    p = pop_min()
    q = pop_min()
    push(p+q)
    cost += p+q</code></pre>
            </div>
            <p><strong>Complexity</strong>: $O(k\log k)$ for $k$ symbols.</p>
            <p>Interpretation: you do <code>k-1</code> merges; each merge does two pops and one push, each <code>log k</code>. The <em>do</em> is: remember it scales well even for large alphabets. The <em>donâ€™t</em> is: assume itâ€™s linear; the heap work matters (but itâ€™s still very fast in practice).</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>Ties â†’ multiple optimal codebooks, same $\mathbb{E}[L]$.</li>
                <li>Two symbols â†’ both length $1$.</li>
            </ul>
            <p>Ties are normal in real data (e.g., equal counts), and Huffman doesnâ€™t care which tied pair you merge first, different trees, same optimal average length. With two symbols, thereâ€™s exactly one sensible prefix code: one gets <code>0</code>, the other gets <code>1</code>. The <em>do</em> is: expect non-uniqueness. The <em>donâ€™t</em> is: treat different Huffman outputs as â€œwrongâ€ if the cost matches.</p>
            <div>
                <pre><code class="language-shell">Two symbols:

A: 0
B: 1

Average length = 1 exactly.</code></pre>
            </div>
            <h4 id="maximum-contiguous-sum-kadane-">Maximum contiguous sum (Kadane)</h4>
            <p><strong>Pattern</strong>: Discard-Negative-Prefix Greedy</p>
            <p>This pattern is about emotional baggage: if the stuff youâ€™ve accumulated so far is dragging you down, stop carrying it. Kadaneâ€™s algorithm works because <em>contiguous</em> means youâ€™re forced to take whatever came immediately before, so the only real choice at each position is: <strong>extend</strong> the current block, or <strong>start fresh</strong> here. The <em>do</em> is: treat every index as a â€œrestart checkpoint.â€ The <em>donâ€™t</em> is: keep a running sum just because you started it earlier; sunk cost has no power here.</p>
            <div>
                <pre><code class="language-shell">Contiguous block = one solid segment

x:  [  ...  | start --------- end | ... ]
            ^ you can't "skip" inside

So at each j:
Either extend the segment ending at j-1
or start a new segment at j.</code></pre>
            </div>
            <p><strong>Problem</strong></p>
            <p>Given an array, pick one contiguous block maximizing its sum.</p>
            <p>Why you should care: this shows up as â€œbest streak,â€ â€œmax profit over a period,â€ â€œstrongest signal window,â€ â€œmost energetic segment,â€ and a million other â€œfind the hottest runâ€ tasks. The <em>do</em> is: recognize it as â€œbest windowâ€ not â€œbest set.â€ The <em>donâ€™t</em> is: mix it up with picking any subset (thatâ€™s a different problem).</p>
            <div>
                <pre><code class="language-shell">Subset vs contiguous (important!)

contiguous:  [x2, x3, x4]  (must be adjacent)
subset:      [x2, x7, x9]  (can skip)

Kadane is for contiguous.</code></pre>
            </div>
            <p><strong>Baseline</strong></p>
            <p>Try all $O(n^2)$ blocks (using prefix sums to evaluate quickly).</p>
            <p>The baseline is the â€œI will brute-force my way to truthâ€ approach: choose every possible start and end, compute sums, keep the best. Itâ€™s correct, and it teaches what â€œoptimalâ€ means, but it wastes time by recomputing overlapping windows. The <em>do</em> is: remember this baseline when you want to justify correctness. The <em>donâ€™t</em> is: actually use it for large <code>n</code> unless you enjoy waiting.</p>
            <div>
                <pre><code class="language-shell">All blocks = all (L,R) pairs

L=0: (0,0) (0,1) (0,2) ...
L=1:       (1,1) (1,2) ...
...

O(n^2) windows, tons of overlap.</code></pre>
            </div>
            <p><strong>Greedy rule</strong></p>
            <p>Never carry a negative-running prefix forward. If your running sum becomes negative, drop it, because adding a negative prefix to any future suffix only makes it worse.</p>
            <p>This is the â€œwhyâ€ that makes the algorithm feel inevitable: if your current partial sum is negative, then for any future value <code>t</code>,
                <code>(negative sum) + t &lt; t</code>.
                So keeping that negative prefix can never help you build a best block that continues into the future. The <em>do</em> is: reset when the running sum goes below zero. The <em>donâ€™t</em> is: reset when it merely â€œgets smallerâ€, smaller can still be useful if it stays non-negative.
            </p>
            <div>
                <pre><code class="language-shell">Why negative prefixes are poison:

Suppose prefix sum P &lt; 0.
Any future suffix S:

P + S  &lt;  0 + S  = S

So the best subarray that ends in the future
will never want to include P.</code></pre>
            </div>
            <p>Equivalent incremental form:</p>
            <p>$$
                E_j = \max(x[j], E_{j-1}+x[j])
                $$</p>
            <p>and track the best seen.</p>
            <p>Here <code>E_j</code> is the best sum of a subarray that <strong>must end at j</strong>. Thatâ€™s the key: â€œending hereâ€ makes the choice local and greedy-friendly. Either you (1) start at <code>j</code> (take only <code>x[j]</code>), or (2) extend the best ending at <code>j-1</code>. Thereâ€™s no third option if contiguity is mandatory. The <em>do</em> is: read the recurrence as â€œrestart vs extend.â€ The <em>donâ€™t</em> is: treat it like magic DP, this one is literally just the two possible ways to end at <code>j</code>.</p>
            <div>
                <pre><code class="language-shell">Two options at j:

Option A: start new at j
   [ x[j] ]

Option B: extend previous best ending at j-1
   [ ... best ending at j-1 ..., x[j] ]

Take max of the two.</code></pre>
            </div>
            <p>A quick â€œflowâ€ visualization for intuition:</p>
            <div>
                <pre><code class="language-shell">x:    [  4,  -6,  3,  2,  -1,  5 ]
E:     4   -2   3   5    4   9
best:  4    4   4   5    5   9

At -6, the running sum becomes negative -&gt; baggage dropped.
Then the streak restarts at 3.</code></pre>
            </div>
            <p><strong>Proof sketch</strong></p>
            <p>A negative prefix cannot improve any future subarray sum, so discarding it is always safe. The loop maintains â€œbest sum ending hereâ€ and â€œbest overall.â€</p>
            <p>The proof is basically a tight little logic loop:</p>
            <ol>
                <li>To get the best subarray ending at <code>j</code>, you either start at <code>j</code> or extend something ending at <code>j-1</code> (contiguity forces this).</li>
                <li>If the best ending at <code>j-1</code> is negative, extending it only hurts, so starting fresh is optimal.</li>
                <li>Therefore the recurrence computes the correct â€œbest ending here,â€ and taking the maximum over all <code>j</code> gives the best overall.</li>
            </ol>
            <p>The <em>do</em> is: anchor your reasoning on â€œmust end at j.â€ The <em>donâ€™t</em> is: try to prove it by enumerating all subarrays again, youâ€™ll just reinvent the baseline.</p>
            <div>
                <pre><code class="language-shell">Invariant view:

E_j = best sum of any subarray that ends exactly at j
BEST = max over all E_j seen so far

Update keeps both truths correct each step.</code></pre>
            </div>
            <p><strong>Complexity</strong>: $O(n)$ time, $O(1)$ space.</p>
            <p>You scan once, keep two numbers (<code>E</code> and <code>BEST</code>). Thatâ€™s the whole win: maximal information compression with minimal bookkeeping. The <em>do</em> is: implement it as a single pass. The <em>donâ€™t</em> is: store all <code>E_j</code> unless you specifically need reconstruction.</p>
            <p><strong>Edge cases</strong></p>
            <ul>
                <li>All negatives â†’ answer is the least negative element (for non-empty requirement).</li>
                <li>If empty block allowed â†’ initialize best at $0$.</li>
            </ul>
            <p>These matter because Kadaneâ€™s â€œreset when negativeâ€ can otherwise trick you into returning 0 even when youâ€™re required to pick <em>something</em>. The <em>do</em> is: decide up front whether â€œempty subarrayâ€ is allowed. The <em>donâ€™t</em> is: mix conventions mid-solution.</p>
            <div>
                <pre><code class="language-shell">All-negative example: [-5, -2, -8]

Non-empty required:
  answer = -2 (pick the single best element)

Empty allowed:
  answer = 0  (pick empty block)</code></pre>
            </div>
            <h3 id="when-greedy-is-guaranteed-matroids">When Greedy Is Guaranteed: Matroids</h3>
            <p>Thereâ€™s a clean world where greedy is always right for nonnegative weights: matroids.</p>
            <p>Informal rules:</p>
            <ol>
                <li>Start from empty.</li>
                <li>Subsets of allowed sets are allowed.</li>
                <li>Augmentation: if one allowed set is smaller than another, you can add something from the larger to the smaller and stay allowed.</li>
            </ol>
            <p>Why you should care: matroids are a formal â€œcertificateâ€ that exchange arguments will succeed. They explain why â€œsort by weight and take what fitsâ€ works for MSTs (graphic matroid).</p>
            <p>Greedy can still work outside matroids (Dijkstra, Huffman), but then correctness depends on problem-specific structure rather than the general matroid guarantee.</p>
            <h3 id="common-failure-modes">Common Failure Modes</h3>
            <p>Greedy doesnâ€™t always work. The failures are valuable because they teach you what a missing proof looks like.</p>
            <h4 id="coin-change-with-non-canonical-coins">Coin change with non-canonical coins</h4>
            <p>Denominations ${1,3,4}$, target $6$.</p>
            <ul>
                <li>Greedy: $4+1+1$ â†’ 3 coins.</li>
                <li>Optimal: $3+3$ â†’ 2 coins.</li>
            </ul>
            <p>Lesson: â€œlargest coin firstâ€ is not universally safe; it depends on special coin systems.</p>
            <h3 id="interval-scheduling-by-earliest-start-time-wrong-rule-">Interval scheduling by earliest start time (wrong rule)</h3>
            <p>Intervals $(1,10),(2,3),(4,5)$.</p>
            <ul>
                <li>Earliest start picks $(1,10)$ â†’ blocks everything â†’ 1 interval.</li>
                <li>Earliest finish picks $(2,3),(4,5)$ â†’ 2 intervals.</li>
            </ul>
            <p>Lesson: the key must match the exchange argument (â€œfinishes earlier leaves more roomâ€).</p>
            <h4 id="fractional-vs-0-1-knapsack">Fractional vs 0/1 knapsack</h4>
            <p>Greedy by value/weight ratio is optimal for fractional knapsack, but fails for 0/1.</p>
            <p>Example capacity $50$ with items $(10,60),(20,100),(30,120)$:</p>
            <ul>
                <li>Greedy ratio picks items 1 and 2 â†’ value $160$.</li>
                <li>Optimal picks items 2 and 3 â†’ value $220$.</li>
            </ul>
            <p>Lesson: allowing fractions changes feasibility structure, and greedy safety can disappear.</p>
        </article-section>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column footer-about">
                <h2>About</h2>
                <p class="footer-message">Thanks for stopping by. This site is free to use; please be respectful and avoid misuse. For questions or collaboration, reach me on <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn</a> or <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a>.</p>
                <p class="footer-signature">Built with care in Berlin (UTC+1).</p>
            </div>
            <div class="footer-column footer-links">
                <h2>Quick Links</h2>
                <ul class="footer-links-list">
                    <li><a href="https://adamdjellouli.com/index.html" title="Home">Home</a></li>
                    <li><a href="https://adamdjellouli.com/core/projects.html" title="Projects">Projects</a></li>
                    <li><a href="https://adamdjellouli.com/core/tools.html" title="Tools">Tools</a></li>
                    <li><a href="https://adamdjellouli.com/core/courses.html" title="Courses">Courses</a></li>
                    <li><a href="https://adamdjellouli.com/core/resume.html" title="Resume">Resume</a></li>
                    <li><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Privacy Policy</a></li>
                    <li><a href="https://adamdjellouli.com/sitemap.xml" title="Sitemap">Sitemap</a></li>
                </ul>
            </div>
            <div class="footer-column footer-social">
                <h2>Follow</h2>
                <ul class="social-media">
                    <li>
                        <a aria-label="YouTube" class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" rel="noopener" target="_blank" title="YouTube"></a>
                        <span class="social-label">YouTube</span>
                    </li>
                    <li>
                        <a aria-label="LinkedIn" class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" rel="noopener" target="_blank" title="LinkedIn"></a>
                        <span class="social-label">LinkedIn</span>
                    </li>
                    <li>
                        <a aria-label="Instagram" class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" rel="noopener" target="_blank" title="Instagram"></a>
                        <span class="social-label">Instagram</span>
                    </li>
                    <li>
                        <a aria-label="GitHub" class="fa fa-github" href="https://github.com/djeada" title="GitHub"></a>
                        <span class="social-label">GitHub</span>
                    </li>
                </ul>
                <img alt="" aria-hidden="true" class="footer-mark" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
        </div>
        <div class="footer-bottom">
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="/app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>