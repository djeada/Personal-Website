<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Greedy algorithms</title>
    <meta content="Greedy algorithms build a solution one step at a time." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper"><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: September 03, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: üá∫üá∏</i></p>
            <h2 id="greedy-algorithms">Greedy algorithms</h2>
            <p>Greedy algorithms build a solution one step at a time. At each step, grab the option that looks best <em>right now</em> by some simple rule (highest value, earliest finish, shortest length, etc.). Keep it if it doesn‚Äôt break the rules of the problem.</p>
            <ol>
                <li>Sort by your rule (the ‚Äúkey‚Äù).</li>
                <li>Scan items in that order.</li>
                <li>If adding this item keeps the partial answer valid, keep it.</li>
                <li>Otherwise skip it.</li>
            </ol>
            <p>Picking the best ‚Äúnow‚Äù doesn‚Äôt obviously give the best ‚Äúoverall.‚Äù The real work is showing that these local choices still lead to a globally best answer.</p>
            <p><strong>Two proof tricks you‚Äôll see a lot:</strong></p>
            <ul>
                <li><em>Exchange argument.</em> Take any optimal solution that disagrees with greedy at the first point. Show you can ‚Äúswap in‚Äù the greedy choice there without making the solution worse or breaking feasibility. Do this repeatedly and you morph some optimal solution into the greedy one‚Äîso greedy must be optimal.</li>
                <li><em>Loop invariant.</em> Write down a sentence that‚Äôs true after every step of the scan (e.g., ‚Äúthe current set is feasible and as good as any other set built from the items we‚Äôve seen‚Äù). Prove it stays true as you process the next item; at the end, that sentence implies optimality.</li>
            </ul>
            <p><em>Picture it like this:</em></p>
            <p>
            <div>
                <pre><code class="language-shell">position ‚Üí   1    2    3    4    5
greedy:     [‚úì]  [‚úó]  [‚úì]  [‚úì]  [‚úó]
some optimal:
             ‚úì    ‚úì    ‚úó    ?    ?
First mismatch at 3 ‚Üí swap in greedy‚Äôs pick without harm.
Repeat until both rows match ‚Üí greedy is optimal.</code></pre>
            </div>
            </p>
            <p><strong>Where greedy shines automatically: matroids (nice constraint systems).</strong>
                There‚Äôs a tidy setting where greedy is <em>always</em> right (for nonnegative weights): when your ‚Äúwhat‚Äôs allowed‚Äù rules form a <strong>matroid</strong>. You don‚Äôt need the symbols‚Äîjust the vibe:</p>
            <ol>
                <li><strong>You can start from empty.</strong></li>
                <li><strong>Throwing things out never hurts.</strong> If a set is allowed, any subset is allowed.</li>
                <li><strong>Smooth growth (augmentation).</strong> If one allowed set is smaller than another, you can always add <em>something</em> from the bigger one to the smaller and stay allowed.</li>
            </ol>
            <p>That third rule prevents dead ends and is exactly what exchange arguments rely on. In matroids, the simple ‚Äúsort by weight and take what fits‚Äù greedy is guaranteed optimal. Outside matroids, greedy can still work‚Äîbut you must justify it for the specific problem using exchange/invariants.</p>
            <h3 id="reachability-on-a-line">Reachability on a line</h3>
            <ul>
                <li>You stand at square $0$ on squares $0,1,\ldots,n-1$.</li>
                <li>Each square $i$ has a jump power $a[i]$. From $i$ you may land on any of $i+1, i+2, \dots, i+a[i]$.</li>
                <li>Goal: decide if you can reach $n-1$; if not, report the furthest reachable square.</li>
            </ul>
            <p><strong>Example</strong></p>
            <p>Input: $a=[3,1,0,0,4,1]$, so $n=6$ (squares $0..5$).</p>
            <p>
            <div>
                <pre><code class="language-shell">indices:  0   1   2   3   4   5
a[i]   :  3   1   0   0   4   1
reach  :  ^ start at 0</code></pre>
            </div>
            </p>
            <p>From any $i$, the allowed landings are a range:</p>
            <p>
            <div>
                <pre><code class="language-shell">i=0 (a[0]=3): 1..3
i=1 (a[1]=1): 2
i=2 (a[2]=0): ‚Äî
i=3 (a[3]=0): ‚Äî
i=4 (a[4]=4): 5..8 (board ends at 5)</code></pre>
            </div>
            </p>
            <p><strong>Baseline idea</strong></p>
            <p>‚ÄúPaint everything reachable, one wave at a time.‚Äù</p>
            <ol>
                <li>Start with ${0}$ reachable.</li>
                <li>For each already-reachable $i$, add all $i+1..i+a[i]$.</li>
                <li>Stop when nothing new appears.</li>
            </ol>
            <p><em>Walkthrough:</em></p>
            <p>
            <div>
                <pre><code class="language-shell">start:   reachable = {0}
from 0:  add {1,2,3}     ‚Üí reachable = {0,1,2,3}
from 1:  add {2}         ‚Üí no change
from 2:  add {}          ‚Üí a[2]=0
from 3:  add {}          ‚Üí a[3]=0
stop:    no new squares  ‚Üí furthest = 3; last (5) unreachable</code></pre>
            </div>
            </p>
            <p>Correct, but can reprocess many squares.</p>
            <p><strong>One-pass trick</strong></p>
            <p>Carry one number while scanning left‚Üíright: the furthest frontier $F$ seen so far.</p>
            <p>Rules:</p>
            <ul>
                <li>If you are at $i$ with $i&gt;F$, you hit a gap ‚Üí stuck forever.</li>
                <li>Otherwise, extend $F \leftarrow \max(F, i+a[i])$ and continue.</li>
            </ul>
            <p>At the end:</p>
            <ul>
                <li>Can reach last iff $F \ge n-1$.</li>
                <li>Furthest reachable square is $F$ (capped by $n-1$).</li>
            </ul>
            <p><em>Pseudocode</em></p>
            <p>
            <div>
                <pre><code class="language-shell">F = 0
for i in 0..n-1:
    if i &gt; F: break
    F = max(F, i + a[i])

can_reach_last = (F &gt;= n-1)
furthest = min(F, n-1)</code></pre>
            </div>
            </p>
            <p>Why this is safe (one line): $F$ always equals ‚Äúbest jump end discovered from any truly-reachable square $\le i$,‚Äù and never decreases; if $i&gt;F$, no earlier jump can help because its effect was already folded into $F$.</p>
            <p><em>Walkthrough:</em></p>
            <p>We draw the frontier as a bracket reaching to $F$.</p>
            <p>Step $i=0$ (inside frontier since $0\le F$); update $F=\max(0,0+3)=3$.</p>
            <p>
            <div>
                <pre><code class="language-shell">indices:  0   1   2   3   4   5
          [===============F]
          0   1   2   3
F=3</code></pre>
            </div>
            </p>
            <p>Step $i=1$: still $i\le F$. Update $F=\max(3,1+1)=3$ (no change).
                Step $i=2$: $F=\max(3,2+0)=3$ (no change).
                Step $i=3$: $F=\max(3,3+0)=3$ (no change).</p>
            <p>Now $i=4$ but $4&gt;F(=3)$ ‚Üí gap ‚Üí stuck.</p>
            <p>
            <div>
                <pre><code class="language-shell">indices:  0   1   2   3   4   5
          [===============F]   x  (i=4 is outside)
F=3</code></pre>
            </div>
            </p>
            <p>Final: $F=3$. Since $F &lt;n-1=5$, last is unreachable; furthest reachable square is $3$.</p>
            <p>Complexity: time $O(n)$, space $O(1)$.</p>
            <h3 id="minimum-spanning-trees">Minimum spanning trees</h3>
            <p>You‚Äôve got a connected weighted graph and you want the cheapest way to connect <strong>all</strong> its vertices without any cycles‚Äîthat‚Äôs a minimum spanning tree (MST). Think ‚Äúone network of cables that touches every building, with the total cost as small as possible.‚Äù</p>
            <p><strong>Example inputs and outputs</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">V = {A,B,C,D,E}

Edges (u-v:w):
A-B:1  A-C:5  A-E:9
B-C:4  B-D:2  B-E:7
C-D:6  C-E:3
D-E:8</code></pre>
            </div>
            </p>
            <p>A correct MST for this graph is:</p>
            <p>$$
                {A‚Äâ‚Å£‚àí‚Äâ‚Å£B(1),¬†B‚Äâ‚Å£‚àí‚Äâ‚Å£D(2),¬†C‚Äâ‚Å£‚àí‚Äâ‚Å£E(3),¬†B‚Äâ‚Å£‚àí‚Äâ‚Å£C(4)}
                $$</p>
            <p>Total weight $=1+2+3+4=10$.</p>
            <p>You can‚Äôt do better: any cheaper set of 4 edges would either miss a vertex or create a cycle.</p>
            <p><em>Baseline</em></p>
            <p>Enumerate every spanning tree and pick the one with the smallest total weight. That‚Äôs conceptually simple‚Äî‚Äútry all combinations of $n-1$ edges that connect everything and have no cycles‚Äù‚Äîbut it explodes combinatorially. Even medium graphs have an astronomical number of spanning trees, so this approach is only good as a thought experiment.</p>
            <p><em>How it works</em></p>
            <p>Both fast methods rely on two facts:</p>
            <ul>
                <li><strong>Cut rule (safe to add)</strong> - for any cut $(S, V\setminus S)$, the cheapest edge that crosses the cut appears in some MST. Intuition: if your current partial connection is on one side, the cheapest bridge to the other side is never a bad idea.</li>
                <li><strong>Cycle rule (safe to skip)</strong> - in any cycle, the most expensive edge is never in an MST. Intuition: if you already have a loop, drop the priciest link and you‚Äôll still be connected but strictly cheaper.</li>
            </ul>
            <h4 id="kruskal-s-method">Kruskal‚Äôs method</h4>
            <p><strong>Example inputs and outputs</strong></p>
            <p>Use the same graph as above. A valid MST is</p>
            <p>$$
                {A!-!B(1), B!-!D(2), C!-!E(3), B!-!C(4)}\quad\Rightarrow\quad \text{total} = 10
                $$</p>
            <p><strong>How it works</strong></p>
            <p>Sort edges from lightest to heaviest; walk down that list and keep an edge if it connects two <strong>different</strong> components. Stop when you have $n-1$ edges.</p>
            <p>Sorted edges by weight:</p>
            <p>
            <div>
                <pre><code class="language-shell">1: A-B
2: B-D
3: C-E
4: B-C
5: A-C
6: C-D
7: B-E
8: D-E
9: A-E</code></pre>
            </div>
            </p>
            <p>We‚Äôll keep a running view of the components; initially each vertex is alone.</p>
            <p>
            <div>
                <pre><code class="language-shell">start:   {A} {B} {C} {D} {E}

take 1:  A-B(1)   ‚Üí {AB} {C} {D} {E}
take 2:  B-D(2)   ‚Üí {ABD} {C} {E}
take 3:  C-E(3)   ‚Üí {ABD} {CE}
take 4:  B-C(4)   ‚Üí {ABCDE}   ‚Üê all connected (|V|-1 edges) ‚Üí stop

kept: A-B(1), B-D(2), C-E(3), B-C(4)  ‚Üí total = 10</code></pre>
            </div>
            </p>
            <ul>
                <li>Edges kept: $A!-!B(1), B!-!D(2), C!-!E(3), B!-!C(4)$.</li>
                <li>Total $=10$. Every later edge would create a cycle and is skipped by the cycle rule.</li>
            </ul>
            <p>Kruskal pseudocode</p>
            <p>
            <div>
                <pre><code class="language-python">MST = ‚àÖ
make_set(v) for v in V
for (w,u,v) in edges sorted by w:
    if find(u) != find(v):
        MST.add((u,v,w))
        union(u,v)
        if |MST| == |V|-1: break</code></pre>
            </div>
            </p>
            <p>Complexity</p>
            <ul>
                <li>Time: $O(E \log E)$ to sort edges + near-constant $\alpha(V)$ for DSU unions; often written $O(E \log V)$ since $E\le V^2$.</li>
                <li>Space: $O(V)$ for disjoint-set structure.</li>
            </ul>
            <h4 id="prim-s-method">Prim's method</h4>
            <p><strong>Example inputs and outputs</strong></p>
            <p>Same graph and target: produce any MST of total weight $10$.</p>
            <p><strong>How it works</strong></p>
            <p>Start from any vertex; repeatedly add the lightest edge that leaves the current tree to bring in a new vertex. Stop when all vertices are in.</p>
            <p>Let‚Äôs start from $A$. The ‚Äútree‚Äù grows one cheapest boundary edge at a time.</p>
            <p>
            <div>
                <pre><code class="language-shell">step 0:
Tree = {A}
Boundary = { A-B(1), A-C(5), A-E(9) }

take A-B(1)
Tree = {A,B}
Boundary = { B-D(2), B-C(4), B-E(7), A-C(5), A-E(9) }

take B-D(2)
Tree = {A,B,D}
Boundary = { B-C(4), A-C(5), D-C(6), B-E(7), D-E(8), A-E(9) }

take B-C(4)
Tree = {A,B,C,D}
Boundary = { C-E(3), A-E(9), B-E(7), D-E(8) }

take C-E(3)
Tree = {A,B,C,D,E}  ‚Üí done

kept: A-B(1), B-D(2), B-C(4), C-E(3) ‚Üí total = 10</code></pre>
            </div>
            </p>
            <p>Edges chosen: exactly the same four as Kruskal, total $=10$.</p>
            <p>Why did step 4 grab a weight-3 edge after we already took a 4? Because earlier that 3 wasn‚Äôt <strong>available</strong>‚Äîit didn‚Äôt cross from the tree to the outside until $C$ joined the tree. Prim never regrets earlier picks because of the cut rule: at each moment it adds the cheapest bridge from ‚Äúinside‚Äù to ‚Äúoutside,‚Äù and that‚Äôs always safe.</p>
            <p>Prim pseudocode (binary heap)</p>
            <p>
            <div>
                <pre><code class="language-python">pick any root r
Tree = {r}
push all edges (r‚Üív,w) into heap
while |Tree| &lt; |V|:
    pop (w,u‚Üív) with minimum w where v ‚àâ Tree
    add v to Tree; record edge (u,v,w) in MST
    push all edges (v‚Üíx,wvx) with x ‚àâ Tree</code></pre>
            </div>
            </p>
            <p>Complexity</p>
            <ul>
                <li>Time: $O(E \log V)$ with a binary heap and adjacency lists; $O(E + V\log V)$ with a Fibonacci heap.</li>
                <li>Space: $O(V)$ for keys/parents and visited set.</li>
            </ul>
            <h3 id="shortest-paths-with-non-negative-weights-dijkstra-">Shortest paths with non-negative weights (Dijkstra)</h3>
            <p>Goal: from start $s$, compute cheapest costs $d(\cdot)$ to every node (and routes if you keep parents).</p>
            <p>Non-negative edges only; that‚Äôs what makes the greedy step safe.</p>
            <p>Example</p>
            <p>
            <div>
                <pre><code class="language-shell">Nodes: A B C D E   (start s=A)

Edges (undirected):
A-B:2  A-C:5
B-C:1  B-D:2  B-E:7
C-D:3  C-E:1
D-E:2</code></pre>
            </div>
            </p>
            <p>Correct answers from A: $d(A)=0, d(B)=2, d(C)=3, d(D)=4, d(E)=4$.</p>
            <p><em>Baseline</em> </p>
            <p>Repeat relaxations $|V|-1$ rounds (Bellman‚ÄìFord-style).</p>
            <p>Work $\approx |V|\cdot|E|$. Handles negatives; we don‚Äôt need that here.</p>
            <p>Fast method (Dijkstra): ‚Äúsettle the smallest label‚Äù</p>
            <ol>
                <li>Initialize distance labels: set $d(s)=0$, and $d(x)=\infty$ for all other nodes.</li>
                <li>Initialize parent pointers $\pi(\cdot)$.</li>
                <li>Initialize the settled set $S=\emptyset$.</li>
                <li>Initialize the unsettled set as $V\setminus S$.</li>
                <li>Select the unsettled node $u$ with the smallest distance label $d(u)$.</li>
                <li>Move node $u$ from the unsettled set into the settled set.</li>
                <li>Update each neighbor $v$ of $u$ by assigning $d(v) \leftarrow \min\bigl(d(v), d(u) + w(u,v)\bigr)$.</li>
                <li>If the update in step 7 improves $d(v)$, then set $\pi(v) \leftarrow u$.</li>
                <li>Repeat from step 5 until all nodes are settled or no reachable unsettled nodes remain.</li>
                <li>Justification of correctness: with non-negative edge weights, any path reaching an unsettled node must have length at least $d(u)$ plus a non-negative exit edge, so the chosen $d(u)$ is final and cannot later be decreased.</li>
            </ol>
            <p>Pseudocode (binary heap)</p>
            <p>
            <div>
                <pre><code class="language-shell">for v in V: d[v]=‚àû; œÄ[v]=nil
d[s]=0
push (0,s) into min-heap H
S = ‚àÖ
while H not empty:
    (du,u) = pop-min(H)
    if u in S: continue         # ignore stale heap entries
    S.add(u)
    for (u,v,w) in adj[u]:
        if d[v] &gt; d[u] + w:
            d[v] = d[u] + w
            œÄ[v] = u
            push (d[v], v) into H</code></pre>
            </div>
            </p>
            <p>Time $O((|V|+|E|)\log|V|)$; space $O(|V|)$.</p>
            <p><em>Walkthrough</em></p>
            <p>Legend: ‚ÄúS‚Äù = settled, ‚ÄúœÄ[x]‚Äù = parent of $x$. Ties break arbitrarily.</p>
            <p>Round 0 (init)</p>
            <p>
            <div>
                <pre><code class="language-shell">S = ‚àÖ
d:  A:0  B:‚àû  C:‚àû  D:‚àû  E:‚àû
œÄ:  A:-  B:-  C:-  D:-  E:-</code></pre>
            </div>
            </p>
            <p>Round 1 ‚Äî pick min unsettled ‚Üí A(0); relax neighbors</p>
            <p>
            <div>
                <pre><code class="language-shell">S = {A}
relax A-B (2):  d[B]=2  œÄ[B]=A
relax A-C (5):  d[C]=5  œÄ[C]=A
d:  A:0S  B:2  C:5  D:‚àû  E:‚àû
œÄ:  A:-   B:A  C:A  D:-  E:-</code></pre>
            </div>
            </p>
            <p>Round 2 ‚Äî pick B(2); relax</p>
            <p>
            <div>
                <pre><code class="language-shell">S = {A,B}
B‚ÜíC (1): 2+1=3 &lt;5 ‚Üí d[C]=3  œÄ[C]=B
B‚ÜíD (2): 2+2=4     ‚Üí d[D]=4  œÄ[D]=B
B‚ÜíE (7): 2+7=9     ‚Üí d[E]=9  œÄ[E]=B
d:  A:0S  B:2S  C:3  D:4  E:9
œÄ:  A:-   B:A   C:B  D:B  E:B</code></pre>
            </div>
            </p>
            <p>Round 3 ‚Äî pick C(3); relax</p>
            <p>
            <div>
                <pre><code class="language-shell">S = {A,B,C}
C‚ÜíD (3): 3+3=6  (no improv; keep 4)
C‚ÜíE (1): 3+1=4 &lt;9 ‚Üí d[E]=4  œÄ[E]=C
d:  A:0S  B:2S  C:3S  D:4  E:4
œÄ:  A:-   B:A   C:B   D:B  E:C</code></pre>
            </div>
            </p>
            <p>Round 4 ‚Äî pick D(4); relax</p>
            <p>
            <div>
                <pre><code class="language-shell">S = {A,B,C,D}
D‚ÜíE (2): 4+2=6 (no improv; keep 4)
d:  A:0S  B:2S  C:3S  D:4S  E:4</code></pre>
            </div>
            </p>
            <p>Round 5 ‚Äî pick E(4); done</p>
            <p>
            <div>
                <pre><code class="language-shell">S = {A,B,C,D,E}  (all settled)
Final d: A:0  B:2  C:3  D:4  E:4
Parents œÄ: B‚ÜêA, C‚ÜêB, D‚ÜêB, E‚ÜêC</code></pre>
            </div>
            </p>
            <p>Reconstruct routes by following parents backward:</p>
            <ul>
                <li>$B$: $A\to B$</li>
                <li>$C$: $A\to B\to C$</li>
                <li>$D$: $A\to B\to D$</li>
                <li>$E$: $A\to B\to C\to E$</li>
            </ul>
            <p>Complexity</p>
            <ul>
                <li>Time: $O((V+E)\log V)$ with a binary heap (often written $O(E \log V)$ when $E\ge V$).</li>
                <li>Space: $O(V)$ for distances, parent pointers, and heap entries.</li>
            </ul>
            <h3 id="maximum-contiguous-sum">Maximum contiguous sum</h3>
            <p>You‚Äôre given a list of numbers laid out in a line. You may pick one <strong>contiguous</strong> block, and you want that block‚Äôs sum to be as large as possible.</p>
            <p><strong>Example inputs and outputs</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">x = [ 2, -3, 4, -1, 2, -5, 3 ]
best block = [ 4, -1, 2 ]  ‚Üí sum = 5</code></pre>
            </div>
            </p>
            <p>So the correct output is ‚Äúmaximum sum $=5$‚Äù and one optimal segment is positions $3$ through $5$ (1-based).</p>
            <p><em>Baseline</em></p>
            <p>Try every possible block and keep the best total. To sum any block $i..j$ quickly, precompute <strong>prefix sums</strong> $S_0=0$ and $S_j=\sum_{k=1}^j x_k$. Then</p>
            <p>$$
                \sum_{k=i}^j x_k = S_j - S_{i-1}
                $$</p>
            <p>Loop over all $j$ and all $i\le j$, compute $S_j-S_{i-1}$, and take the maximum. This is easy to reason about and always correct, but it does $O(n^2)$ block checks.</p>
            <p><strong>How it works</strong></p>
            <p>Walk left to right once and carry two simple numbers.</p>
            <ul>
                <li>$S$: the running prefix sum up to the current position.</li>
                <li>$M$: the <strong>smallest</strong> prefix seen so far (to the left of the current position).</li>
            </ul>
            <p>At each step $j$, the best block <strong>ending at</strong> $j$ is ‚Äúcurrent prefix minus the smallest older prefix‚Äù:</p>
            <p>$$
                \text{best ending at j} = S_j - \min_{0\le t \le j} S_t
                $$</p>
            <p>So during the scan:</p>
            <ol>
                <li>Update $S \leftarrow S + x_j$.</li>
                <li>Update the answer with $S - M$.</li>
                <li>Update $M \leftarrow \min(M, S)$.</li>
            </ol>
            <p>This is the whole algorithm. In words: keep the lowest floor you‚Äôve ever seen and measure how high you are above it now. If you dip to a new floor, remember it; if you rise, maybe you‚Äôve set a new record.</p>
            <p>A widely used equivalent form keeps a ‚Äúbest sum ending here‚Äù value $E$: set $E \leftarrow \max(x_j,; E+x_j)$ and track a global maximum. It‚Äôs the same idea written incrementally: if the running sum ever hurts you, you ‚Äúreset‚Äù and start fresh at the current element.</p>
            <p><em>Walkthrough</em></p>
            <p>Sequence $x = [2,-3,4,-1,2,-5,3]$.</p>
            <p>Initialize $S=0$, $M=0$, and $\text{best}=-\infty$. Keep the index $t$ where the current $M$ occurred so we can reconstruct the block as $(t+1)..j$.</p>
            <p>
            <div>
                <pre><code class="language-shell">j   x_j   S_j = S+x_j   M (min prefix so far)   S_j - M   best   chosen block
--------------------------------------------------------------------------------
 1    2         2                0                  2        2     (1..1)
       update: M = min(0,2) = 0

 2   -3        -1                0                 -1        2     (still 1..1)
       update: M = min(0,-1) = -1   [new floor at t=2]

 3    4         3               -1                  4        4     (3..3)
       update: M = min(-1,3) = -1

 4   -1         2               -1                  3        4     (still 3..3)
       update: M = min(-1,2) = -1

 5    2         4               -1                  5        5     (3..5)  ‚úì
       update: M = min(-1,4) = -1

 6   -5        -1               -1                  0        5     (still 3..5)
       update: M = min(-1,-1) = -1

 7    3         2               -1                  3        5     (still 3..5)
       update: M = min(-1,2) = -1</code></pre>
            </div>
            </p>
            <p>Final answer: maximum sum $=5$, achieved by indices $3..5$ (that‚Äôs $[4,-1,2]$).</p>
            <p>You can picture $S_j$ as a hilly skyline and $M$ as the lowest ground you‚Äôve touched. The best block is the tallest vertical gap between the skyline and any earlier ground level.</p>
            <p>
            <div>
                <pre><code class="language-shell">prefix S: 0 ‚Üí 2 ‚Üí -1 ‚Üí 3 ‚Üí 2 ‚Üí 4 ‚Üí -1 ‚Üí 2
ground M: 0   0   -1   -1  -1  -1   -1  -1
gap S-M:  0   2    0    4   3   5    0   3
                                ^ peak gap = 5 here</code></pre>
            </div>
            </p>
            <p>Pseudocode (prefix-floor form):</p>
            <p>
            <div>
                <pre><code class="language-shell">best = -‚àû          # or x[0] if you require non-empty
S = 0
M = 0              # 0 makes empty prefix available
t = 0              # index where M happened (0 means before first element)
best_i = best_j = None

for j in 1..n:
    S = S + x[j]
    if S - M &gt; best:
        best = S - M
        best_i = t + 1
        best_j = j
    if S &lt; M:
        M = S
        t = j

return best, (best_i, best_j)</code></pre>
            </div>
            </p>
            <p><em>Edge cases</em></p>
            <p>When all numbers are negative, the best block is the <strong>least negative single element</strong>. The scan handles this automatically because $M$ keeps dropping with every step, so the maximum of $S_j-M$ happens when you take just the largest entry.</p>
            <p>Empty-block conventions matter. If you define the answer to be strictly nonempty, initialize $\text{best}$ with $x_1$ and $E=x_1$ in the incremental form; if you allow empty blocks with sum $0$, initialize $\text{best}=0$ and $M=0$. Either way, the one-pass logic doesn‚Äôt change.</p>
            <p><em>Complexity</em></p>
            <ul>
                <li>Time: $O(n)$</li>
                <li>Space: $O(1)$</li>
            </ul>
            <h3 id="scheduling-themes">Scheduling themes</h3>
            <p>Two classics:</p>
            <ul>
                <li>Pick as many non-overlapping intervals as possible (one room, max meetings).</li>
                <li>Keep maximum lateness small when jobs have deadlines.</li>
            </ul>
            <p>They‚Äôre both greedy‚Äîand both easy to run by hand.</p>
            <p>Imagine you have time intervals on a single line, and you can keep an interval only if it doesn‚Äôt overlap anything you already kept. The aim is to keep as many as possible.</p>
            <p><strong>Example inputs and outputs</strong></p>
            <p>Intervals (start, finish):</p>
            <p>
            <div>
                <pre><code class="language-shell">(1,3) (2,5) (4,7) (6,9) (8,10) (9,11)</code></pre>
            </div>
            </p>
            <p>A best answer keeps four intervals, for instance $(1,3),(4,7),(8,10),(10,11)$.</p>
            <p><strong>Baseline (slow)</strong></p>
            <p>Try all subsets and keep the largest that has no overlaps. That‚Äôs conceptually simple and always correct, but it‚Äôs exponential in the number of intervals, which is a non-starter for anything but tiny inputs.</p>
            <p><strong>Greedy rule:</strong> </p>
            <p>Sort by finish time and take what fits.</p>
            <ul>
                <li>Scan from earliest finisher to latest.</li>
                <li>Keep $(s,e)$ iff $s \ge \text{last end}$; then set $\text{last end}\leftarrow e$.</li>
            </ul>
            <p>Sorted by finish:</p>
            <p>$$
                (1,3), (2,5), (4,7), (6,9), (8,10), (9,11)
                $$</p>
            <p>Run the scan and track the end of the last kept interval.</p>
            <p>
            <div>
                <pre><code class="language-shell">last_end = -‚àû
(1,3):  1 ‚â• -‚àû ‚Üí keep ‚Üí last_end = 3
(2,5):  2 &lt; 3  ‚Üí skip
(4,7):  4 ‚â• 3  ‚Üí keep ‚Üí last_end = 7
(6,9):  6 &lt; 7  ‚Üí skip
(8,10): 8 ‚â• 7  ‚Üí keep ‚Üí last_end = 10
(9,11): 9 &lt; 10 ‚Üí skip</code></pre>
            </div>
            </p>
            <p>Kept intervals: $(1,3),(4,7),(8,10)$. If we allow a meeting that starts exactly at $10$, we can also keep $(10,11)$ if it exists. Four kept, which matches the claim.</p>
            <p>A tiny picture helps the ‚Äúfinish early‚Äù idea feel natural:</p>
            <p>
            <div>
                <pre><code class="language-shell">time ‚Üí
kept:  [1‚îÄ‚îÄ‚îÄ‚îÄ3) [4‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ7)  [8‚îÄ‚îÄ‚îÄ‚îÄ10)
skip:      [2‚îÄ‚îÄ‚îÄ‚îÄ5)  [6‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ9)[9‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ11)
ending earlier leaves more open space to the right</code></pre>
            </div>
            </p>
            <p>Why this works: at the first place an optimal schedule would choose a later-finishing interval, swapping in the earlier finisher cannot reduce what still fits afterward, so you can push the optimal schedule to match greedy without losing size.</p>
            <p>Handy pseudocode</p>
            <p>
            <div>
                <pre><code class="language-python"># Interval scheduling (max cardinality)
sort intervals by end time
last_end = -‚àû
keep = []
for (s,e) in intervals:
    if s &gt;= last_end:
        keep.append((s,e))
        last_end = e</code></pre>
            </div>
            </p>
            <p><em>Complexity</em></p>
            <ul>
                <li>Time: $O(n \log n)$ to sort by finishing time; $O(n)$ scan.</li>
                <li>Space: $O(1)$ (beyond input storage).</li>
            </ul>
            <h3 id="minimize-the-maximum-lateness">Minimize the maximum lateness</h3>
            <p>Now think of $n$ jobs, all taking the same amount of time (say one unit). Each job $i$ has a deadline $d_i$. When you run them in some order, the completion time of the $k$-th job is $C_k=k$ (since each takes one unit), and its lateness is</p>
            <p>$$
                L_i = C_i - d_i.
                $$</p>
            <p>Negative values mean you finished early; the quantity to control is the worst lateness $L_{\max}=\max_i L_i$. The goal is to order the jobs so $L_{\max}$ is as small as possible.</p>
            <p><strong>Example inputs and outputs</strong></p>
            <p>Jobs and deadlines:</p>
            <ul>
                <li>$J_1: d_1=3$</li>
                <li>$J_2: d_2=1$</li>
                <li>$J_3: d_3=4$</li>
                <li>$J_4: d_4=2$</li>
            </ul>
            <p>An optimal schedule is $J_2,J_4, J_1, J_3$. The maximum lateness there is $0$.</p>
            <p><strong>Baseline (slow)</strong></p>
            <p>Try all $n!$ orders, compute every job‚Äôs completion time and lateness, and take the order with the smallest $L_{\max}$. This explodes even for modest $n$.</p>
            <p><strong>Greedy rule</strong></p>
            <p>Order jobs by nondecreasing deadlines (earliest due date first, often called EDD). Fixing any ‚Äúinversion‚Äù where a later deadline comes before an earlier one can only help the maximum lateness, so sorting by deadlines is safe.</p>
            <p>Deadlines in increasing order:</p>
            <p>$$
                J_2(d=1), J_4(d=2), J_1(d=3), J_3(d=4)
                $$</p>
            <p>Run them one by one and compute completion times and lateness.</p>
            <p>
            <div>
                <pre><code class="language-shell">slot 1: J2 finishes at C=1 ‚Üí L2 = 1 - d2(=1) = 0
slot 2: J4 finishes at C=2 ‚Üí L4 = 2 - d4(=2) = 0
slot 3: J1 finishes at C=3 ‚Üí L1 = 3 - d1(=3) = 0
slot 4: J3 finishes at C=4 ‚Üí L3 = 4 - d3(=4) = 0
L_max = 0</code></pre>
            </div>
            </p>
            <p>If you scramble the order, the worst lateness jumps. For example, $J_1,J_2,J_3,J_4$ gives</p>
            <p>
            <div>
                <pre><code class="language-shell">slot 1: J1 ‚Üí L1 = 1 - 3 = -2
slot 2: J2 ‚Üí L2 = 2 - 1 = 1
slot 3: J3 ‚Üí L3 = 3 - 4 = -1
slot 4: J4 ‚Üí L4 = 4 - 2 = 2
L_max = 2   (worse)</code></pre>
            </div>
            </p>
            <p>A quick timeline sketch shows how EDD keeps you out of trouble:</p>
            <p>
            <div>
                <pre><code class="language-shell">time ‚Üí 1   2   3   4
EDD:   [J2][J4][J1][J3]   deadlines: 1   2   3   4
late?    0    0    0    0  ‚Üí max lateness 0</code></pre>
            </div>
            </p>
            <p>Why this works: if two adjacent jobs are out of deadline order, swapping them never increases any completion time relative to its own deadline, and strictly improves at least one, so repeatedly fixing these inversions leads to the sorted-by-deadline order with no worse maximum lateness.</p>
            <p>Pseudocode</p>
            <p>
            <div>
                <pre><code class="language-shell"># Minimize L_max (EDD)
sort jobs by increasing deadline d_j
t = 0; Lmax = -‚àû
for job j in order:
    t += p_j           # completion time C_j
    L = t - d_j
    Lmax = max(Lmax, L)
return order, Lmax</code></pre>
            </div>
            </p>
            <p><em>Complexity</em></p>
            <ul>
                <li>Time: $O(n \log n)$ to sort by deadlines; $O(n)$ evaluation.</li>
                <li>Space: $O(1)$.</li>
            </ul>
            <h3 id="huffman-coding">Huffman coding</h3>
            <p>You have symbols that occur with known frequencies $f_i&gt;0$ and $\sum_i f_i=1$ (if you start with counts, first normalize by their total). The goal is to assign each symbol a binary codeword so that no codeword is a prefix of another (a <strong>prefix code</strong>, i.e., uniquely decodable without separators), and the average length</p>
            <p>$$
                \mathbb{E}[L]=\sum_i f_i\,L_i
                $$</p>
            <p>is as small as possible. Prefix codes correspond exactly to <strong>full binary trees</strong> (every internal node has two children) whose leaves are the symbols and whose leaf depths equal the codeword lengths $L_i$. The <strong>Kraft inequality</strong> $\sum_i 2^{-L_i}\le 1$ characterizes feasibility; equality holds for full trees (so an optimal prefix code ‚Äúfills‚Äù the inequality).</p>
            <p><strong>Example inputs and outputs</strong></p>
            <p>Frequencies:</p>
            <p>$$
                A:0.40,\quad B:0.20,\quad C:0.20,\quad D:0.10,\quad E:0.10.
                $$</p>
            <p>A valid optimal answer will be a prefix code with expected length as small as possible. We will compute the exact minimum and one optimal set of lengths $L_A,\dots,L_E$, plus a concrete codebook. (There can be multiple optimal codebooks when there are ties in frequencies; their <strong>lengths</strong> agree, though the exact bitstrings may differ.)</p>
            <p><strong>Baseline</strong></p>
            <p>One conceptual baseline is to enumerate all full binary trees with five labeled leaves and pick the one minimizing $\sum f_i,L_i$. That is correct but explodes combinatorially as the number of symbols grows. A simpler but usually suboptimal baseline is to give every symbol the same length $\lceil \log_2 5\rceil=3$. That fixed-length code has $\mathbb{E}[L]=3$.</p>
            <p><strong>Greedy Approach</strong></p>
            <p>Huffman‚Äôs rule repeats one tiny step: always merge the two least frequent items. When you merge two ‚Äúsymbols‚Äù with weights $p$ and $q$, you create a parent of weight $p+q$. <strong>Why does this change the objective by exactly $p+q$?</strong> Every leaf in those two subtrees increases its depth (and thus its code length) by $1$, so the total increase in $\sum f_i L_i$ is $\sum_{\ell\in\text{subtrees}} f_\ell\cdot 1=(p+q)$ by definition of $p$ and $q$. Summing over all merges yields the final cost:</p>
            <p>$$
                \mathbb{E}[L]=\sum_{\text{merges}} (p+q)=\sum_{\text{internal nodes}} \text{weight}.
                $$</p>
            <p><strong>Why is the greedy choice optimal?</strong> In an optimal tree the two deepest leaves must be siblings; if not, pairing them to be siblings never increases any other depth and strictly reduces cost whenever a heavier symbol is deeper than a lighter one (an <strong>exchange argument</strong>: swapping depths changes the cost by $f_{\text{heavy}}-f_{\text{light}}&gt;0$ in our favor). Collapsing those siblings into a single pseudo-symbol reduces the problem size without changing optimality, so induction finishes the proof. (Ties can be broken arbitrarily; all tie-breaks achieve the same minimum $\mathbb{E}[L]$.)</p>
            <p>Start with the multiset ${0.40, 0.20, 0.20, 0.10, 0.10}$. At each line, merge the two smallest weights and add their sum to the running cost.</p>
            <p>
            <div>
                <pre><code class="language-shell">1) merge 0.10 + 0.10 ‚Üí 0.20        cost += 0.20   (total 0.20)
   multiset becomes {0.20, 0.20, 0.20, 0.40}

2) merge 0.20 + 0.20 ‚Üí 0.40        cost += 0.40   (total 0.60)
   multiset becomes {0.20, 0.40, 0.40}

3) merge 0.20 + 0.40 ‚Üí 0.60        cost += 0.60   (total 1.20)
   multiset becomes {0.40, 0.60}

4) merge 0.40 + 0.60 ‚Üí 1.00        cost += 1.00   (total 2.20)
   multiset becomes {1.00}  (done)</code></pre>
            </div>
            </p>
            <p>So the optimal expected length is $\boxed{\mathbb{E}[L]=2.20}$ bits per symbol. This already beats the naive fixed-length baseline $3$. It also matches the information-theoretic bound $H(f)\le \mathbb{E}[L] &lt;H(f)+1$, since the entropy here is $H\approx 2.1219$.</p>
            <p>Now assign actual lengths. Record who merged with whom:</p>
            <ul>
                <li>Step 1 merges $D(0.10)$ and $E(0.10)$ ‚Üí those two become siblings.</li>
                <li>Step 2 merges $B(0.20)$ and $C(0.20)$ ‚Üí those two become siblings.</li>
                <li>Step 3 merges the pair $D!E(0.20)$ with $A(0.40)$.</li>
                <li>Step 4 merges the pair from step 3 with the pair $B!C(0.40)$.</li>
            </ul>
            <p>Depths follow directly (each merge adds one level to its members):</p>
            <p>$$
                L_A=2,\quad L_B=L_C=2,\quad L_D=L_E=3.
                $$</p>
            <p>Check the Kraft sum $3\cdot 2^{-2}+2\cdot 2^{-3}=3/4+1/4=1$ and the cost $0.4\cdot2+0.2\cdot2+0.2\cdot2+0.1\cdot3+0.1\cdot3=2.2$.</p>
            <p>A tidy tree (weights shown for clarity):</p>
            <p>
            <div>
                <pre><code class="language-shell">[1.00]
+--0--&gt; [0.60]
|       +--0--&gt; A(0.40)
|       <code>--1--&gt; [0.20]
|                +--0--&gt; D(0.10)
|                </code>--1--&gt; E(0.10)
<code>--1--&gt; [0.40]
        +--0--&gt; B(0.20)
        </code>--1--&gt; C(0.20)</code></pre>
            </div>
            </p>
            <p>One concrete codebook arises by reading left edges as 0 and right edges as 1 (the left/right choice is arbitrary; flipping all bits in a subtree yields an equivalent optimal code):</p>
            <ul>
                <li>$A \mapsto 00$</li>
                <li>$B \mapsto 10$</li>
                <li>$C \mapsto 11$</li>
                <li>$D \mapsto 010$</li>
                <li>$E \mapsto 011$</li>
            </ul>
            <p>You can verify the prefix property immediately and recompute $\mathbb{E}[L]$ from these lengths to get $2.20$ again. (From these lengths you can also construct the <strong>canonical Huffman code</strong>, which orders codewords lexicographically‚Äîuseful for compactly storing the codebook.)</p>
            <p><em>Complexity</em></p>
            <ul>
                <li>Time: $O(k \log k)$ using a min-heap over $k$ symbol frequencies (each of the $k-1$ merges performs two extractions and one insertion).</li>
                <li>Space: $O(k)$ for the heap and $O(k)$ for the resulting tree (plus $O(k)$ for an optional map from symbols to codewords).</li>
            </ul>
        </article-section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#greedy-algorithms">Greedy algorithms</a>
                <ol>
                    <li><a href="#reachability-on-a-line">Reachability on a line</a></li>
                    <li><a href="#minimum-spanning-trees">Minimum spanning trees</a>
                        <ol>
                            <li><a href="#kruskal-s-method">Kruskal‚Äôs method</a></li>
                            <li><a href="#prim-s-method">Prim's method</a></li>
                        </ol>
                    </li>
                    <li><a href="#shortest-paths-with-non-negative-weights-dijkstra-">Shortest paths with non-negative weights (Dijkstra)</a></li>
                    <li><a href="#maximum-contiguous-sum">Maximum contiguous sum</a></li>
                    <li><a href="#scheduling-themes">Scheduling themes</a></li>
                    <li><a href="#minimize-the-maximum-lateness">Minimize the maximum lateness</a></li>
                    <li><a href="#huffman-coding">Huffman coding</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/backtracking.html">Backtracking</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/basic_concepts.html">Basic Concepts</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/brain_teasers.html">Brain Teasers</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/data_structures.html">Data Structures</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/dynamic_programming.html">Dynamic Programming</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/graphs.html">Graphs</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/greedy_algorithms.html">Greedy Algorithms</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/matrices.html">Matrices</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/searching.html">Searching</a></li>
                    <li><a href="https://adamdjellouli.com/articles/algorithms_and_data_structures/sorting.html">Sorting</a></li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If you‚Äôd like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                ¬© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>