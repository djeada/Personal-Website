<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Simulations in Statistical Inference</title>
    <meta content="Statistical inference often involves estimating population parameters and constructing confidence intervals based on sample data." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="../../../index.html">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/courses.html" title="Browse Courses by Adam Djellouli"> Courses </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper"><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: October 31, 2022</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="simulations-in-statistical-inference">Simulations in Statistical Inference</h2>
            <p>Statistical inference often involves estimating population parameters and constructing confidence intervals based on sample data. Traditional methods rely on assumptions about the sampling distribution of estimators, such as normality and known standard errors. However, these assumptions may not hold, especially with small sample sizes or complex estimators. <strong>Simulations</strong>, like the <strong>Monte Carlo method</strong> and <strong>bootstrap techniques</strong>, offer powerful alternatives to traditional inference by using computational methods to approximate sampling distributions and estimate standard errors.</p>
            <h3 id="confidence-intervals-for-the-population-mean">Confidence Intervals for the Population Mean</h3>
            <h4 id="traditional-confidence-interval">Traditional Confidence Interval</h4>
            <p>For a population mean $\mu$, the traditional confidence interval is:</p>
            <p>$$
                \bar{x} \pm z_{\alpha/2} \cdot SE(\bar{x})
                $$</p>
            <p>where:</p>
            <ul>
                <li>$\bar{x}$: Sample mean.</li>
                <li>$z_{\alpha/2}$: Critical value from the standard normal distribution corresponding to the desired confidence level $(1 - \alpha)$.</li>
                <li>$SE(\bar{x})$: Standard error of the sample mean, typically estimated as $\frac{s}{\sqrt{n}}$ when the population standard deviation $\sigma$ is unknown.</li>
            </ul>
            <h4 id="limitations-of-traditional-methods">Limitations of Traditional Methods</h4>
            <ul>
                <li>The <strong>normality assumption</strong> assumes that the sample mean $\bar{x}$ is normally distributed, which may not hold for small sample sizes or non-normal populations.</li>
                <li><strong>Unknown standard error</strong> can be problematic when $SE(\hat{\theta})$ is difficult to compute due to complex estimators or unknown population parameters.</li>
            </ul>
            <h3 id="simulations-in-statistical-inference">Simulations in Statistical Inference</h3>
            <p>Simulations provide a way to estimate the sampling distribution of an estimator $\hat{\theta}$ without relying on strict theoretical assumptions.</p>
            <h3 id="the-monte-carlo-method">The Monte Carlo Method</h3>
            <p>The <strong>Monte Carlo method</strong> uses random sampling from a known distribution to approximate numerical results, particularly for estimating parameters and their variability.</p>
            <h4 id="estimating-an-unknown-parameter-theta-">Estimating an Unknown Parameter $\theta$</h4>
            <ul>
                <li>The <strong>objective</strong> is to estimate a population parameter $\theta$, such as the average height in the U.S.</li>
                <li>The <strong>approach</strong> involves drawing $n$ observations, denoted as $X_1, X_2, \dots, X_n$, from the population.</li>
                <li>To estimate, compute the sample mean <strong>$\hat{\theta} = \bar{X}$</strong>.</li>
                <li>According to the <strong>law of large numbers</strong>, as $n$ increases, $\hat{\theta}$ will converge to the true population parameter $\theta$.</li>
            </ul>
            <h4 id="estimating-the-standard-error-se-hat-theta-">Estimating the Standard Error $SE(\hat{\theta})$</h4>
            <ul>
                <li>The <strong>problem</strong> is that calculating the standard error $SE(\hat{\theta})$ analytically can be complex.</li>
                <li>A <strong>Monte Carlo solution</strong> involves drawing multiple independent samples to estimate $SE(\hat{\theta})$.</li>
                <li><strong>Multiple samples</strong> are drawn, with $B$ independent samples of size $n$ from the population.</li>
                <li>For each sample $b$, <strong>compute estimates</strong> $\hat{\theta}_b$.</li>
                <li>The <strong>standard error</strong> is then estimated using the formula:</li>
            </ul>
            <p>$$
                SE(\hat{\theta}) \approx \sqrt{\frac{1}{B - 1} \sum_{b=1}^{B} (\hat{\theta}_b - \bar{\hat{\theta}})^2}
                $$</p>
            <p>where $\bar{\hat{\theta}} = \frac{1}{B} \sum_{b=1}^{B} \hat{\theta}_b$.</p>
            <h4 id="advantages">Advantages</h4>
            <ul>
                <li>The <strong>flexibility</strong> of this method allows it to be applied to complex estimators where analytical solutions are not feasible.</li>
                <li><strong>Accuracy</strong> improves as the number of simulations $B$ increases.</li>
            </ul>
            <p>Hereâ€™s the improved version with the plot reference included and a better name for it:</p>
            <h3 id="example-estimating-standard-error-using-monte-carlo-simulation">Example: Estimating Standard Error Using Monte Carlo Simulation</h3>
            <p>In this example, we estimate the standard error of the sample mean $\hat{\theta}$ using a Monte Carlo approach. This method involves generating multiple independent samples from a population, calculating the mean $\hat{\theta_b}$ for each sample, and using these means to estimate the standard error.</p>
            <p>Steps:
                - Draw $B$ independent samples of size $n$ from a normal population.
                - Calculate the sample mean $\hat{\theta_b}$ for each sample.
                - Estimate the standard error $SE(\hat{\theta})$ using the formula:</p>
            <p>$$
                SE(\hat{\theta}) \approx \sqrt{\frac{1}{B - 1} \sum_{b = 1}^{B} (\hat{\theta_b} - \bar{\theta})^2}
                $$</p>
            <p>where $\bar{\theta} = \frac{1}{B} \sum_{b = 1}^{B} \hat{\theta_b}$ is the average of all sample means.</p>
            <p>Parameters:</p>
            <ul>
                <li>Population distribution: Normal with mean 100 and standard deviation 15.</li>
                <li>Sample size $n = 30$.</li>
                <li>Number of independent samples $B = 1000$.</li>
            </ul>
            <p>Monte Carlo Simulation:</p>
            <ul>
                <li>Generate $B = 1000$ samples from a normal population with mean $100$ and standard deviation $15$.</li>
                <li>Each sample contains $n = 30$ values.</li>
                <li>For each sample, calculate the mean $\hat{\theta_b}$, and store these means in an array.</li>
            </ul>
            <p>Estimate of Standard Error:
                - Calculate the overall mean of the sample means $\bar{\theta}$.
                - Use the formula for standard error estimation from the sample means.</p>
            <p><img alt="Sample Means Distribution with Monte Carlo Estimated Standard Error" src="https://github.com/user-attachments/assets/53d883d3-1a70-4530-9d09-6d7eab654d33" /></p>
            <p><strong>Estimated Standard Error (Monte Carlo)</strong>: 2.7208</p>
            <h3 id="the-bootstrap-principle">The Bootstrap Principle</h3>
            <ul>
                <li>The <strong>challenge</strong> arises when the population distribution is unknown, and only a single sample is available.</li>
                <li>The <strong>solution</strong> is to use the sample itself to approximate the sampling distribution of $\hat{\theta}$.</li>
            </ul>
            <h4 id="the-plug-in-principle">The Plug-in Principle</h4>
            <ul>
                <li>The <strong>concept</strong> involves replacing the unknown population distribution with the empirical distribution derived from the sample.</li>
                <li>The <strong>justification</strong> is that if the sample is representative, its distribution closely approximates the population.</li>
            </ul>
            <h4 id="bootstrap-procedure">Bootstrap Procedure</h4>
            <ol>
                <li>Start with the <strong>original sample</strong>, denoted as $X = { X_1, X_2, \dots, X_n }$.</li>
                <li>Generate <strong>bootstrap samples</strong> by sampling with replacement from $X$ to create $B$ bootstrap samples $X^{*b}$, each of size $n$.</li>
                <li>For each bootstrap sample $X^{<em>b}$, </em><em>compute bootstrap estimates</em><em> $\hat{\theta}^</em>_b$.</li>
                <li>Finally, estimate the standard error using the formula:</li>
            </ol>
            <p>$$
                SE_{boot}(\hat{\theta}) = \sqrt{\frac{1}{B-1}\sum_{b=1}^{B}\left(\hat{\theta}_b - \bar{\hat{\theta}}\right)^2}
                $$</p>
            <p>with</p>
            <p>$$
                \bar{\hat{\theta}} = \frac{1}{B}\sum_{b=1}^{B}\hat{\theta}_b.
                $$</p>
            <h3 id="bootstrap-confidence-intervals">Bootstrap Confidence Intervals</h3>
            <p>Bootstrapping allows construction of confidence intervals without relying on normality or known standard errors.</p>
            <h4 id="1-normal-approximation-interval">1. Normal Approximation Interval</h4>
            <ul>
                <li>The <strong>assumption</strong> is that the sampling distribution of $\hat{\theta}$ is approximately normal.</li>
                <li>The <strong>interval</strong> is calculated as:</li>
            </ul>
            <p>$$
                [\hat{\theta} - z_{\alpha/2} \cdot SE_{\text{boot}}(\hat{\theta}), \quad \hat{\theta} + z_{\alpha/2} \cdot SE_{\text{boot}}(\hat{\theta})]
                $$</p>
            <p>This approach is appropriate for symmetric distributions and large sample sizes.</p>
            <h4 id="2-bootstrap-percentile-interval">2. Bootstrap Percentile Interval</h4>
            <ul>
                <li>The <strong>concept</strong> of this interval relies on using percentiles from the bootstrap distribution.</li>
                <li>The <strong>interval</strong> is given by:</li>
            </ul>
            <p>$$
                [\hat{\theta}<em>{\alpha/2},\quad \hat{\theta}</em>{1-\alpha/2}]
                $$</p>
            <ul>
                <li>Here, $\hat{\theta}_{(\alpha/2)}$ represents the $100 \times (\alpha/2)$ percentile of $\hat{\theta}*_b$ .</li>
                <li>This method does not assume the distribution is normal.</li>
            </ul>
            <h4 id="3-bootstrap-pivotal-interval">3. Bootstrap Pivotal Interval</h4>
            <ul>
                <li>This method <strong>adjusts for bias</strong> by centering the interval around $\hat{\theta}$.</li>
                <li>The <strong>interval</strong> is calculated as:</li>
            </ul>
            <p>$$[2\hat{\theta} - \hat{\theta}<em>{1-\alpha/2},\quad 2\hat{\theta} - \hat{\theta}</em>{\alpha/2}]$$</p>
            <p>This interval is more accurate for skewed distributions.</p>
            <h3 id="bootstrapping-for-regression">Bootstrapping for Regression</h3>
            <p>Bootstrapping can estimate the variability of regression coefficients when traditional assumptions (like normality of errors) may not hold.</p>
            <h4 id="simple-linear-regression-model">Simple Linear Regression Model</h4>
            <p>$$
                Y_i = a + b X_i + e_i, \quad i = 1, 2 \dots n
                $$</p>
            <ul>
                <li>$Y_i$: Response variable.</li>
                <li>$X_i$: Predictor variable.</li>
                <li>$a$, $b$: Regression coefficients.</li>
                <li>$e_i$: Error terms, assumed to be independent with mean zero.</li>
            </ul>
            <h4 id="residual-resampling">Residual Resampling</h4>
            <ul>
                <li>The first step is to <strong>fit the original model</strong> and obtain estimates for $\hat{a}$ and $\hat{b}$.</li>
                <li>Next, <strong>compute the residuals</strong> as</li>
            </ul>
            <p>$$
                \hat{e}_i = Y_i - \hat{a} - \hat{b}\, X_i.
                $$</p>
            <ul>
                <li>Optionally, <strong>center the residuals</strong> to ensure they have a mean of zero.</li>
                <li>Then, <strong>bootstrap samples</strong> are created by resampling the residuals $\hat{e}_i^*$ with replacement and generating new responses as</li>
            </ul>
            <p>$$
                Y_i^<em> = \hat{a} + \hat{b}\, X_i + \hat{e}_i^</em>.
                $$</p>
            <ul>
                <li><strong>Refit the model</strong> using the new responses to compute $\hat{a}^<em>$ and $\hat{b}^</em>$.</li>
                <li><strong>Repeat this process</strong> for $B$ bootstrap samples to obtain a reliable estimate.</li>
                <li>Finally, <strong>estimate the variability</strong> by using the distribution of $\hat{b}^*$ to calculate $SE(\hat{b})$.</li>
                <li>This method assumes that the <strong>error terms</strong> $e_i$ are identically distributed.</li>
            </ul>
            <h4 id="case-resampling-pairs-method-">Case Resampling (Pairs Method)</h4>
            <ul>
                <li>Begin by <strong>bootstrapping samples</strong> by resampling the $(X_i, Y_i)$ pairs with replacement.</li>
                <li><strong>Refit the model</strong> for each sample to calculate $\hat{a}^<em>$ and $\hat{b}^</em>$.</li>
                <li><strong>Repeat this process</strong> for $B$ bootstrap samples.</li>
                <li><strong>Estimate the variability</strong> by analyzing the distribution of $\hat{b}^*$ from the bootstrap results.</li>
                <li>An advantage of this method is that it captures the variability in both $X$ and $Y$.</li>
            </ul>
            <h4 id="wild-bootstrap">Wild Bootstrap</h4>
            <ul>
                <li>The <strong>purpose</strong> of the wild bootstrap is to handle heteroscedasticity, where the variance of the errors is not constant.</li>
                <li>The <strong>method</strong> involves multiplying residuals by random variables $\eta_i$ that have a mean of zero and a variance of one.</li>
                <li>New responses are then generated as</li>
            </ul>
            <p>$$
                Y_i^* = \hat{a} + \hat{b}\, X_i + \hat{e}_i\, \eta_i
                $$</p>
            <p>to account for this variability.</p>
            <h4 id="example-estimating-variability-of-regression-slope-using-residual-resampling">Example: Estimating Variability of Regression Slope Using Residual Resampling</h4>
            <p>In this example, we demonstrate the Residual Resampling method to estimate the variability of the regression slope $b$.</p>
            <p><strong>Steps:</strong></p>
            <ul>
                <li>Generate synthetic data with a known true intercept $a = 3$ and slope $b = 2$, along with random noise.</li>
                <li>Fit the original linear regression model and obtain estimates for $\hat{a}$ and $\hat{b}$.</li>
                <li>Compute the residuals</li>
            </ul>
            <p>$$
                \hat{e}_i = Y_i - \hat{a} - \hat{b}\, X_i.
                $$</p>
            <ul>
                <li>Perform bootstrapping by resampling the residuals, generating new responses, and refitting the model to obtain new estimates $\hat{a}^<em>$ and $\hat{b}^</em>$.</li>
                <li>Repeat the process for $B$ bootstrap samples to estimate the standard error of $\hat{b}$.</li>
            </ul>
            <p><img alt="Distribution of Slope Estimates from Residual Resampling" src="https://github.com/user-attachments/assets/57bc7cef-80a1-4fea-bab0-7ae3fc0bb765" /></p>
            <p>The initial linear regression model provided an estimate for the slope of approximately $\hat{b} = 1.954$.</p>
            <p>Bootstrap Resampling:</p>
            <ul>
                <li>We performed $B = 1000$ bootstrap iterations by resampling the residuals from the original model and refitting the model to compute new slope estimates each time.</li>
                <li>This process generates a distribution of slope estimates under different bootstrap samples, reflecting the variability in the slope.</li>
                <li>The standard error of the slope was estimated to be 0.0311, indicating the variability of the slope estimates.</li>
            </ul>
            <h3 id="practical-considerations">Practical Considerations</h3>
            <h4 id="number-of-bootstrap-samples-b-">Number of Bootstrap Samples $B$</h4>
            <ul>
                <li>There is a <strong>trade-off</strong> between precision and computation: using a larger $B$ provides more precise estimates but increases computational demands.</li>
                <li>It is generally <strong>recommended</strong> to use at least $B = 1,000$ when calculating confidence intervals.</li>
            </ul>
            <h4 id="assumptions-and-limitations">Assumptions and Limitations</h4>
            <ul>
                <li>The <strong>bootstrap method</strong> relies on the sample being representative of the population for accurate results.</li>
                <li><strong>Independence of observations</strong> is crucial, as the bootstrap assumes that each observation is independent of the others.</li>
                <li><strong>Sample size</strong> can affect reliability, with the bootstrap being less dependable when dealing with very small samples.</li>
            </ul>
        </article-section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#simulations-in-statistical-inference">Simulations in Statistical Inference</a>
                <ol>
                    <li><a href="#confidence-intervals-for-the-population-mean">Confidence Intervals for the Population Mean</a>
                        <ol>
                            <li><a href="#traditional-confidence-interval">Traditional Confidence Interval</a></li>
                            <li><a href="#limitations-of-traditional-methods">Limitations of Traditional Methods</a></li>
                        </ol>
                    </li>
                    <li><a href="#simulations-in-statistical-inference">Simulations in Statistical Inference</a></li>
                    <li><a href="#the-monte-carlo-method">The Monte Carlo Method</a>
                        <ol>
                            <li><a href="#estimating-an-unknown-parameter-theta-">Estimating an Unknown Parameter $\theta$</a></li>
                            <li><a href="#estimating-the-standard-error-se-hat-theta-">Estimating the Standard Error $SE(\hat{\theta})$</a></li>
                            <li><a href="#advantages">Advantages</a></li>
                        </ol>
                    </li>
                    <li><a href="#example-estimating-standard-error-using-monte-carlo-simulation">Example: Estimating Standard Error Using Monte Carlo Simulation</a></li>
                    <li><a href="#the-bootstrap-principle">The Bootstrap Principle</a>
                        <ol>
                            <li><a href="#the-plug-in-principle">The Plug-in Principle</a></li>
                            <li><a href="#bootstrap-procedure">Bootstrap Procedure</a></li>
                        </ol>
                    </li>
                    <li><a href="#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a>
                        <ol>
                            <li><a href="#1-normal-approximation-interval">1. Normal Approximation Interval</a></li>
                            <li><a href="#2-bootstrap-percentile-interval">2. Bootstrap Percentile Interval</a></li>
                            <li><a href="#3-bootstrap-pivotal-interval">3. Bootstrap Pivotal Interval</a></li>
                        </ol>
                    </li>
                    <li><a href="#bootstrapping-for-regression">Bootstrapping for Regression</a>
                        <ol>
                            <li><a href="#simple-linear-regression-model">Simple Linear Regression Model</a></li>
                            <li><a href="#residual-resampling">Residual Resampling</a></li>
                            <li><a href="#case-resampling-pairs-method-">Case Resampling (Pairs Method)</a></li>
                            <li><a href="#wild-bootstrap">Wild Bootstrap</a></li>
                            <li><a href="#example-estimating-variability-of-regression-slope-using-residual-resampling">Example: Estimating Variability of Regression Slope Using Residual Resampling</a></li>
                        </ol>
                    </li>
                    <li><a href="#practical-considerations">Practical Considerations</a>
                        <ol>
                            <li><a href="#number-of-bootstrap-samples-b-">Number of Bootstrap Samples $B$</a></li>
                            <li><a href="#assumptions-and-limitations">Assumptions and Limitations</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/statistical_moments.html">Statistical Moments</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If youâ€™d like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>