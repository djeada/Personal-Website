<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Multiple Comparisons</title>
    <meta content="When conducting multiple hypothesis tests simultaneously, the likelihood of committing at least one Type I error (falsely rejecting a true null hypothesis) increases." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper"><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: March 26, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="multiple-comparisons">Multiple Comparisons</h2>
            <p>When conducting multiple hypothesis tests simultaneously, the likelihood of committing at least one Type I error (falsely rejecting a true null hypothesis) increases. This increase is due to the problem known as the "multiple comparisons problem" or the "look-elsewhere effect". The methods to address this issue typically involve adjustments to the significance level or p-values, and each has its advantages and disadvantages. </p>
            <h3 id="data-snooping-and-the-multiple-testing-fallacy">Data Snooping and the Multiple Testing Fallacy</h3>
            <ul>
                <li>A <strong>1992 Swedish study</strong> suggested a statistically significant link between living near power lines and childhood leukemia, but follow-up studies failed to replicate the finding.</li>
                <li>The study performed <strong>800 statistical tests</strong>, which greatly increased the chance of finding false positives due to random chance.</li>
                <li>The <strong>multiple testing fallacy</strong> occurs when running a large number of tests. Even when no true effect exists, some tests will yield significant results by coincidence. For example, if the significance level is 1%, you would expect 8 false positives from 800 tests.</li>
            </ul>
            <h4 id="multiple-comparisons-problem">Multiple Comparisons Problem</h4>
            <ul>
                <li>The <strong>p-value</strong> represents the probability of obtaining a result as extreme as the observed one if the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis.</li>
                <li>The <strong>look-elsewhere effect</strong> or <strong>data snooping</strong> refers to the issue that, when many tests are conducted, some will appear significant just by chance, even if no real effect is present.</li>
            </ul>
            <h4 id="reproducibility-and-replicability-crisis">Reproducibility and Replicability Crisis</h4>
            <ul>
                <li><strong>Reproducibility</strong> refers to achieving the same results when using the same data and methods, while <strong>replicability</strong> involves obtaining similar results when using different data or methods.</li>
                <li>A growing concern about the reliability of scientific findings, known as the <strong>reproducibility and replicability crisis</strong>, has been highlighted by issues such as data snooping. For example, John Ioannidisâ€™s 2005 paper, <em>"Why Most Published Research Findings Are False,"</em> underscores this problem in scientific research.</li>
            </ul>
            <h4 id="addressing-the-multiple-testing-problem">Addressing the Multiple Testing Problem</h4>
            <ul>
                <li>The <strong>Bonferroni correction</strong> adjusts p-values by multiplying them by the number of tests conducted, ensuring that the overall probability of making at least one false positive is no more than 5%. However, it is very conservative and may render true effects insignificant.</li>
                <li>The <strong>false discovery proportion (FDP)</strong> offers a more flexible approach, focusing on controlling the proportion of false discoveries among all findings. For instance, if 80 true discoveries are made alongside 41 false discoveries, the FDP is 34%, meaning 34% of the discoveries are false positives.</li>
            </ul>
            <h4 id="false-discovery-rate-fdr-">False Discovery Rate (FDR)</h4>
            <ul>
                <li>The <strong>false discovery rate (FDR)</strong> represents the expected proportion of false discoveries among all discoveries.</li>
                <li>The <strong>Benjamini-Hochberg procedure</strong> controls the FDR by ranking p-values and selecting the largest p-value that satisfies a certain condition, ensuring a controlled rate of false discoveries, such as 5%.</li>
            </ul>
            <h4 id="using-a-validation-set-to-avoid-data-snooping">Using a Validation Set to Avoid Data Snooping</h4>
            <ul>
                <li>The <strong>validation set approach</strong> involves splitting the data into two distinct sets to prevent data snooping.</li>
                <li>The <strong>model-building set</strong> is used to explore the data and identify potential relationships during the analysis phase.</li>
                <li>The <strong>validation set</strong> is reserved for testing hypotheses that emerge from the model-building phase, ensuring an unbiased evaluation of the findings.</li>
                <li>It is <strong>crucial</strong> that the validation set remains unexamined during the exploratory phase to avoid introducing bias or data snooping into the results.</li>
            </ul>
            <h3 id="family-wise-error-rate-fwer-">Family-wise Error Rate (FWER)</h3>
            <p>The family-wise error rate (FWER) is the probability of making at least one Type I error among all the tests in a family. Controlling FWER maintains overall confidence in the results when conducting multiple tests.</p>
            <h4 id="bonferroni-correction">Bonferroni Correction</h4>
            <p>The Bonferroni correction is a common method for controlling the FWER. It adjusts the significance level (Î±) by dividing it by the number of tests performed (n):</p>
            <p>$$
                \alpha_{\text{{adjusted}}} = \frac{\alpha}{n}
                $$</p>
            <p>This adjusted significance level is then used to compute the critical values for each test. The Bonferroni correction is inherently conservative, making it more likely to commit Type II errors (falsely accepting a false null hypothesis), especially when there are many tests or the tests are not independent.
                Here is an improved version of your example with better LaTeX formatting and more explanation:</p>
            <h4 id="example-bonferroni-correction">Example: Bonferroni Correction</h4>
            <p>Suppose we are conducting 20 independent hypothesis tests, and the significance level for the family-wise error rate is $\alpha = 0.05$. To control for multiple comparisons using the Bonferroni correction, we adjust the significance level by dividing $\alpha$ by the number of tests.</p>
            <p>The Bonferroni-adjusted significance level, $\alpha_{\text{adjusted}}$, is calculated as follows:</p>
            <p>$$
                \alpha_{\text{adjusted}} = \frac{\alpha}{m} = \frac{0.05}{20} = 0.0025
                $$</p>
            <p>where:</p>
            <ul>
                <li>$\alpha = 0.05$ is the desired overall significance level,</li>
                <li>$m = 20$ is the number of tests being conducted.</li>
            </ul>
            <p><strong>Conclusion:</strong></p>
            <p>After applying the Bonferroni correction, we would reject the null hypothesis for an individual test only if its p-value is less than $0.0025$. This correction helps control the family-wise error rate, reducing the chance of Type I errors (false positives) across multiple tests. However, it also makes the test more conservative, increasing the likelihood of Type II errors (false negatives).</p>
            <h3 id="false-discovery-rate-fdr-">False Discovery Rate (FDR)</h3>
            <p>In contrast to FWER, the false discovery rate (FDR) controls for the expected proportion of false positives among all rejected null hypotheses. FDR controlling procedures are generally more powerful than FWER controlling methods, making them particularly suitable for exploratory studies where the discovery of new findings is prioritized.</p>
            <h4 id="benjamini-hochberg-procedure">Benjamini-Hochberg Procedure</h4>
            <p>The Benjamini-Hochberg (BH) procedure is widely used for controlling the FDR. This method involves ordering the p-values from smallest to largest and then comparing each p-value to an adjusted significance level that depends on its rank (i) and the total number of tests (n):</p>
            <p>$$
                \alpha_{\text{{adjusted}}} = \frac{\alpha \times i}{n}
                $$</p>
            <p>We reject the null hypothesis for all tests where the p-value is less than or equal to the adjusted significance level. </p>
            <h4 id="example-multiple-hypothesis-testing">Example: Multiple Hypothesis Testing</h4>
            <p>Suppose we are conducting six hypothesis tests, and the p-values obtained from these tests are:</p>
            <p>$$
                {0.001, 0.008, 0.039, 0.041, 0.042, 0.06}
                $$</p>
            <p>We will apply the Bonferroni-Holm correction to control the family-wise error rate at $\alpha = 0.05$. The procedure requires us to compare each ordered p-value to a sequentially adjusted significance level.</p>
            <p><strong>Step-by-Step Procedure:</strong></p>
            <p>I. <strong>Order the p-values</strong> in ascending order: </p>
            <p>$$
                0.001, 0.008, 0.039, 0.041, 0.042, 0.06
                $$</p>
            <p>II. <strong>Adjust the significance level</strong> for each test. The adjusted significance level for the $i$-th test is calculated as:</p>
            <p>$$
                \alpha_i = \frac{\alpha}{n - i + 1}
                $$</p>
            <p>where $n$ is the total number of tests (in this case, $n = 6$) and $\alpha = 0.05$.</p>
            <p>III. <strong>Compare each p-value to its adjusted $\alpha_i$</strong>:</p>
            <p>For $p_1 = 0.001$:</p>
            <p>$$
                0.001 &lt; \frac{0.05}{6} \approx 0.00833 \quad \text{(Reject $H_0$)}
                $$</p>
            <p>For $p_2 = 0.008$:</p>
            <p>$$
                0.008 &lt; \frac{0.05}{5} = 0.01 \quad \text{(Reject $H_0$)}
                $$</p>
            <p>For $p_3 = 0.039$:</p>
            <p>$$
                0.039 &gt; \frac{0.05}{4} = 0.0125 \quad \text{(Fail to Reject $H_0$)}
                $$</p>
            <p>Since we fail to reject $H_0$ at this step, there is no need to test further hypotheses, as the procedure stops here.</p>
            <p><img alt="output(29)" src="https://github.com/user-attachments/assets/e1dfbabc-e720-448d-a8b3-228f91d665eb" /></p>
            <p>Using the Bonferroni-Holm procedure, we reject the null hypothesis for the first two tests but fail to reject for the remaining tests.</p>
            <p>This method helps reduce the probability of Type I errors (false positives) when conducting multiple comparisons. However, as with all statistical procedures, there is a trade-off, potentially increasing the risk of Type II errors (false negatives). Researchers must balance these risks depending on the context and goals of their study.</p>
        </article-section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#multiple-comparisons">Multiple Comparisons</a>
                <ol>
                    <li><a href="#data-snooping-and-the-multiple-testing-fallacy">Data Snooping and the Multiple Testing Fallacy</a>
                        <ol>
                            <li><a href="#multiple-comparisons-problem">Multiple Comparisons Problem</a></li>
                            <li><a href="#reproducibility-and-replicability-crisis">Reproducibility and Replicability Crisis</a></li>
                            <li><a href="#addressing-the-multiple-testing-problem">Addressing the Multiple Testing Problem</a></li>
                            <li><a href="#false-discovery-rate-fdr-">False Discovery Rate (FDR)</a></li>
                            <li><a href="#using-a-validation-set-to-avoid-data-snooping">Using a Validation Set to Avoid Data Snooping</a></li>
                        </ol>
                    </li>
                    <li><a href="#family-wise-error-rate-fwer-">Family-wise Error Rate (FWER)</a>
                        <ol>
                            <li><a href="#bonferroni-correction">Bonferroni Correction</a></li>
                            <li><a href="#example-bonferroni-correction">Example: Bonferroni Correction</a></li>
                        </ol>
                    </li>
                    <li><a href="#false-discovery-rate-fdr-">False Discovery Rate (FDR)</a>
                        <ol>
                            <li><a href="#benjamini-hochberg-procedure">Benjamini-Hochberg Procedure</a></li>
                            <li><a href="#example-multiple-hypothesis-testing">Example: Multiple Hypothesis Testing</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/statistical_moments.html">Statistical Moments</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If youâ€™d like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>