<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Autocovariance functions and coefficients</title>
    <meta content="Autocovariance functions describe how values of a time series relate to their lagged counterparts, measuring the joint variability between a series at time $t$ and its value at a previous time $t-k$ (where $k$ is the lag)." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>Last modified: October 29, 2023</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="autocovariance-functions-and-coefficients">Autocovariance functions and coefficients</h2>
            <p>Autocovariance functions describe how values of a time series relate to their lagged counterparts, measuring the joint variability between a series at time $t$ and its value at a previous time $t-k$ (where $k$ is the lag). In autoregressive models, these relationships are expressed through <strong>coefficients</strong>, which quantify the influence of past values on future values. The autocovariance function helps in estimating these coefficients by analyzing the strength and pattern of correlations at different lags. Higher autocovariance at a specific lag suggests a stronger influence of past values on the present, aiding in model selection and parameter estimation for time series models like AR, MA, and ARIMA.</p>
            <h3 id="random-variables-r-v-">Random Variables (r.v.)</h3>
            <p>A <strong>random variable (r.v.)</strong> is a mapping from a set of outcomes in a probability space to a set of real numbers. We can distinguish between:</p>
            <p>I. <strong>Discrete random variables</strong> take on countable values. For example, let:</p>
            <p>$$
                X = {45, 36, 27, \dots}
                $$</p>
            <p>II. <strong>Continuous random variables</strong> take on any value in a continuous range. For instance:</p>
            <p>$$
                Y \in (10, 60)
                $$</p>
            <p>A <strong>realization</strong> is a specific observed value of a random variable. For instance:</p>
            <p>$$
                X = 20 \quad \text{and} \quad Y = 30.29
                $$</p>
            <h3 id="covariance">Covariance</h3>
            <p>The <strong>covariance</strong> between two random variables $X$ and $Y$ measures the linear relationship between them. It is defined as:</p>
            <p>$$
                \text{Cov}(X, Y) = E\left[(X - \mu_X)(Y - \mu_Y)\right]
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$\mu_X = E[X]$ is the mean of $X$.</li>
                <li>$\mu_Y = E[Y]$ is the mean of $Y$.</li>
                <li>$E[\cdot]$ denotes the expectation operator.</li>
            </ul>
            <p>The covariance is <strong>symmetric</strong>:</p>
            <p>$$
                \text{Cov}(X, Y) = \text{Cov}(Y, X)
                $$</p>
            <p>Interpretation:</p>
            <ul>
                <li>If $\text{Cov}(X, Y) &gt; 0$, $X$ and $Y$ increase together.</li>
                <li>If $\text{Cov}(X, Y) &lt; 0$, when $X$ increases, $Y$ tends to decrease.</li>
                <li>If $\text{Cov}(X, Y) = 0$, there is no linear dependence between $X$ and $Y$.</li>
            </ul>
            <h4 id="estimation-of-covariance">Estimation of Covariance</h4>
            <p>To estimate the covariance from a paired dataset $(x_1, y_1), (x_2, y_2), \dots, (x_N, y_N)$, we use the sample covariance formula:</p>
            <p>$$
                s_{xy} = \frac{1}{N - 1} \sum_{t=1}^{N} (x_t - \bar{x})(y_t - \bar{y})
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$\bar{x} = \frac{1}{N} \sum_{t=1}^{N} x_t$ is the sample mean of $x$,</li>
                <li>$\bar{y} = \frac{1}{N} \sum_{t=1}^{N} y_t$ is the sample mean of $y$,</li>
                <li>$N$ is the number of observations.</li>
            </ul>
            <h3 id="stochastic-processes">Stochastic Processes</h3>
            <p>A <strong>stochastic process</strong> is a collection of random variables indexed by time, denoted as:</p>
            <p>$$
                {X_t : t \in T}
                $$</p>
            <p>where $T$ is the index set (often time or space).</p>
            <p>Each $X_t$ follows a certain distribution with a mean $\mu$ and variance $\sigma^2$:</p>
            <p>$$
                X_t \sim \text{Distribution}(\mu, \sigma^2)
                $$</p>
            <p><strong>Example</strong>: A time series is a realization of a stochastic process. Consider the following realizations:</p>
            <p>$$
                X_1, X_2, X_3, \dots
                $$</p>
            <p>Realized as:</p>
            <p>$$
                30, 29, 57, \dots
                $$</p>
            <h3 id="autocovariance-function">Autocovariance Function</h3>
            <p>The <strong>autocovariance function</strong> measures the covariance between two values of the time series at different times $s$ and $t$:</p>
            <p>$$
                \gamma(s, t) = \text{Cov}(X_s, X_t) = E\left[(X_s - \mu_s)(X_t - \mu_t)\right]
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$X_s$ and $X_t$ are the values of the time series at times $s$ and $t$, respectively.</li>
                <li>$\mu_s$ and $\mu_t$ are the means at times $s$ and $t$.</li>
            </ul>
            <p><strong>Variance</strong> as a special case:</p>
            <p>When $s = t$, the autocovariance function simplifies to the variance of the series at time $t$:</p>
            <p>$$
                \gamma(t, t) = E\left[(X_t - \mu_t)^2\right] = \text{Var}(X_t) = \sigma_t^2
                $$</p>
            <h3 id="lagged-autocovariance">Lagged Autocovariance</h3>
            <p>The <strong>lagged autocovariance function</strong> measures the covariance between values of the series at times $t$ and $t+k$, where $k$ is the lag:</p>
            <p>$$
                \gamma_k = \gamma(t, t+k) = E\left[(X_t - \mu)(X_{t+k} - \mu)\right]
                $$</p>
            <p>For a <strong>stationary process</strong>, the autocovariance function depends only on the lag $k$, not the specific times $t$ and $t+k$:</p>
            <p>$$
                \gamma_k \approx c_k
                $$</p>
            <p>This implies that the autocovariance function remains constant for different time points, provided the lag $k$ is the same.</p>
            <h4 id="autocovariance-coefficients">Autocovariance Coefficients</h4>
            <p><strong>Autocovariance</strong> measures the covariance of a time series with itself at different time lags. For a time series ${X_t}$, the <strong>autocovariance at lag $k$</strong> is defined as:</p>
            <p>$$
                \gamma_k = \text{Cov}(X_t, X_{t+k}) = E\left[(X_t - \mu)(X_{t+k} - \mu)\right]
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$X_t$ is the value of the time series at time $t$,</li>
                <li>$X_{t+k}$ is the value of the time series at time $t+k$,</li>
                <li>$\mu$ is the mean of the series (assumed to be constant for weak stationarity).</li>
            </ul>
            <p><strong>Sample Estimation</strong> of the autocovariance coefficient $\gamma_k$ is denoted by $c_k$. For a time series with $N$ observations, the estimator is:</p>
            <p>$$
                c_k = \frac{1}{N} \sum_{t=1}^{N-k} (x_t - \bar{x})(x_{t+k} - \bar{x})
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$\bar{x} = \frac{1}{N} \sum_{t=1}^{N} x_t$ is the sample mean of the series.</li>
            </ul>
            <h4 id="assumption-of-weak-stationarity">Assumption of Weak Stationarity</h4>
            <p>For weakly stationary processes, the mean $\mu$ is constant, and the autocovariance $\gamma_k$ depends only on the lag $k$, not on the actual time points $t$ and $t+k$. Therefore, the autocovariance function becomes:</p>
            <p>$$
                \gamma_k = E\left[(X_t - \mu)(X_{t+k} - \mu)\right] = \text{Cov}(X_t, X_{t+k})
                $$</p>
            <p>Under the assumption of weak stationarity, the sample autocovariance $c_k$ is computed as:</p>
            <p>$$
                c_k = \frac{1}{N} \sum_{t=1}^{N-k} (x_t - \bar{x})(x_{t+k} - \bar{x})
                $$</p>
            <p>This allows us to estimate the strength of the relationship between $X_t$ and $X_{t+k}$ at different lags $k$.</p>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#autocovariance-functions-and-coefficients">Autocovariance functions and coefficients</a>
                <ol>
                    <li><a href="#random-variables-r-v-">Random Variables (r.v.)</a></li>
                    <li><a href="#covariance">Covariance</a>
                        <ol>
                            <li><a href="#estimation-of-covariance">Estimation of Covariance</a></li>
                        </ol>
                    </li>
                    <li><a href="#stochastic-processes">Stochastic Processes</a></li>
                    <li><a href="#autocovariance-function">Autocovariance Function</a></li>
                    <li><a href="#lagged-autocovariance">Lagged Autocovariance</a>
                        <ol>
                            <li><a href="#autocovariance-coefficients">Autocovariance Coefficients</a></li>
                            <li><a href="#assumption-of-weak-stationarity">Assumption of Weak Stationarity</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/readme.html">Readme</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>