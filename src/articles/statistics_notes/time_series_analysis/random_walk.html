<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Random Walk Model</title>
    <meta content="The random walk is a fundamental and widely used time series model, often applied in finance to represent stock prices and other economic indicators." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: April 25, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="random-walk-model">Random Walk Model</h2>
            <p>The <strong>random walk</strong> is a fundamental and widely used time series model, often applied in finance to represent stock prices and other economic indicators. The idea behind the random walk is that the value of the process at time $t$ is the sum of its value at time $t-1$ and a random shock (or noise). Essentially, each step of the process is unpredictable and governed by randomness.</p>
            <p>Mathematically, the random walk model is represented as:</p>
            <p>$$
                X_t = X_{t-1} + Z_t
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$X_t$ is the value of the process at time $t$ (e.g., the stock price today).</li>
                <li>$X_{t-1}$ is the value at the previous time step (e.g., the stock price yesterday).</li>
                <li>$Z_t$ is a <strong>white noise</strong> term, typically assumed to follow a normal distribution $Z_t \sim \mathcal{N}(\mu, \sigma^2)$, with mean $\mu$ and variance $\sigma^2$.</li>
            </ul>
            <h3 id="evolution-of-a-random-walk-over-time">Evolution of a Random Walk Over Time</h3>
            <p>To better understand how a random walk evolves, we can expand the model over time. Starting at $X_0 = 0$, we have:</p>
            <p>$$
                X_1 = Z_1
                $$</p>
            <p>$$
                X_2 = Z_1 + Z_2
                $$</p>
            <p>$$
                X_3 = Z_1 + Z_2 + Z_3
                $$</p>
            <p>$$
                X_t = \sum_{i=1}^{t} Z_i
                $$</p>
            <p>In general, the value at time $t$, $X_t$, is the cumulative sum of all past shocks $Z_1, Z_2, \dots, Z_t$. This means that the random walk retains the effects of all previous shocks, making it highly dependent on its past values.</p>
            <h3 id="mean-and-variance-of-a-random-walk">Mean and Variance of a Random Walk</h3>
            <p>The key properties of a random walk are its <strong>mean</strong> and <strong>variance</strong>. Since each step $Z_t$ is a random shock with its own distribution, the behavior of the entire random walk can be derived from the properties of the shocks.</p>
            <h4 id="expected-value">Expected Value</h4>
            <p>The expected value $E[X_t]$ gives us the average or mean value of $X_t$ over time. Since $Z_t \sim \mathcal{N}(\mu, \sigma^2)$, the expected value of each shock $Z_t$ is $E[Z_t] = \mu$. Therefore, the expected value of $X_t$ at any time $t$ is:</p>
            <p>$$
                E[X_t] = E\left[\sum_{i=1}^{t} Z_i\right] = \sum_{i=1}^{t} E[Z_i] = \mu t
                $$</p>
            <p>This shows that the expected value of a random walk grows linearly with time $t$ if $\mu \neq 0$. When $\mu = 0$, the random walk has no trend, and its expected value remains 0.</p>
            <h4 id="variance">Variance</h4>
            <p>The variance $\text{Var}(X_t)$ measures the spread or uncertainty of $X_t$ at time $t$. Since the variance of each shock $Z_t$ is $\sigma^2$, and the shocks are assumed to be independent, the variance of the sum of shocks is the sum of their variances:</p>
            <p>$$
                \text{Var}(X_t) = \text{Var}\left(\sum_{i=1}^{t} Z_i\right) = \sum_{i=1}^{t} \text{Var}(Z_i) = \sigma^2 t
                $$</p>
            <p>This means that the variance of a random walk increases linearly with time, implying that the uncertainty around $X_t$ grows as $t$ increases. The longer the random walk progresses, the more dispersed the values become.</p>
            <h3 id="simulation-of-a-random-walk-in-python">Simulation of a Random Walk in Python</h3>
            <p>A <strong>random walk</strong> is a type of stochastic process where each value in the sequence is determined by the previous value plus a random shock. This concept can be useful in various fields such as finance (for modeling stock prices), physics (for modeling particle movements), or statistics (as a time series model). Simulating a random walk in Python is straightforward, as we iteratively add random shocks to calculate each successive value. </p>
            <p>The basic model for a random walk is:</p>
            <p>$$
                X_t = X_{t-1} + Z_t
                $$</p>
            <p>where:
                - $X_t$ is the value of the random walk at time step $t$,
                - $X_{t-1}$ is the value of the random walk at the previous time step,
                - $Z_t$ represents a random shock at time $t$, typically drawn from a normal distribution $\mathcal{N}(0, 1)$.</p>
            <p>This means that each new value of the random walk is determined by adding a random shock $Z_t$ to the current value. The random walk typically starts at some initial value (often $X_0 = 0$).</p>
            <h3 id="simulation-example">Simulation Example</h3>
            <p>The following Python code demonstrates how to simulate and plot a random walk using <strong>NumPy</strong> for generating the random shocks and <strong>Matplotlib</strong> for visualization.</p>
            <p>
            <div>
                <pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Number of steps in the random walk
N = 1000

# Generate white noise (Z_t ~ N(0, 1))
Z = np.random.normal(loc=0, scale=1, size=N)

# Initialize the random walk (X_0 = 0)
X = np.cumsum(np.insert(Z, 0, 0))  # Insert X_0 = 0 and compute cumulative sum

# Plot the random walk
plt.figure(figsize=(10, 6))
plt.plot(X, label='Random Walk')
plt.title('Simulation of a Random Walk')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.show()</code></pre>
            </div>
            </p>
            <p>Explanation:</p>
            <ol>
                <li>The array <code>Z</code> represents the sequence of random shocks $Z_t$ drawn from a normal distribution $\mathcal{N}(0, 1)$. This sequence of shocks has a mean of 0 and a standard deviation of 1, making it "white noise"â€”a series of uncorrelated random variables.</li>
                <li>The cumulative sum of <code>Z</code> is used to create the random walk. The <code>np.cumsum()</code> function calculates the cumulative sum of the array, giving the values $X_t$ for each time step. The function <code>np.insert(Z, 0, 0)</code> adds the initial value $X_0 = 0$ at the start.</li>
                <li>We then plot the random walk, where the x-axis represents time and the y-axis represents the value of the walk at each step.</li>
            </ol>
            <p>Here is an example plot of the random walk:</p>
            <p><img alt="Figure_1" src="https://github.com/user-attachments/assets/0328869d-6a94-4f9b-b623-09e9d3e42311" /></p>
            <h3 id="autocorrelation-of-the-random-walk">Autocorrelation of the Random Walk</h3>
            <p>Autocorrelation measures how a time series is correlated with its past values. A random walk typically exhibits <strong>high autocorrelation</strong> because each step is dependent on the previous step. We can visualize the autocorrelation function (ACF) of the random walk using <code>statsmodels</code>.</p>
            <p>
            <div>
                <pre><code class="language-python">from statsmodels.graphics.tsaplots import plot_acf

# Plot the autocorrelation function (ACF)
plot_acf(X, lags=50)
plt.show()</code></pre>
            </div>
            </p>
            <p>The autocorrelation plot typically shows strong correlations for several lags, reflecting the memory of the process. An example of the ACF plot is shown below:</p>
            <p><img alt="Figure_2" src="https://github.com/user-attachments/assets/82260af5-9278-4e44-b527-554a5ef12aa5" /></p>
            <h3 id="removing-the-trend-with-the-difference-operator">Removing the Trend with the Difference Operator</h3>
            <p>A random walk has a <strong>trend</strong> due to the cumulative nature of the process. Even if the random shocks have zero mean, the variance of the process increases over time, making it <strong>non-stationary</strong>. A stationary process has a constant mean and variance over time, and its autocorrelation function decays quickly. To transform the random walk into a stationary process, we can apply the <strong>difference operator</strong>.</p>
            <p>The <strong>difference operator</strong> is defined as:</p>
            <p>$$
                \Delta X_t = X_t - X_{t-1} = Z_t
                $$</p>
            <p>Applying this operation to a random walk removes the trend, as each differenced value corresponds to the original random shocks $Z_t$. This transformation yields a series of white noise.</p>
            <h3 id="differencing-in-python">Differencing in Python</h3>
            <p>We can use <code>numpy.diff()</code> to difference the random walk:</p>
            <p>
            <div>
                <pre><code class="language-python"># Difference the random walk to remove the trend
diff_X = np.diff(X)

# Plot the differenced time series
plt.figure(figsize=(10, 6))
plt.plot(diff_X, label='Differenced Random Walk')
plt.title('Differenced Time Series (White Noise)')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.show()

# Plot the autocorrelation function (ACF) of the differenced series
plot_acf(diff_X, lags=50)
plt.show()</code></pre>
            </div>
            </p>
            <p>Explanation:</p>
            <ol>
                <li>The <code>np.diff()</code> function calculates the differences between consecutive values in the <code>X</code> array, effectively applying the difference operator $\Delta X_t$. The resulting series, <code>diff_X</code>, represents the original random shocks $Z_t$, which are white noise.</li>
                <li>After differencing, we plot the new series to visualize the transformation. The plot shows random fluctuations around zero, which is characteristic of white noise.</li>
                <li>The autocorrelation function of the differenced series should show no significant correlations at any lag, as the differenced process is now white noise with no memory of previous values.</li>
            </ol>
            <p>Here is an example plot of the differenced random walk:</p>
            <p><img alt="Figure_3" src="https://github.com/user-attachments/assets/91b7c7e2-9354-42ff-a6da-0312e4bb258b" /></p>
            <p>And the ACF plot for the differenced series:</p>
            <p><img alt="Figure_4" src="https://github.com/user-attachments/assets/d3b952e4-27aa-4edf-a6f9-955fcc54fee3" /></p>
            <h3 id="correlogram-of-a-random-walk">Correlogram of a Random Walk</h3>
            <p>The <strong>Autocorrelation Function (ACF)</strong> of a random walk provides important insights into its structure. Since each value in a random walk is highly dependent on its previous value (and indirectly on all past values), the autocorrelation at lower lags tends to be very high. The ACF of a random walk decays slowly, indicating <strong>non-stationarity</strong>. </p>
            <p>Specifically:</p>
            <ul>
                <li>The autocorrelation at lag 1 is typically close to 1.</li>
                <li>The autocorrelation decreases gradually at higher lags but remains significant.</li>
            </ul>
            <p>Once we apply the difference operator, the ACF of the differenced series becomes close to zero for all lags, confirming that the differenced series is now <strong>stationary white noise</strong>.</p>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#random-walk-model">Random Walk Model</a>
                <ol>
                    <li><a href="#evolution-of-a-random-walk-over-time">Evolution of a Random Walk Over Time</a></li>
                    <li><a href="#mean-and-variance-of-a-random-walk">Mean and Variance of a Random Walk</a>
                        <ol>
                            <li><a href="#expected-value">Expected Value</a></li>
                            <li><a href="#variance">Variance</a></li>
                        </ol>
                    </li>
                    <li><a href="#simulation-of-a-random-walk-in-python">Simulation of a Random Walk in Python</a></li>
                    <li><a href="#simulation-example">Simulation Example</a></li>
                    <li><a href="#autocorrelation-of-the-random-walk">Autocorrelation of the Random Walk</a></li>
                    <li><a href="#removing-the-trend-with-the-difference-operator">Removing the Trend with the Difference Operator</a></li>
                    <li><a href="#differencing-in-python">Differencing in Python</a></li>
                    <li><a href="#correlogram-of-a-random-walk">Correlogram of a Random Walk</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>