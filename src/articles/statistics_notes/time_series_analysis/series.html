<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Sequences and Series</title>
    <meta content="A sequence is an ordered list of numbers that can be viewed as a function mapping each natural number $n$ to a specific value $a_n$." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper"><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: June 16, 2021</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="sequences-and-series">Sequences and Series</h2>
            <h3 id="sequences">Sequences</h3>
            <p>A <strong>sequence</strong> is an ordered list of numbers that can be viewed as a function mapping each natural number $n$ to a specific value $a_n$. More formally, a sequence ${a_n}$ is a function whose domain is the set of natural numbers, and the values are called the terms of the sequence:</p>
            <p>$$
                a_1, a_2, a_3, \dots, a_n, \dots
                $$</p>
            <p>A sequence can either approach a particular value, in which case it is said to <strong>converge</strong>, or it can increase or oscillate indefinitely, in which case it <strong>diverges</strong>.</p>
            <p>A sequence ${a_n}$ <strong>converges</strong> to a limit $a$ if, as $n$ becomes very large, the values of $a_n$ get arbitrarily close to $a$. Mathematically, this is expressed as:</p>
            <p>$$
                \lim_{n \to \infty} a_n = a
                $$</p>
            <p>This means for any small number $\epsilon &gt; 0$, there exists a large number $N$ such that for all $n &gt; N$, the distance between $a_n$ and $a$ is smaller than $\epsilon$. If no such limit exists, the sequence <strong>diverges</strong>.</p>
            <h4 id="examples-of-sequences">Examples of Sequences</h4>
            <ol>
                <li><strong>Convergent Sequence:</strong></li>
            </ol>
            <p>Consider the sequence $a_n = \frac{n}{n+2}$. This gives the sequence:</p>
            <p>$$
                \frac{1}{3}, \frac{2}{4}, \frac{3}{5}, \dots
                $$</p>
            <p>As $n \to \infty$, the terms of the sequence approach 1:</p>
            <p>$$
                \lim_{n \to \infty} \frac{n}{n+2} = 1
                $$</p>
            <p>Therefore, this sequence converges to 1.</p>
            <ol>
                <li><strong>Divergent Sequence:</strong></li>
            </ol>
            <p>Now consider the sequence $a_n = 4^n$. This gives the sequence:</p>
            <p>$$
                4, 16, 64, \dots
                $$</p>
            <p>As $n \to \infty$, the terms of the sequence grow without bound, meaning this sequence diverges.</p>
            <ol>
                <li><strong>Another Divergent Sequence:</strong></li>
            </ol>
            <p>Another example of a divergent sequence is $a_n = n + 1$, which gives:</p>
            <p>$$
                2, 3, 4, \dots
                $$</p>
            <p>As $n \to \infty$, the sequence grows indefinitely, and hence it diverges.</p>
            <ol>
                <li><strong>Convergent Sequence:</strong></li>
            </ol>
            <p>Consider the sequence $a_n = \frac{1}{n^3}$, which gives:</p>
            <p>$$
                1, \frac{1}{8}, \frac{1}{27}, \dots
                $$</p>
            <p>As $n \to \infty$, the terms of this sequence get smaller and smaller, approaching 0:</p>
            <p>$$
                \lim_{n \to \infty} \frac{1}{n^3} = 0
                $$</p>
            <p>Hence, this sequence converges to 0.</p>
            <h3 id="partial-sums">Partial Sums</h3>
            <p>The <strong>partial sum</strong> $s_n$ of a sequence ${a_n}$ is the sum of the first $n$ terms of the sequence:</p>
            <p>$$
                s_n = a_1 + a_2 + \dots + a_n
                $$</p>
            <p>Partial sums are used to analyze the behavior of series, where the idea is to observe whether the sum of the terms converges to a specific value as more terms are added. For example, consider the following partial sums:</p>
            <ul>
                <li>$s_1 = a_1$</li>
                <li>$s_2 = a_1 + a_2$</li>
                <li>$s_3 = a_1 + a_2 + a_3$</li>
                <li>$\dots$</li>
            </ul>
            <p>A series formed by a sequence is said to converge if the sequence of partial sums converges as $n \to \infty$.</p>
            <h3 id="series">Series</h3>
            <p>A <strong>series</strong> is the sum of the terms of a sequence. If the sequence of partial sums ${s_n}$ converges to a limit $s$, the series is said to <strong>converge</strong> to that limit $s$. Mathematically, the infinite series is written as:</p>
            <p>$$
                \sum_{k=1}^{\infty} a_k = \lim_{n \to \infty} s_n = \lim_{n \to \infty} (a_1 + a_2 + \dots + a_n) = s
                $$</p>
            <p>If the partial sums do not approach a finite limit as $n$ increases, then the series is said to be <strong>divergent</strong>.</p>
            <h3 id="geometric-series-and-rational-functions">Geometric Series and Rational Functions</h3>
            <p>A <strong>geometric series</strong> is a series of the form:</p>
            <p>$$
                \sum_{k=0}^{\infty} r^k = \frac{1}{1 - r}, \quad \text{for } |r| &lt; 1
                $$</p>
            <p>This result can be used to represent certain rational functions as infinite series. For example:</p>
            <p>$$
                \frac{1}{1 - x} = \sum_{k=0}^{\infty} x^k, \quad \text{for } |x| &lt; 1
                $$</p>
            <p>This is useful in time series analysis when dealing with autoregressive models and other representations involving rational functions.</p>
            <h3 id="examples-of-convergent-series">Examples of Convergent Series</h3>
            <p>I. <strong>Geometric Series</strong>:</p>
            <p>A geometric series is a series where each term is a constant multiple (called the common ratio) of the previous term. A simple example is the following geometric series:</p>
            <p>$$
                \sum_{k=0}^{\infty} \frac{1}{3^k}
                $$</p>
            <p>This series converges to:</p>
            <p>$$
                \sum_{k=0}^{\infty} \frac{1}{3^k} = \frac{1}{1 - \frac{1}{3}} = \frac{3}{2}
                $$</p>
            <p>II. <strong>P-Series</strong> (convergent for $p &gt; 1$):</p>
            <p>A <strong>p-series</strong> is of the form:</p>
            <p>$$
                \sum_{k=1}^{\infty} \frac{1}{k^p}
                $$</p>
            <p>For $p = 2$, the series converges to:</p>
            <p>$$
                \sum_{k=1}^{\infty} \frac{1}{k^2} = \frac{\pi^2}{6}
                $$</p>
            <p>III. <strong>Alternating Series</strong>:</p>
            <p>An alternating series is a series where the signs of the terms alternate between positive and negative. A famous example is:</p>
            <p>$$
                \sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{k}
                $$</p>
            <p>This series converges to:</p>
            <p>$$
                \sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{k} = \ln(2)
                $$</p>
            <h3 id="examples-of-divergent-series">Examples of Divergent Series</h3>
            <p>I. <strong>Geometric Series with growth factor greater than 1</strong>:</p>
            <p>Consider the geometric series:</p>
            <p>$$
                \sum_{k=1}^{\infty} 4^k = 4 + 16 + 64 + \dots
                $$</p>
            <p>Since the ratio between successive terms is greater than 1, this series diverges as the partial sums grow without bound.</p>
            <p>II. <strong>Arithmetic Series</strong>:</p>
            <p>In an arithmetic series, the difference between successive terms is constant. For example:</p>
            <p>$$
                \sum_{k=1}^{\infty} (2k + 3) = 5 + 7 + 9 + \dots
                $$</p>
            <p>The terms grow linearly, and the series diverges as $n \to \infty$.</p>
            <p>III. <strong>Harmonic Series</strong>:</p>
            <p>The harmonic series is:</p>
            <p>$$
                \sum_{k=1}^{\infty} \frac{1}{k} = 1 + \frac{1}{2} + \frac{1}{3} + \dots
                $$</p>
            <p>Although the terms $\frac{1}{k}$ approach 0 as $k \to \infty$, the sum of the terms grows without bound. Hence, the harmonic series diverges.</p>
            <h3 id="absolute-convergence">Absolute Convergence</h3>
            <p>A series is <strong>absolutely convergent</strong> if the series of the absolute values of its terms is convergent:</p>
            <p>$$
                \sum_{k=1}^{\infty} |a_k|
                $$</p>
            <p><strong>Absolute convergence</strong> implies <strong>convergence</strong>. This is a stronger condition than regular convergence, as a series can converge without being absolutely convergent (for example, alternating series).</p>
            <h3 id="convergence-tests">Convergence Tests</h3>
            <p>When dealing with infinite series, itâ€™s important to determine whether the series converges (approaches a finite value) or diverges (grows without bound or oscillates without settling). To do this, mathematicians use various convergence tests, each suited for different types of series. Below are some of the most commonly used tests for determining whether an infinite series converges or diverges:</p>
            <p>I. <strong>Integral Test</strong>:</p>
            <p>The integral test compares a series to the integral of a continuous, positive, decreasing function. Suppose ${a_n}$ is a sequence and $f(x)$ is a continuous, positive, decreasing function such that $f(n) = a_n$ for all $n \geq 1$. If the integral of $f(x)$ from 1 to infinity converges, then the series converges. Otherwise, the series diverges.</p>
            <p>$$
                \sum_{n=1}^{\infty} a_n \quad \text{converges if and only if} \quad \int_1^{\infty} f(x) \, dx \quad \text{converges}.
                $$</p>
            <p><strong>Example</strong>: Consider the series $\sum_{n=1}^{\infty} \frac{1}{n^2}$. Compare this to the integral $\int_1^{\infty} \frac{1}{x^2} \, dx$, which converges to 1. Hence, the series converges.</p>
            <p>II. <strong>Comparison Test</strong>:</p>
            <p>The comparison test compares the given series to a known convergent or divergent series. If the terms of the series ${a_n}$ are smaller than the terms of a known convergent series ${b_n}$, and all terms are positive, then the series $\sum a_n$ also converges. Similarly, if the terms are larger than those of a known divergent series, the series $\sum a_n$ diverges.</p>
            <p>$$
                0 \leq a_n \leq b_n \quad \text{and} \quad \sum b_n \quad \text{converges} \quad \Rightarrow \quad \sum a_n \quad \text{converges}.
                $$</p>
            <p><strong>Example</strong>: To check if $\sum_{n=1}^{\infty} \frac{1}{n^3 + 2}$ converges, compare it to $\sum_{n=1}^{\infty} \frac{1}{n^3}$, which is a convergent p-series with $p &gt; 1$. Since the terms of $\frac{1}{n^3 + 2}$ are smaller, the series converges by comparison.</p>
            <p>III. <strong>Limit Comparison Test</strong>:</p>
            <p>The limit comparison test is useful when the terms of the series are not directly comparable to a known series but have similar behavior as $n \to \infty$. If the limit of the ratio between the terms of two series is a finite, positive constant, both series either converge or diverge together.</p>
            <p>$$
                \lim_{n \to \infty} \frac{a_n}{b_n} = c \quad \text{where} \quad 0 &lt; c &lt; \infty.
                $$</p>
            <p><strong>Example</strong>: Consider the series $\sum_{n=1}^{\infty} \frac{n^2 + 1}{2n^2 + 3}$. Compare it to $\sum_{n=1}^{\infty} \frac{1}{n^2}$. The limit of the ratio of terms is:</p>
            <p>$$
                \lim_{n \to \infty} \frac{\frac{n^2 + 1}{2n^2 + 3}}{\frac{1}{n^2}} = \frac{1}{2}.
                $$</p>
            <p>Since the comparison series $\sum \frac{1}{n^2}$ converges, the original series also converges.</p>
            <p>IV. <strong>Alternating Series Test (Leibniz's Test)</strong>:</p>
            <p>This test is used for series where the terms alternate in sign. For an alternating series $\sum (-1)^{n} a_n$, if the absolute value of the terms $a_n$ decreases monotonically (i.e., $a_{n+1} \leq a_n$) and $\lim_{n \to \infty} a_n = 0$, then the series converges.</p>
            <p><strong>Example</strong>: Consider the alternating harmonic series $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}$, which is of the form $(-1)^{n+1} \frac{1}{n}$. Since $\frac{1}{n}$ decreases and approaches 0 as $n \to \infty$, the series converges.</p>
            <p>V. <strong>Ratio Test</strong>:</p>
            <p>The ratio test is particularly useful for series involving factorials or exponential terms. To apply the ratio test, compute the limit of the absolute value of the ratio of successive terms:</p>
            <p>$$
                L = \lim_{n \to \infty} \left| \frac{a_{n+1}}{a_n} \right|.
                $$</p>
            <ul>
                <li>If $L &lt; 1$, the series converges.</li>
                <li>If $L &gt; 1$, the series diverges.</li>
                <li>If $L = 1$, the test is inconclusive.</li>
            </ul>
            <p><strong>Example</strong>: For the series $\sum_{n=1}^{\infty} \frac{n!}{n^n}$, applying the ratio test gives:</p>
            <p>$$
                L = \lim_{n \to \infty} \left| \frac{(n+1)!/(n+1)^{n+1}}{n!/n^n} \right| = \lim_{n \to \infty} \frac{(n+1)}{n+1} \cdot \left(\frac{n}{n+1}\right)^n = 0.
                $$</p>
            <p>Since $L = 0$, the series converges.</p>
            <p>VI. <strong>Root Test</strong>:</p>
            <p>The root test, or Cauchy's root test, involves taking the $n$-th root of the absolute value of the terms of the series. Let:</p>
            <p>$$
                L = \lim_{n \to \infty} \sqrt[n]{|a_n|}.
                $$</p>
            <ul>
                <li>If $L &lt; 1$, the series converges.</li>
                <li>If $L &gt; 1$, the series diverges.</li>
                <li>If $L = 1$, the test is inconclusive.</li>
            </ul>
            <p><strong>Example</strong>: For the series $\sum_{n=1}^{\infty} \left(\frac{3}{4}\right)^n$, applying the root test gives:</p>
            <p>$$
                L = \lim_{n \to \infty} \sqrt[n]{\left|\frac{3}{4}\right|^n} = \frac{3}{4}.
                $$</p>
            <p>Since $L = \frac{3}{4} &lt; 1$, the series converges.</p>
            <h3 id="mean-square-convergence">Mean-Square Convergence</h3>
            <p>In the context of stochastic processes, mean-square convergence is an important concept for analyzing the behavior of sequences of random variables. Suppose $X_1, X_2, X_3, \dots$ is a sequence of random variables representing a stochastic process. We say that $X_n$ converges to a random variable $X$ in the <strong>mean-square sense</strong> if the expected value of the squared difference between $X_n$ and $X$ approaches zero as $n$ becomes large. Formally, this is expressed as:</p>
            <p>$$
                \mathbb{E}[(X_n - X)^2] \to 0 \quad \text{as} \quad n \to \infty
                $$</p>
            <p>This definition means that as $n \to \infty$, the random variables $X_n$ become increasingly close to $X$ in the sense of the expected value of their squared differences, providing a measure of convergence in a probabilistic sense.</p>
            <h4 id="inverting-the-ma-1-model">Inverting the MA(1) Model</h4>
            <p>Consider the <strong>MA(1)</strong> (Moving Average of order 1) model, which is commonly used in time series analysis. In this model, the process $X_t$ at time $t$ is defined as:</p>
            <p>$$
                X_t = Z_t + \beta Z_{t-1}
                $$</p>
            <p>where $Z_t$ represents white noise, which is a sequence of independent, identically distributed random variables with zero mean and constant variance $\sigma_Z^2$. The parameter $\beta$ is a constant that defines the relationship between the current observation and the previous white noise term.</p>
            <p>We are interested in expressing $Z_t$ as an infinite sum involving the past values of $X_t$. Through algebraic manipulation, we can express $Z_t$ as:</p>
            <p>$$
                Z_t = \sum_{k=0}^{\infty} (-\beta)^k X_{t-k}
                $$</p>
            <p>This infinite sum can be shown to <strong>converge in the mean-square sense</strong>, provided certain conditions on $\beta$ are satisfied. Specifically, we need to ensure that the sum of these terms remains bounded as $n \to \infty$, which ensures that the approximation $\sum_{k=0}^{n} (-\beta)^k X_{t-k}$ becomes increasingly close to $Z_t$.</p>
            <h4 id="autocovariance-function-of-the-ma-1-process">Autocovariance Function of the MA(1) Process</h4>
            <p>The <strong>autocovariance function</strong> $\gamma(k)$ of a stochastic process measures the covariance between $X_t$ and $X_{t+k}$ for different time lags $k$. For the MA(1) process, the autocovariance function is relatively simple due to the limited memory of the process, which only depends on the current and previous white noise terms.</p>
            <p>The autocovariance function for the MA(1) process is given by:</p>
            <p>$$
                \gamma(k) =
                \begin{cases}
                (1 + \beta^2) \sigma_Z^2, &amp; \text{if } k = 0 \\
                \beta \sigma_Z^2, &amp; \text{if } k = 1 \\
                0, &amp; \text{if } k &gt; 1
                \end{cases}
                $$</p>
            <p>For negative values of $k$, the autocovariance function is symmetric, meaning that $\gamma(-k) = \gamma(k)$.</p>
            <p>This shows that the MA(1) process has non-zero autocovariances only for the first lag (i.e., between $X_t$ and $X_{t-1}$), and beyond that, the covariance is zero due to the white noise properties of $Z_t$.</p>
            <h4 id="series-convergence-in-mean-square-sense">Series Convergence in Mean-Square Sense</h4>
            <p>To investigate the convergence of the infinite series expression for $Z_t$, consider the partial sum of the first $n$ terms:</p>
            <p>$$
                \sum_{k=0}^{n} (-\beta)^k X_{t-k}
                $$</p>
            <p>We want to ensure that this sum converges to $Z_t$ in the mean-square sense. In other words, we need:</p>
            <p>$$
                \mathbb{E}\left[\left(\sum_{k=0}^{n} (-\beta)^k X_{t-k} - Z_t \right)^2\right] \to 0 \quad \text{as} \quad n \to \infty
                $$</p>
            <p>This expression represents the expected value of the squared difference between the partial sum and the true value of $Z_t$, and we aim to show that this difference diminishes as more terms are added to the sum.</p>
            <p>Expanding this expression:</p>
            <p>$$
                \mathbb{E}\left[\left(\sum_{k=0}^{n} (-\beta)^k X_{t-k}\right)^2 - 2\mathbb{E}\left(\sum_{k=0}^{n} (-\beta)^k X_{t-k} Z_t \right) + \mathbb{E}[Z_t^2]\right]
                $$</p>
            <p>Breaking this down into individual terms:
                - The first term involves the expected value of the squared partial sum: $\mathbb{E}\left[\sum_{k=0}^{n} \beta^{2k} X_{t-k}^2\right]$.
                - The second term represents the cross terms between the partial sum and $Z_t$.
                - The third term is the variance of $Z_t$, which is $\sigma_Z^2$.</p>
            <p>To achieve mean-square convergence, the total expression must approach 0 as $n \to \infty$.</p>
            <h4 id="condition-for-convergence">Condition for Convergence</h4>
            <p>For the series to converge in the mean-square sense, we require that the individual terms involving powers of $\beta$ decay sufficiently fast. Specifically, we need:</p>
            <p>$$
                \sigma_Z^2 \beta^{2(n+2)} \to 0 \quad \text{as} \quad n \to \infty
                $$</p>
            <p>This will only occur if:</p>
            <p>$$
                |\beta| &lt; 1
                $$</p>
            <p>When $|\beta| &lt; 1$, the powers of $\beta$ diminish as $n$ increases, ensuring that the sum remains bounded and that the partial sums converge to $Z_t$.</p>
            <h4 id="invertibility-condition">Invertibility Condition</h4>
            <p>The condition $|\beta| &lt; 1$ is also known as the <strong>invertibility condition</strong> for the MA(1) process. This condition guarantees that the moving average process can be expressed as an infinite autoregressive (AR) process. In terms of the polynomial $\beta(B) = 1 + \beta B$ (where $B$ is the backshift operator), the invertibility condition states that the root of the polynomial must lie <strong>outside the unit circle</strong> in the complex plane, meaning:</p>
            <p>$$
                |\beta| &lt; 1
                $$</p>
            <p>Thus, the invertibility condition ensures that the MA(1) process can be uniquely represented as an <strong>AR(âˆž)</strong> process, which is crucial for the identification and estimation of time series models.</p>
        </article-section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#sequences-and-series">Sequences and Series</a>
                <ol>
                    <li><a href="#sequences">Sequences</a>
                        <ol>
                            <li><a href="#examples-of-sequences">Examples of Sequences</a></li>
                        </ol>
                    </li>
                    <li><a href="#partial-sums">Partial Sums</a></li>
                    <li><a href="#series">Series</a></li>
                    <li><a href="#geometric-series-and-rational-functions">Geometric Series and Rational Functions</a></li>
                    <li><a href="#examples-of-convergent-series">Examples of Convergent Series</a></li>
                    <li><a href="#examples-of-divergent-series">Examples of Divergent Series</a></li>
                    <li><a href="#absolute-convergence">Absolute Convergence</a></li>
                    <li><a href="#convergence-tests">Convergence Tests</a></li>
                    <li><a href="#mean-square-convergence">Mean-Square Convergence</a>
                        <ol>
                            <li><a href="#inverting-the-ma-1-model">Inverting the MA(1) Model</a></li>
                            <li><a href="#autocovariance-function-of-the-ma-1-process">Autocovariance Function of the MA(1) Process</a></li>
                            <li><a href="#series-convergence-in-mean-square-sense">Series Convergence in Mean-Square Sense</a></li>
                            <li><a href="#condition-for-convergence">Condition for Convergence</a></li>
                            <li><a href="#invertibility-condition">Invertibility Condition</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/statistical_moments.html">Statistical Moments</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If youâ€™d like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>