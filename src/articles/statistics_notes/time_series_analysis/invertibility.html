<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Invertibility in Time Series Models</title>
    <meta content="In time series modeling, invertibility is the property of a model that allows the innovation process (also called the noise or disturbance process) to be expressed as a function of the observed series and its past values." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>Last modified: September 16, 2024</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="invertibility-in-time-series-models">Invertibility in Time Series Models</h2>
            <p>In time series modeling, <strong>invertibility</strong> is the property of a model that allows the innovation process (also called the noise or disturbance process) to be expressed as a function of the observed series and its past values. This is particularly relevant for <strong>Moving Average (MA)</strong> models.</p>
            <h3 id="intuition-behind-invertibility">Intuition Behind Invertibility</h3>
            <p>Invertibility ensures that a <strong>Moving Average (MA)</strong> model, which expresses the current value of a series as a linear combination of white noise terms, can be transformed into an <strong>Autoregressive (AR)</strong> form. This is crucial because it allows us to use observed data to infer the underlying white noise, making the model estimable and stable.</p>
            <p>An <strong>invertible model</strong> ensures a unique relationship between the observed values of the time series and the underlying innovations. Without invertibility, the same time series could be explained by multiple different models, which makes interpretation and prediction difficult.</p>
            <h3 id="mathematical-definition-of-invertibility">Mathematical Definition of Invertibility</h3>
            <p>Formally, a process ${X_t}$ is said to be <strong>invertible</strong> if the white noise sequence ${Z_t}$ can be expressed as a convergent infinite sum of past observations ${X_t}$:</p>
            <p>$$
                Z_t = \sum_{k=0}^{\infty} \pi_k X_{t-k}
                $$</p>
            <p>where the series $\sum_{k=0}^{\infty} |\pi_k|$ converges.</p>
            <h3 id="why-is-invertibility-important-">Why is Invertibility Important?</h3>
            <p>Invertibility is essential for practical purposes because:</p>
            <ul>
                <li>It ensures that the noise (or shock) sequence $Z_t$ can be uniquely recovered from the observed data.</li>
                <li>It prevents model ambiguity by ensuring a one-to-one correspondence between the observed series and the underlying noise.</li>
                <li>It is necessary for model estimation, as non-invertible models may lead to poor or misleading parameter estimates.</li>
            </ul>
            <p>Invertibility also allows the series to be expressed in an <strong>AR(âˆž)</strong> (AutoRegressive process of infinite order) form, which helps in analysis and forecasting.</p>
            <h3 id="general-conditions-for-invertibility">General Conditions for Invertibility</h3>
            <p>For a <strong>Moving Average (MA)</strong> process to be invertible, the parameters associated with the lagged noise terms must satisfy certain conditions. Specifically, for an MA process of order $q$:</p>
            <p>$$
                X_t = Z_t + \theta_1 Z_{t-1} + \theta_2 Z_{t-2} + \dots + \theta_q Z_{t-q}
                $$</p>
            <p>the model is invertible if and only if the roots of the associated characteristic equation lie outside the unit circle in the complex plane. The characteristic equation is:</p>
            <p>$$
                1 + \theta_1 z + \theta_2 z^2 + \dots + \theta_q z^q = 0
                $$</p>
            <h3 id="example-ma-1-process">Example: MA(1) Process</h3>
            <p>Now let's apply the concept of invertibility to a specific case, the <strong>Moving Average (MA(1))</strong> process.</p>
            <p>Consider an <strong>MA(1)</strong> process:</p>
            <p>$$
                X_t = Z_t + \beta Z_{t-1}
                $$</p>
            <p>where $Z_t$ is white noise with mean 0 and variance $\sigma_Z^2$, and $\beta$ is a constant. To determine the invertibility of this model, we need to express $Z_t$ in terms of $X_t$ and its past values.</p>
            <h4 id="inversion-using-backward-substitution">Inversion Using Backward Substitution</h4>
            <p>We can express $Z_t$ in terms of $X_t$ and its lagged values by backward substitution. Starting from:</p>
            <p>$$
                Z_t = X_t - \beta Z_{t-1}
                $$</p>
            <p>Now substitute $Z_{t-1}$ from the same equation:</p>
            <p>$$
                Z_t = X_t - \beta \left( X_{t-1} - \beta Z_{t-2} \right) = X_t - \beta X_{t-1} + \beta^2 Z_{t-2}
                $$</p>
            <p>Continuing this process:</p>
            <p>$$
                Z_t = X_t - \beta X_{t-1} + \beta^2 X_{t-2} - \beta^3 X_{t-3} + \dots
                $$</p>
            <p>This shows that the <strong>MA(1)</strong> process can be written as an infinite autoregressive process:</p>
            <p>$$
                Z_t = \sum_{k=0}^{\infty} (-\beta)^k X_{t-k}
                $$</p>
            <p>This series converges if $|\beta| &lt; 1$. Therefore, the MA(1) process is <strong>invertible</strong> if $|\beta| &lt; 1$.</p>
            <h4 id="inversion-using-the-backward-shift-operator">Inversion Using the Backward Shift Operator</h4>
            <p>Alternatively, we can use the <strong>backward shift operator</strong> to invert the MA(1) process.</p>
            <p>Given:</p>
            <p>$$
                X_t = (1 + \beta B) Z_t
                $$</p>
            <p>where $B$ is the backward shift operator (i.e., $B Z_t = Z_{t-1}$), we aim to find $Z_t$ in terms of $X_t$ by inverting the operator $1 + \beta B$:</p>
            <p>$$
                Z_t = (1 + \beta B)^{-1} X_t
                $$</p>
            <p>The inverse of $1 + \beta B$ can be expanded as a power series:</p>
            <p>$$
                (1 + \beta B)^{-1} = 1 - \beta B + \beta^2 B^2 - \beta^3 B^3 + \dots
                $$</p>
            <p>Thus, applying this operator to $X_t$, we get:</p>
            <p>$$
                Z_t = X_t - \beta X_{t-1} + \beta^2 X_{t-2} - \beta^3 X_{t-3} + \dots
                $$</p>
            <p>This is the same result obtained by backward substitution. Again, the series converges if $|\beta| &lt; 1$, confirming that the MA(1) process is invertible under this condition.</p>
            <h3 id="example-ma-2-process">Example: MA(2) Process</h3>
            <p>Consider an <strong>MA(2)</strong> process:</p>
            <p>$$
                X_t = Z_t + \theta_1 Z_{t-1} + \theta_2 Z_{t-2}
                $$</p>
            <p>The characteristic equation for this process is:</p>
            <p>$$
                1 + \theta_1 z + \theta_2 z^2 = 0
                $$</p>
            <p>For invertibility, the roots of this equation must lie outside the unit circle. Suppose $\theta_1 = 0.5$ and $\theta_2 = 0.3$. The characteristic equation becomes:</p>
            <p>$$
                1 + 0.5 z + 0.3 z^2 = 0
                $$</p>
            <p>Solving this quadratic equation:</p>
            <p>$$
                z = \frac{-0.5 \pm \sqrt{0.5^2 - 4 \cdot 0.3 \cdot 1}}{2 \cdot 0.3} = \frac{-0.5 \pm \sqrt{0.25 - 1.2}}{0.6}
                $$</p>
            <p>$$
                z = \frac{-0.5 \pm \sqrt{-0.95}}{0.6}
                $$</p>
            <p>Since the discriminant is negative, the roots are complex numbers. The modulus of these complex roots must be greater than 1 for the process to be invertible. If the modulus of the roots is less than 1, the process is not invertible.</p>
            <h3 id="convergence-of-the-series-in-ma-models">Convergence of the Series in MA Models</h3>
            <p>When working with <strong>Moving Average (MA)</strong> models, it's important to ensure that the infinite series we obtain when trying to express the noise term $Z_t$ as a function of past observations $X_t$ converges. This is crucial because we want to guarantee that the process remains stable and well-defined over time.</p>
            <h4 id="understanding-mean-square-convergence">Understanding Mean-Square Convergence</h4>
            <p>In time series analysis, when we express $Z_t$ (the white noise term) as an infinite sum of past values of the observed series $X_t$, we need this sum to <strong>converge in the mean-square sense</strong>. This type of convergence is important because it means that, as we include more and more past terms, the series approaches a stable value in terms of the average squared deviation from the true value of the noise term $Z_t$.</p>
            <p>In the context of an MA(1) model, this means we can write:</p>
            <p>$$
                Z_t = X_t - \beta X_{t-1} + \beta^2 X_{t-2} - \beta^3 X_{t-3} + \dots
                $$</p>
            <p>This representation involves an <strong>infinite series</strong> of lagged values of $X_t$, where each term is weighted by increasing powers of $\beta$. For this series to be <strong>stable</strong> and <strong>convergent</strong>, the terms $\beta^n$ must decay as $n \to \infty$, meaning that as we go further back in time (larger lags), the influence of past values should diminish.</p>
            <h4 id="condition-for-convergence-beta-1-">Condition for Convergence: $|\beta| &lt; 1$</h4>
            <p>For the series to converge in the mean-square sense, the absolute value of $\beta$ must be <strong>less than 1</strong>. This condition ensures that the powers of $\beta$ become progressively smaller as $n$ increases, which in turn guarantees that the terms in the infinite sum $\beta^n X_{t-n}$ shrink in magnitude. If $|\beta| \geq 1$, the terms would grow or remain constant, and the series would fail to converge, leading to instability in the model.</p>
            <p>Letâ€™s break it down:</p>
            <ul>
                <li><strong>If $|\beta| &lt; 1$:</strong> Each successive term $\beta^n$ becomes smaller and smaller as $n$ increases, causing the series to converge to a finite value.</li>
                <li><strong>If $|\beta| = 1$:</strong> The terms do not decay, and the series either oscillates (if $\beta = -1$) or remains constant (if $\beta = 1$).</li>
                <li><strong>If $|\beta| &gt; 1$:</strong> The terms $\beta^n$ grow larger as $n$ increases, causing the series to diverge.</li>
            </ul>
            <p>Therefore, the necessary condition for the <strong>convergence of the series</strong> in an MA(1) process is:</p>
            <p>$$
                |\beta| &lt; 1
                $$</p>
            <p>This ensures that the MA(1) model is <strong>invertible</strong>, meaning we can express the white noise $Z_t$ as a finite sum of past values of $X_t$.</p>
            <h4 id="generalization-to-higher-order-ma-models">Generalization to Higher-Order MA Models</h4>
            <p>The concept of convergence extends to higher-order MA models as well. For an MA(q) model:</p>
            <p>$$
                X_t = Z_t + \theta_1 Z_{t-1} + \theta_2 Z_{t-2} + \dots + \theta_q Z_{t-q}
                $$</p>
            <p>We can express the noise $Z_t$ as an infinite sum of past values of $X_t$ using a similar process. The condition for convergence in this case is that the <strong>roots</strong> of the characteristic polynomial:</p>
            <p>$$
                1 + \theta_1 z + \theta_2 z^2 + \dots + \theta_q z^q = 0
                $$</p>
            <p>must lie <strong>outside the unit circle</strong> in the complex plane. This ensures that the coefficients of the lagged terms (analogous to powers of $\beta$ in MA(1)) decay as we go further back in time, leading to a convergent series.</p>
            <h4 id="example-ma-1-process">Example: MA(1) Process</h4>
            <p>For an MA(1) process:</p>
            <p>$$
                X_t = Z_t + \beta Z_{t-1}
                $$</p>
            <p>Using backward substitution, we express $Z_t$ as an infinite series:</p>
            <p>$$
                Z_t = X_t - \beta X_{t-1} + \beta^2 X_{t-2} - \beta^3 X_{t-3} + \dots
                $$</p>
            <p>The condition for this series to converge is:</p>
            <p>$$
                |\beta| &lt; 1
                $$</p>
            <p>This ensures that the terms $\beta^n$ decay as $n \to \infty$, leading to convergence of the series. In practical terms, if $|\beta|$ is too large, the influence of past values remains strong, and the infinite series becomes unstable and non-convergent.</p>
            <p>Thus, for any MA process, ensuring that the absolute values of the coefficients of the lagged noise terms are <strong>less than 1</strong> is a key requirement for convergence and invertibility.</p>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#invertibility-in-time-series-models">Invertibility in Time Series Models</a>
                <ol>
                    <li><a href="#intuition-behind-invertibility">Intuition Behind Invertibility</a></li>
                    <li><a href="#mathematical-definition-of-invertibility">Mathematical Definition of Invertibility</a></li>
                    <li><a href="#why-is-invertibility-important-">Why is Invertibility Important?</a></li>
                    <li><a href="#general-conditions-for-invertibility">General Conditions for Invertibility</a></li>
                    <li><a href="#example-ma-1-process">Example: MA(1) Process</a>
                        <ol>
                            <li><a href="#inversion-using-backward-substitution">Inversion Using Backward Substitution</a></li>
                            <li><a href="#inversion-using-the-backward-shift-operator">Inversion Using the Backward Shift Operator</a></li>
                        </ol>
                    </li>
                    <li><a href="#example-ma-2-process">Example: MA(2) Process</a></li>
                    <li><a href="#convergence-of-the-series-in-ma-models">Convergence of the Series in MA Models</a>
                        <ol>
                            <li><a href="#understanding-mean-square-convergence">Understanding Mean-Square Convergence</a></li>
                            <li><a href="#condition-for-convergence-beta-1-">Condition for Convergence: $|\beta| &lt; 1$</a></li>
                            <li><a href="#generalization-to-higher-order-ma-models">Generalization to Higher-Order MA Models</a></li>
                            <li><a href="#example-ma-1-process">Example: MA(1) Process</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>