<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Covariance</title>
    <meta content="Covariance is a fundamental statistical measure that quantifies the degree to which two random variables change together." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: December 23, 2023</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <header>Covariance</header>
            <p>Covariance is a fundamental statistical measure that quantifies the degree to which two random variables change together. It indicates the direction of the linear relationship between variables:</p>
            <ul>
                <li>A <strong>positive covariance</strong> implies that as one variable increases, the other tends to increase as well.</li>
                <li>A <strong>negative covariance</strong> suggests that as one variable increases, the other tends to decrease.</li>
                <li>A <strong>zero covariance</strong> indicates no linear relationship between the variables.</li>
            </ul>
            <h2 id="definition">Definition</h2>
            <p>The <strong>covariance</strong> between two random variables $X$ and $Y$ is defined as the expected value (mean) of the product of their deviations from their respective means:</p>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}\left[ (X - \mu_X)(Y - \mu_Y) \right]
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$\text{Cov}(X, Y)$ is the covariance between $X$ and $Y$.</li>
                <li>$\mathbb{E}$ denotes the expected value operator.</li>
                <li>$\mu_X = \mathbb{E}[X]$ is the mean of $X$.</li>
                <li>$\mu_Y = \mathbb{E}[Y]$ is the mean of $Y$.</li>
            </ul>
            <h3 id="alternative-expression">Alternative Expression</h3>
            <p>By expanding the definition and applying the linearity properties of expectation, covariance can also be expressed as:</p>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X] \mathbb{E}[Y]
                $$</p>
            <p><strong>Derivation</strong>:</p>
            <ol>
                <li>Start with the definition:</li>
            </ol>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}\left[ (X - \mu_X)(Y - \mu_Y) \right]
                $$</p>
            <ol>
                <li>Expand the product inside the expectation:</li>
            </ol>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}\left[ XY - X \mu_Y - \mu_X Y + \mu_X \mu_Y \right]
                $$</p>
            <ol>
                <li>Use the linearity of expectation:</li>
            </ol>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}[XY] - \mu_Y \mathbb{E}[X] - \mu_X \mathbb{E}[Y] + \mu_X \mu_Y
                $$</p>
            <ol>
                <li>Recognize that $\mu_X = \mathbb{E}[X]$ and $\mu_Y = \mathbb{E}[Y]$:</li>
            </ol>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}[XY] - \mu_Y \mu_X - \mu_X \mu_Y + \mu_X \mu_Y = \mathbb{E}[XY] - \mu_X \mu_Y
                $$</p>
            <p>Thus, we arrive at:</p>
            <p>$$
                \text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X] \mathbb{E}[Y]
                $$</p>
            <h3 id="interpretation">Interpretation</h3>
            <ul>
                <li><strong>Positive Covariance ($\text{Cov}(X, Y) &gt; 0 $)</strong>: Indicates that $X$ and $Y$ tend to increase or decrease together.</li>
                <li><strong>Negative Covariance ($\text{Cov}(X, Y) &lt; 0 $)</strong>: Indicates that when $X$ increases, $Y$ tends to decrease, and vice versa.</li>
                <li><strong>Zero Covariance ($\text{Cov}(X, Y) = 0 $)</strong>: Suggests no linear relationship between $X$ and $Y$.</li>
            </ul>
            <p><strong>Important Note</strong>:</p>
            <ul>
                <li>If $X$ and $Y$ are <strong>independent</strong>, then $\text{Cov}(X, Y) = 0 $.</li>
                <li>However, a covariance of zero does <strong>not</strong> necessarily imply independence. Variables can be uncorrelated (zero covariance) but still dependent in a non-linear way.</li>
            </ul>
            <h2 id="properties-of-covariance">Properties of Covariance</h2>
            <p>I. <strong>Symmetry</strong>:</p>
            <p>$$
                \text{Cov}(X, Y) = \text{Cov}(Y, X)
                $$</p>
            <p>II. <strong>Linearity in Each Argument</strong>:</p>
            <p>For constants $a$ and $b$, and random variables $X$, $Y$, and $Z$:</p>
            <p>$$
                \text{Cov}(aX + bY, Z) = a \text{Cov}(X, Z) + b \text{Cov}(Y, Z)
                $$</p>
            <p>III. <strong>Covariance with Itself (Variance Relation)</strong>:</p>
            <p>The covariance of a variable with itself is the variance of that variable:</p>
            <p>$$
                \text{Cov}(X, X) = \text{Var}(X)
                $$</p>
            <p>IV. <strong>Scaling</strong>:</p>
            <p>If $a$ and $b$ are constants:</p>
            <p>$$
                \text{Cov}(aX, bY) = ab \text{Cov}(X, Y)
                $$</p>
            <p>V. <strong>Addition of Constants</strong>:</p>
            <p>Adding a constant to a variable does not affect the covariance:</p>
            <p>$$
                \text{Cov}(X + c, Y) = \text{Cov}(X, Y)
                $$</p>
            <p>VI. <strong>Relationship with Correlation</strong>:</p>
            <p>Covariance is related to the correlation coefficient $\rho_{XY}$:</p>
            <p>$$
                \rho_{XY} = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
                $$</p>
            <p>Where $\sigma_X$ and $\sigma_Y$ are the standard deviations of $X$ and $Y$, respectively.</p>
            <h2 id="sample-covariance">Sample Covariance</h2>
            <p>When working with sample data, the sample covariance between two variables $X$ and $Y$ is calculated as:</p>
            <p>$$
                s_{XY} = \text{Cov}(X, Y) = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y})
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$n$ is the number of observations.</li>
                <li>$X_i$ and $Y_i$ are the $i$-th observations of variables $X$ and $Y$.</li>
                <li>$\bar{X}$ and $\bar{Y}$ are the sample means of $X$ and $Y$.</li>
            </ul>
            <p><strong>Note</strong>: The denominator $n - 1$ provides an unbiased estimate of the covariance for a sample drawn from a population.</p>
            <h2 id="example-calculating-covariance-step-by-step">Example: Calculating Covariance Step by Step</h2>
            <p>Let's calculate the covariance between two variables $X$ and $Y$ using the following dataset:</p>
            <p>
            <table>
                <tr>
                    <td>Observation ($i$)</td>
                    <td>$X_i$</td>
                    <td>$Y_i$</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>1</td>
                    <td>2</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>2</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>3</td>
                    <td>6</td>
                </tr>
            </table>
            </p>
            <h3 id="step-1-calculate-the-sample-means">Step 1: Calculate the Sample Means</h3>
            <p>Compute the mean of $X$ and $Y$:</p>
            <p>$$
                \bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i = \frac{1 + 2 + 3}{3} = \frac{6}{3} = 2
                $$</p>
            <p>$$
                \bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i = \frac{2 + 4 + 6}{3} = \frac{12}{3} = 4
                $$</p>
            <h3 id="step-2-compute-the-deviations-from-the-mean">Step 2: Compute the Deviations from the Mean</h3>
            <p>Calculate $(X_i - \bar{X})$ and $(Y_i - \bar{Y})$:</p>
            <p>
            <table>
                <tr>
                    <td>$i$</td>
                    <td>$X_i$</td>
                    <td>$Y_i$</td>
                    <td>$X_i - \bar{X}$</td>
                    <td>$Y_i - \bar{Y}$</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>1</td>
                    <td>2</td>
                    <td>$1 - 2 = -1$</td>
                    <td>$2 - 4 = -2 $</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>2</td>
                    <td>4</td>
                    <td>$2 - 2 = 0 $</td>
                    <td>$4 - 4 = 0 $</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>3</td>
                    <td>6</td>
                    <td>$3 - 2 = 1$</td>
                    <td>$6 - 4 = 2 $</td>
                </tr>
            </table>
            </p>
            <h3 id="step-3-calculate-the-product-of-deviations">Step 3: Calculate the Product of Deviations</h3>
            <p>Compute $(X_i - \bar{X})(Y_i - \bar{Y})$:</p>
            <p>
            <table>
                <tr>
                    <td>$i$</td>
                    <td>$X_i - \bar{X}$</td>
                    <td>$Y_i - \bar{Y}$</td>
                    <td>$(X_i - \bar{X})(Y_i - \bar{Y})$</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>-1</td>
                    <td>-2</td>
                    <td>$(-1)(-2) = 2 $</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>0</td>
                    <td>0</td>
                    <td>$(0)(0) = 0 $</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>1</td>
                    <td>2</td>
                    <td>$(1)(2) = 2 $</td>
                </tr>
            </table>
            </p>
            <h3 id="step-4-sum-the-products-of-deviations">Step 4: Sum the Products of Deviations</h3>
            <p>Compute the sum:</p>
            <p>$$
                \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y}) = 2 + 0 + 2 = 4
                $$</p>
            <h3 id="step-5-calculate-the-sample-covariance">Step 5: Calculate the Sample Covariance</h3>
            <p>Use the sample covariance formula:</p>
            <p>$$
                s_{XY} = \text{Cov}(X, Y) = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y})
                $$</p>
            <p>Since $n = 3 $:</p>
            <p>$$
                s_{XY} = \frac{1}{3 - 1} \times 4 = \frac{1}{2} \times 4 = 2
                $$</p>
            <p>Interpretation:</p>
            <ul>
                <li>The positive covariance of $2 $ indicates that $X$ and $Y$ tend to increase together.</li>
                <li>Since the data points lie perfectly on a straight line ($Y = 2X$), the covariance reflects a perfect positive linear relationship.</li>
            </ul>
            <h3 id="step-6-calculate-the-variances-optional-">Step 6: Calculate the Variances (Optional)</h3>
            <p>For completeness, calculate the variances of $X$ and $Y$:</p>
            <h4 id="variance-of-x-">Variance of $X$</h4>
            <p>$$
                s_{XX} = \text{Var}(X) = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \bar{X})^2
                $$</p>
            <p>Compute $(X_i - \bar{X})^2 $:</p>
            <p>
            <table>
                <tr>
                    <td>$i$</td>
                    <td>$X_i - \bar{X}$</td>
                    <td>$(X_i - \bar{X})^2 $</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>-1</td>
                    <td>$(-1)^2 = 1$</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>0</td>
                    <td>$(0)^2 = 0 $</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>1</td>
                    <td>$(1)^2 = 1$</td>
                </tr>
            </table>
            </p>
            <p>Sum:</p>
            <p>$$
                \sum_{i=1}^{n} (X_i - \bar{X})^2 = 1 + 0 + 1 = 2
                $$</p>
            <p>Compute variance:</p>
            <p>$$
                s_{XX} = \frac{1}{2} \times 2 = 1
                $$</p>
            <h4 id="variance-of-y-">Variance of $Y$</h4>
            <p>Similarly, compute $(Y_i - \bar{Y})^2 $:</p>
            <p>
            <table>
                <tr>
                    <td>$i$</td>
                    <td>$Y_i - \bar{Y}$</td>
                    <td>$(Y_i - \bar{Y})^2 $</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>-2</td>
                    <td>$(-2)^2 = 4 $</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>0</td>
                    <td>$(0)^2 = 0 $</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>2</td>
                    <td>$(2)^2 = 4 $</td>
                </tr>
            </table>
            </p>
            <p>Sum:</p>
            <p>$$
                \sum_{i=1}^{n} (Y_i - \bar{Y})^2 = 4 + 0 + 4 = 8
                $$</p>
            <p>Compute variance:</p>
            <p>$$
                s_{YY} = \text{Var}(Y) = \frac{1}{2} \times 8 = 4
                $$</p>
            <h3 id="step-7-calculate-the-correlation-coefficient-optional-">Step 7: Calculate the Correlation Coefficient (Optional)</h3>
            <p>The correlation coefficient $r_{XY}$ standardizes the covariance, providing a dimensionless measure of the strength and direction of the linear relationship:</p>
            <p>$$
                r_{XY} = \frac{s_{XY}}{\sqrt{s_{XX} \times s_{YY}}} = \frac{2}{\sqrt{1 \times 4}} = \frac{2}{2} = 1
                $$</p>
            <p>Interpretation:</p>
            <ul>
                <li>A correlation coefficient of $1$ indicates a perfect positive linear relationship between $X$ and $Y$.</li>
                <li>This makes sense since $Y = 2X$ in the dataset.</li>
            </ul>
            <p>Plot:</p>
            <p><img alt="output(13)" src="https://github.com/user-attachments/assets/85baa5bd-7459-4d06-ad4c-6c514eac3899" /></p>
            <h2 id="limitations-of-covariance">Limitations of Covariance</h2>
            <p>I. <strong>Scale Dependence</strong>:</p>
            <ul>
                <li>Covariance values are affected by the units of measurement of the variables.</li>
                <li>For example, measuring height in meters vs. centimeters will change the covariance.</li>
            </ul>
            <p>II. <strong>Comparison Difficulties</strong>:</p>
            <ul>
                <li>Because covariance is not standardized, comparing covariances across different datasets or variables with different scales is challenging.</li>
                <li>This is why the <strong>correlation coefficient</strong>, which standardizes covariance, is often used.</li>
            </ul>
            <p>III. <strong>Not a Measure of Strength</strong>:</p>
            <ul>
                <li>The magnitude of covariance does not directly indicate the strength of the relationship.</li>
                <li>A large covariance could be due to large variances rather than a strong relationship.</li>
            </ul>
            <p>IV. <strong>Linear Relationships Only</strong>:</p>
            <ul>
                <li>Covariance measures only linear relationships.</li>
                <li>It does not capture non-linear dependencies between variables.</li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol>
                <li><a href="#definition">Definition</a>
                    <ol>
                        <li><a href="#alternative-expression">Alternative Expression</a></li>
                        <li><a href="#interpretation">Interpretation</a></li>
                    </ol>
                </li>
                <li><a href="#properties-of-covariance">Properties of Covariance</a></li>
                <li><a href="#sample-covariance">Sample Covariance</a></li>
                <li><a href="#example-calculating-covariance-step-by-step">Example: Calculating Covariance Step by Step</a>
                    <ol>
                        <li><a href="#step-1-calculate-the-sample-means">Step 1: Calculate the Sample Means</a></li>
                        <li><a href="#step-2-compute-the-deviations-from-the-mean">Step 2: Compute the Deviations from the Mean</a></li>
                        <li><a href="#step-3-calculate-the-product-of-deviations">Step 3: Calculate the Product of Deviations</a></li>
                        <li><a href="#step-4-sum-the-products-of-deviations">Step 4: Sum the Products of Deviations</a></li>
                        <li><a href="#step-5-calculate-the-sample-covariance">Step 5: Calculate the Sample Covariance</a></li>
                        <li><a href="#step-6-calculate-the-variances-optional-">Step 6: Calculate the Variances (Optional)</a>
                            <ol>
                                <li><a href="#variance-of-x-">Variance of $X$</a></li>
                                <li><a href="#variance-of-y-">Variance of $Y$</a></li>
                            </ol>
                        </li>
                        <li><a href="#step-7-calculate-the-correlation-coefficient-optional-">Step 7: Calculate the Correlation Coefficient (Optional)</a></li>
                    </ol>
                </li>
                <li><a href="#limitations-of-covariance">Limitations of Covariance</a></li>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/statistical_moments.html">Statistical Moments</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All content here is free to use,
                    but please remember to be respectful and avoid any misuse of the site.
                    If youâ€™d like to get in touch, feel free to reach out via my
                    <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a>
                    or connect with me on
                    <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a>
                    if you have technical questions or ideas to share.
                    Wishing you all the best and a fantastic life ahead!
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>