<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Logistic Regression</title>
    <meta content="Logistic regression is a statistical method used for modeling the probability of a binary outcome based on one or more predictor variables." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: April 02, 2024</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <header>Logistic Regression</header>
            <p>Logistic regression is a statistical method used for modeling the probability of a binary outcome based on one or more predictor variables. It is widely used in various fields such as medicine, social sciences, and machine learning for classification problems where the dependent variable is dichotomous (e.g., success/failure, yes/no, positive/negative).</p>
            <h2 id="the-logistic-regression-model">The Logistic Regression Model</h2>
            <h3 id="binary-outcomes">Binary Outcomes</h3>
            <p>In logistic regression, the dependent variable $y $ takes on binary values:</p>
            <p>$$
                y_i = \begin{cases}
                1 &amp; \text{if event occurs (e.g., success)} \\
                0 &amp; \text{if event does not occur (e.g., failure)}
                \end{cases}
                $$</p>
            <h3 id="logistic-function-sigmoid-function-">Logistic Function (Sigmoid Function)</h3>
            <p>The logistic function models the probability that $y = 1$ given the predictor variables $x_1, x_2, \dots, x_p $:</p>
            <p>$$
                p(x) = P(y = 1 \mid x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p)}}
                $$</p>
            <p>This function maps any real-valued number into a value between 0 and 1, making it suitable for probability estimation.</p>
            <h3 id="odds-and-logit-function">Odds and Logit Function</h3>
            <p>The <strong>odds</strong> of an event occurring is the ratio of the probability that the event occurs to the probability that it does not occur.</p>
            <p>$$
                \text{Odds}(x) = \frac{p(x)}{1 - p(x)}
                $$</p>
            <p>The natural logarithm of the odds is called the <strong>logit function</strong>.</p>
            <p>$$
                \text{logit}(p(x)) = \ln \left( \frac{p(x)}{1 - p(x)} \right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p
                $$</p>
            <p>The logit function establishes a linear relationship between the predictor variables and the log-odds of the outcome.</p>
            <h3 id="interpretation-of-coefficients">Interpretation of Coefficients</h3>
            <ul>
                <li>The <strong>intercept ($\beta_0$)</strong> represents the log-odds of the outcome when all predictor variables are zero.</li>
                <li>The <strong>coefficients ($\beta_j$)</strong> indicate the change in the log-odds of the outcome for a one-unit increase in $x_j$, while keeping all other variables constant.</li>
            </ul>
            <p>Exponentiating the coefficients provides the <strong>odds ratios</strong>:</p>
            <p>$$
                \text{Odds Ratio for } x_j = e^{\beta_j}
                $$</p>
            <p>An odds ratio greater than 1 indicates that as $x_j $ increases, the odds of the outcome occurring increase.</p>
            <h2 id="estimation-of-coefficients">Estimation of Coefficients</h2>
            <p>Unlike linear regression, logistic regression does not have a closed-form solution for estimating the coefficients. Instead, coefficients are estimated using <strong>Maximum Likelihood Estimation (MLE)</strong>.</p>
            <h3 id="likelihood-function">Likelihood Function</h3>
            <p>Given $n $ independent observations, the likelihood function $L(\boldsymbol{\beta})$ is the product of the probabilities of observing the data:</p>
            <p>$$
                L(\boldsymbol{\beta}) = \prod_{i=1}^{n} [p(x_i)]^{y_i} [1 - p(x_i)]^{1 - y_i}
                $$</p>
            <h3 id="log-likelihood-function">Log-Likelihood Function</h3>
            <p>Taking the natural logarithm simplifies the product into a sum:</p>
            <p>$$
                \ell(\boldsymbol{\beta}) = \ln L(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[ y_i \ln p(x_i) + (1 - y_i) \ln (1 - p(x_i)) \right]
                $$</p>
            <h3 id="maximizing-the-log-likelihood">Maximizing the Log-Likelihood</h3>
            <p>The goal is to find the coefficients $\boldsymbol{\beta}$ that maximize $\ell(\boldsymbol{\beta})$. This is typically done using iterative numerical methods such as:</p>
            <ul>
                <li>Newton-Raphson method</li>
                <li>Fisher Scoring</li>
                <li>Gradient Descent</li>
            </ul>
            <h3 id="newton-raphson-method">Newton-Raphson Method</h3>
            <p>An iterative method that updates the coefficient estimates using:</p>
            <p>$$
                \boldsymbol{\beta}^{(k+1)} = \boldsymbol{\beta}^{(k)} - [\mathbf{H}(\boldsymbol{\beta}^{(k)})]^{-1} \mathbf{g}(\boldsymbol{\beta}^{(k)})
                $$</p>
            <p>Where:</p>
            <ul>
                <li>$\mathbf{g}(\boldsymbol{\beta})$ is the gradient (first derivative) of the log-likelihood function.</li>
                <li>$\mathbf{H}(\boldsymbol{\beta})$ is the Hessian matrix (second derivative) of the log-likelihood function.</li>
            </ul>
            <h2 id="assumptions-of-logistic-regression">Assumptions of Logistic Regression</h2>
            <ol>
                <li>The <strong>binary outcome</strong> indicates that the dependent variable has two possible values.</li>
                <li><strong>Independent observations</strong> ensure that each data point is independent of the others.</li>
                <li><strong>Linearity in log-odds</strong> means that the logit of the outcome is a linear function of the predictor variables.</li>
                <li><strong>No multicollinearity</strong> ensures that the predictor variables are not highly correlated with each other.</li>
                <li>A <strong>large sample size</strong> is preferred, as maximum likelihood estimation (MLE) performs better with more data.</li>
            </ol>
            <h2 id="example">Example</h2>
            <h3 id="problem-statement">Problem Statement</h3>
            <p>We aim to predict whether a student will pass a test ($y = 1$) or fail ($y = 0 $) based on:</p>
            <ul>
                <li>$x_1$: Number of hours studied</li>
                <li>$x_2$: Number of practice exams taken</li>
            </ul>
            <h3 id="data">Data</h3>
            <p>
            <table>
                <tr>
                    <td>Student ($i $)</td>
                    <td>Hours Studied ($x_{1i}$)</td>
                    <td>Practice Exams ($x_{2i}$)</td>
                    <td>Pass ($y_i $)</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>2</td>
                    <td>1</td>
                    <td>0</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>4</td>
                    <td>2</td>
                    <td>0</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>5</td>
                    <td>2</td>
                    <td>1</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td>6</td>
                    <td>3</td>
                    <td>1</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td>8</td>
                    <td>4</td>
                    <td>1</td>
                </tr>
            </table>
            </p>
            <h3 id="step-by-step-estimation">Step-by-Step Estimation</h3>
            <h4 id="1-initial-setup">1. Initial Setup</h4>
            <p>We need to estimate $\beta_0 $, $\beta_1$, and $\beta_2$ in the logistic regression model:</p>
            <p>$$
                p(x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2)}}
                $$</p>
            <h4 id="2-construct-the-design-matrix-and-response-vector">2. Construct the Design Matrix and Response Vector</h4>
            <p>Let $\mathbf{X}$ be the design matrix including the intercept term:</p>
            <p>$$
                \mathbf{X} = \begin{bmatrix}
                1 &amp; x_{11} &amp; x_{21} \\
                1 &amp; x_{12} &amp; x_{22} \\
                1 &amp; x_{13} &amp; x_{23} \\
                1 &amp; x_{14} &amp; x_{24} \\
                1 &amp; x_{15} &amp; x_{25} \\
                \end{bmatrix} = \begin{bmatrix}
                1 &amp; 2 &amp; 1 \\
                1 &amp; 4 &amp; 2 \\
                1 &amp; 5 &amp; 2 \\
                1 &amp; 6 &amp; 3 \\
                1 &amp; 8 &amp; 4 \\
                \end{bmatrix}
                $$</p>
            <p>Response vector $\mathbf{y}$:</p>
            <p>$$
                \mathbf{y} = \begin{bmatrix}
                0 \\
                0 \\
                1 \\
                1 \\
                1 \\
                \end{bmatrix}
                $$</p>
            <h4 id="3-initialize-coefficients">3. Initialize Coefficients</h4>
            <p>Start with initial guesses for $\boldsymbol{\beta}$, say:</p>
            <p>$$
                \boldsymbol{\beta}^{(0)} = \begin{bmatrix}
                \beta_0^{(0)} \\
                \beta_1^{(0)} \\
                \beta_2^{(0)} \\
                \end{bmatrix} = \begin{bmatrix}
                0 \\
                0 \\
                0 \\
                \end{bmatrix}
                $$</p>
            <h4 id="4-iterative-optimization-simplified-explanation-">4. Iterative Optimization (Simplified Explanation)</h4>
            <p>Due to the complexity of MLE calculations, we will provide a simplified explanation. In practice, statistical software performs these calculations.</p>
            <p><strong>Iteration Steps</strong>:</p>
            <ul>
                <li>Compute predicted probabilities $p_i^{(k)}$ using current coefficients.</li>
            </ul>
            <p>$$
                p_i^{(k)} = \frac{1}{1 + e^{-(\beta_0^{(k)} + \beta_1^{(k)} x_{1i} + \beta_2^{(k)} x_{2i})}}
                $$</p>
            <ul>
                <li>Compute the gradient $\mathbf{g}(\boldsymbol{\beta}^{(k)})$ and Hessian $\mathbf{H}(\boldsymbol{\beta}^{(k)})$.</li>
                <li>Update coefficients using the Newton-Raphson formula.</li>
                <li>The process continues until the change in the log-likelihood or coefficients is below a predefined threshold.</li>
            </ul>
            <h4 id="5-estimated-coefficients">5. Estimated Coefficients</h4>
            <p>Assuming the optimization converges, we obtain estimated coefficients (using statistical software):</p>
            <p>$$
                \hat{\beta}_0 = -9.28, \quad \hat{\beta}_1 = 1.23, \quad \hat{\beta}_2 = 0.98
                $$</p>
            <h4 id="6-logistic-regression-equation">6. Logistic Regression Equation</h4>
            <p>$$
                p(x) = \frac{1}{1 + e^{-(-9.28 + 1.23 x_1 + 0.98 x_2)}}
                $$</p>
            <h3 id="interpretation-of-coefficients">Interpretation of Coefficients</h3>
            <p><strong>Intercept ($\beta_0 = -9.28$)</strong>: The log-odds of passing when $x_1 = 0 $ and $x_2 = 0 $.</p>
            <p><strong>Coefficient for Hours Studied ($\beta_1 = 1.23$)</strong>: For each additional hour studied, the log-odds of passing increase by 1.23 units, holding $x_2$ constant.</p>
            <p><strong>Odds Ratio</strong>:</p>
            <p>$$
                e^{1.23} \approx 3.42
                $$</p>
            <p>The odds of passing are approximately 3.42 times higher for each additional hour studied.</p>
            <p><strong>Coefficient for Practice Exams ($\beta_2 = 0.98$)</strong>: For each additional practice exam taken, the log-odds of passing increase by 0.98 units, holding $x_1$ constant.</p>
            <p><strong>Odds Ratio</strong>:</p>
            <p>$$
                e^{0.98} \approx 2.66
                $$</p>
            <p>The odds of passing are approximately 2.66 times higher for each additional practice exam taken.</p>
            <h3 id="predicting-probabilities">Predicting Probabilities</h3>
            <h4 id="predict-for-a-student-who-studied-5-hours-and-took-2-practice-exams">Predict for a Student Who Studied 5 Hours and Took 2 Practice Exams</h4>
            <p>Compute the probability of passing:</p>
            <p>$$
                p = \frac{1}{1 + e^{-(-9.28 + 1.23 \times 5 + 0.98 \times 2)}} = \frac{1}{1 + e^{-(-9.28 + 6.15 + 1.96)}} = \frac{1}{1 + e^{-(-1.17)}} = \frac{1}{1 + e^{1.17}} \approx 0.24
                $$</p>
            <p>The probability of passing is approximately 24%.</p>
            <h4 id="predict-for-a-student-who-studied-7-hours-and-took-3-practice-exams">Predict for a Student Who Studied 7 Hours and Took 3 Practice Exams</h4>
            <p>$$
                p = \frac{1}{1 + e^{-(-9.28 + 1.23 \times 7 + 0.98 \times 3)}} = \frac{1}{1 + e^{-(-9.28 + 8.61 + 2.94)}} = \frac{1}{1 + e^{-2.27}} = \frac{1}{1 + e^{-2.27}} \approx 0.906
                $$</p>
            <p>The probability of passing is approximately 90.6%.</p>
            <p>Plot:</p>
            <p><img alt="output(14)" src="https://github.com/user-attachments/assets/5b72e473-e273-408a-a1db-d71e2a8f924b" /></p>
            <h3 id="model-evaluation">Model Evaluation</h3>
            <h4 id="confusion-matrix">Confusion Matrix</h4>
            <p>Using a threshold of 0.5 to classify predictions:</p>
            <p>
            <table>
                <tr>
                    <td>Student ($i $)</td>
                    <td>$y_i $</td>
                    <td>Predicted $p_i $</td>
                    <td>Predicted Class ($\hat{y}_i $)</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>0</td>
                    <td>$p_1 \approx 0.005 $</td>
                    <td>0</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>0</td>
                    <td>$p_2 \approx 0.046 $</td>
                    <td>0</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>1</td>
                    <td>$p_3 \approx 0.24 $</td>
                    <td>0</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td>1</td>
                    <td>$p_4 \approx 0.82$</td>
                    <td>1</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td>1</td>
                    <td>$p_5 \approx 0.99 $</td>
                    <td>1</td>
                </tr>
            </table>
            </p>
            <ul>
                <li><strong>True Positives (TP)</strong>: 2 (Students 4 and 5)</li>
                <li><strong>True Negatives (TN)</strong>: 2 (Students 1 and 2)</li>
                <li><strong>False Negatives (FN)</strong>: 1 (Student 3)</li>
                <li><strong>False Positives (FP)</strong>: 0</li>
            </ul>
            <h4 id="accuracy">Accuracy</h4>
            <p>$$
                \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total}} = \frac{2 + 2}{5} = 0.8
                $$</p>
            <h4 id="precision">Precision</h4>
            <p>$$
                \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} = \frac{2}{2 + 0} = 1.0
                $$</p>
            <h4 id="recall-sensitivity-">Recall (Sensitivity)</h4>
            <p>$$
                \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} = \frac{2}{2 + 1} = \frac{2}{3} \approx 0.667
                $$</p>
            <h4 id="f1-score">F1 Score</h4>
            <p>$$
                \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = 2 \times \frac{1.0 \times 0.667}{1.0 + 0.667} \approx 0.8
                $$</p>
            <h3 id="receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) Curve</h3>
            <ul>
                <li>Plotting True Positive Rate (Recall) vs. False Positive Rate at various thresholds.</li>
                <li>Calculate Area Under the ROC Curve (AUC) to assess model performance.</li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol>
                <li><a href="#the-logistic-regression-model">The Logistic Regression Model</a>
                    <ol>
                        <li><a href="#binary-outcomes">Binary Outcomes</a></li>
                        <li><a href="#logistic-function-sigmoid-function-">Logistic Function (Sigmoid Function)</a></li>
                        <li><a href="#odds-and-logit-function">Odds and Logit Function</a></li>
                        <li><a href="#interpretation-of-coefficients">Interpretation of Coefficients</a></li>
                    </ol>
                </li>
                <li><a href="#estimation-of-coefficients">Estimation of Coefficients</a>
                    <ol>
                        <li><a href="#likelihood-function">Likelihood Function</a></li>
                        <li><a href="#log-likelihood-function">Log-Likelihood Function</a></li>
                        <li><a href="#maximizing-the-log-likelihood">Maximizing the Log-Likelihood</a></li>
                        <li><a href="#newton-raphson-method">Newton-Raphson Method</a></li>
                    </ol>
                </li>
                <li><a href="#assumptions-of-logistic-regression">Assumptions of Logistic Regression</a></li>
                <li><a href="#example">Example</a>
                    <ol>
                        <li><a href="#problem-statement">Problem Statement</a></li>
                        <li><a href="#data">Data</a></li>
                        <li><a href="#step-by-step-estimation">Step-by-Step Estimation</a>
                            <ol>
                                <li><a href="#1-initial-setup">1. Initial Setup</a></li>
                                <li><a href="#2-construct-the-design-matrix-and-response-vector">2. Construct the Design Matrix and Response Vector</a></li>
                                <li><a href="#3-initialize-coefficients">3. Initialize Coefficients</a></li>
                                <li><a href="#4-iterative-optimization-simplified-explanation-">4. Iterative Optimization (Simplified Explanation)</a></li>
                                <li><a href="#5-estimated-coefficients">5. Estimated Coefficients</a></li>
                                <li><a href="#6-logistic-regression-equation">6. Logistic Regression Equation</a></li>
                            </ol>
                        </li>
                        <li><a href="#interpretation-of-coefficients">Interpretation of Coefficients</a></li>
                        <li><a href="#predicting-probabilities">Predicting Probabilities</a>
                            <ol>
                                <li><a href="#predict-for-a-student-who-studied-5-hours-and-took-2-practice-exams">Predict for a Student Who Studied 5 Hours and Took 2 Practice Exams</a></li>
                                <li><a href="#predict-for-a-student-who-studied-7-hours-and-took-3-practice-exams">Predict for a Student Who Studied 7 Hours and Took 3 Practice Exams</a></li>
                            </ol>
                        </li>
                        <li><a href="#model-evaluation">Model Evaluation</a>
                            <ol>
                                <li><a href="#confusion-matrix">Confusion Matrix</a></li>
                                <li><a href="#accuracy">Accuracy</a></li>
                                <li><a href="#precision">Precision</a></li>
                                <li><a href="#recall-sensitivity-">Recall (Sensitivity)</a></li>
                                <li><a href="#f1-score">F1 Score</a></li>
                            </ol>
                        </li>
                        <li><a href="#receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) Curve</a></li>
                    </ol>
                </li>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Basic Concepts<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/axioms_of_probability.html">Axioms of Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayes_theorem.html">Bayes Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/bayesian_vs_frequentist.html">Bayesian vs Frequentist</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/conditional_probability.html">Conditional Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/descriptive_statistics.html">Descriptive Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/geometric_probability.html">Geometric Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_probability.html">Introduction to Probability</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/introduction_to_statistics.html">Introduction to Statistics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/probability_tree.html">Probability Tree</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/standard_error_and_lln.html">Standard Error and Lln</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/basic_concepts/total_probability.html">Total Probability</a></li>
                        </ol>
                    </li>
                    <li>Probability Distributions<ol>
                            <li>Continuous Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/beta_distribution.html">Beta Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/chi_square_distribution.html">Chi Square Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/exponential_distribution.html">Exponential Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/f_distribution.html">F Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/gamma_distribution.html">Gamma Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/log_normal_distribution.html">Log Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/normal_distribution.html">Normal Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/student_t_distribution.html">Student T Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/continuous_distributions/uniform_distribution.html">Uniform Distribution</a></li>
                                </ol>
                            </li>
                            <li>Discrete Distributions<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/binomial_distribution.html">Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/geometric_distribution.html">Geometric Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/negative_binomial_distribution.html">Negative Binomial Distribution</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/discrete_distributions/poisson_distribution.html">Poisson Distribution</a></li>
                                </ol>
                            </li>
                            <li>Intro<ol>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/central_limit_theorem.html">Central Limit Theorem</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/introduction_to_distributions.html">Introduction to Distributions</a></li>
                                    <li><a href="https://adamdjellouli.com/articles/statistics_notes/probability_distributions/intro/normal_curve_and_z_score.html">Normal Curve and z Score</a></li>
                                </ol>
                            </li>
                        </ol>
                    </li>
                    <li>Correlation and Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/correlation.html">Correlation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/covariance.html">Covariance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/logistic_regression.html">Logistic Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/metrics.html">Metrics</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/multiple_regression.html">Multiple Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/correlation_and_regression/simple_linear_regression.html">Simple Linear Regression</a></li>
                        </ol>
                    </li>
                    <li>Statistical Inference<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_categorical_data.html">Analysis of Categorical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/analysis_of_variance.html">Analysis of Variance</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/confidence_intervals.html">Confidence Intervals</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/hypothesis_testing.html">Hypothesis Testing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/multiple_comparisons.html">Multiple Comparisons</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/null_hypothesis.html">Null Hypothesis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/resampling.html">Resampling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/statistical_inference/type_i_and_type_ii_errors.html">Type i and Type Ii Errors</a></li>
                        </ol>
                    </li>
                    <li>Time Series Analysis<ol>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/arima_models.html">Arima Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocorrelation_function.html">Autocorrelation Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autocovariance_function.html">Autocovariance Function</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/autoregressive_models.html">Autoregressive Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/backward_shift_operator.html">Backward Shift Operator</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/difference_equations.html">Difference Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/forecasting.html">Forecasting</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/invertibility.html">Invertibility</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/moving_average_models.html">Moving Average Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/random_walk.html">Random Walk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/seasonality_and_trends.html">Seasonality and Trends</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/series.html">Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/stationarity.html">Stationarity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/statistical_moments_and_time_series.html">Statistical Moments and Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series.html">Time Series</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/time_series_modeling.html">Time Series Modeling</a></li>
                            <li><a href="https://adamdjellouli.com/articles/statistics_notes/time_series_analysis/yule_walker_equations.html">Yule Walker Equations</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>