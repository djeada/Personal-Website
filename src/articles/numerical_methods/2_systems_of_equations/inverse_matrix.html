<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Matrix Inverse</title>
    <meta content="The inverse of a matrix A is denoted as A^-1." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>Last modified: December 31, 2024</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="matrix-inverse">Matrix Inverse</h2>
            <p>The inverse of a matrix A is denoted as A^-1. It is a unique matrix such that when it is multiplied by the original matrix A, the result is the identity matrix I. Mathematically, this is expressed as:</p>
            <p>$$
                AA^{-1} = A^{-1}A = I
                $$</p>
            <p>Not all matrices have an inverse. Only square matrices (those with the same number of rows and columns) are eligible to have an inverse, and even then, some do not. A matrix has an inverse if and only if it is non-singular, i.e., its determinant is not zero.</p>
            <h3 id="mathematical-formulation">Mathematical Formulation</h3>
            <p>Given a square matrix A of order n, the inverse A^-1 is calculated as:</p>
            <p>$$
                A^{-1} = \frac{1}{det(A)} adj(A)
                $$</p>
            <p>where det(A) is the determinant of A and adj(A) is the adjugate of A.</p>
            <p>The adjugate of A is the transpose of the cofactor matrix C of A. Each element c_ij of C is calculated as (-1)^(i+j) det(M_ij), where M_ij is the (i, j)th minor of A.</p>
            <h3 id="using-inverse-matrix-to-solve-matrix-equations">Using inverse matrix to solve matrix equations</h3>
            <p>We can solve a following matrix equation, using a matrix invers:</p>
            <p>$$ A\boldsymbol{x}=\boldsymbol{b} $$</p>
            <p>Let's mutiply both sides by the inverse of the matrix $A$:</p>
            <p>$$ \implies A^{-1}A\boldsymbol{x} = A^{-1}\boldsymbol{b} $$</p>
            <p>$$ \implies I\boldsymbol{x} = A^{-1}\boldsymbol{b} $$</p>
            <p>$$ \implies \boldsymbol{x} = A^{-1}\boldsymbol{b} $$</p>
            <h3 id="algorithm-steps">Algorithm Steps</h3>
            <p>Finding the inverse of a matrix is a multi-step process:</p>
            <ol>
                <li>Check if the matrix is invertible. A matrix is invertible if it is square (has the same number of rows and columns) and its determinant is not zero. If the matrix is not invertible, stop here, the matrix does not have an inverse.</li>
                <li>Calculate the matrix of minors. The minor of each element in the matrix is the determinant of the matrix formed by removing the row and column of that element from the original matrix.</li>
                <li>Form the matrix of cofactors. Multiply each minor by (-1)^(i+j), where i and j are the row and column numbers of each element.</li>
                <li>Calculate the adjugate of the matrix. The adjugate is simply the transpose of the cofactor matrix.</li>
                <li>Finally, the inverse of the original matrix is the adjugate divided by the determinant of the original matrix.</li>
            </ol>
            <h3 id="example">Example</h3>
            <p>Let's take a 2x2 matrix A as an example:</p>
            <p>$$
                A = \begin{bmatrix} 4 &amp; 7 \
                2 &amp; 6\ \end{bmatrix}
                $$</p>
            <ol>
                <li>First, check if the matrix is invertible. The determinant of A is (4<em>6 - 7</em>2) = 10, which is not zero, so the matrix is invertible.</li>
                <li>The minor of 4 is the determinant of the matrix that results from removing the row and column of 4 from A, which is just 6. Similarly, the minor of 7 is 2, the minor of 2 is 7, and the minor of 6 is 4.</li>
                <li>The cofactor matrix is obtained by multiplying each minor by (-1)^(i+j). For a 2x2 matrix, this results in the same matrix, as (-1)^(i+j) is 1 for all elements.</li>
                <li>The adjugate of A is the transpose of the cofactor matrix, which is the same in this case because A is a 2x2 matrix.</li>
                <li>The inverse of A is the adjugate divided by the determinant, resulting in:</li>
            </ol>
            <p>$$
                A^{-1} = \frac{1}{10} \begin{bmatrix} 6 &amp; -7 \
                -2 &amp; 4\ \end{bmatrix} = \begin{bmatrix} 0.6 &amp; -0.7 \
                -0.2 &amp; 0.4\ \end{bmatrix}
                $$</p>
            <h3 id="advantages">Advantages</h3>
            <ul>
                <li>The <strong>inverse of a matrix</strong> provides an analytical solution for systems of linear equations of the form $A \mathbf{x} = \mathbf{b}$, where $\mathbf{x} = A^{-1} \mathbf{b}$, offering a direct approach when the inverse is available.</li>
                <li>Matrix inversion is a <strong>fundamental concept in linear algebra</strong>, with applications ranging from solving systems of equations to transformations in geometry, optimization problems, and control systems.</li>
                <li>It enables the <strong>characterization of matrix properties</strong>, such as determining whether a matrix is singular (non-invertible) and finding relationships in systems represented by matrices.</li>
                <li>Inverse matrices are used in <strong>statistical computations</strong>, such as calculating the covariance matrix in multivariate analysis and solving normal equations in least squares problems.</li>
                <li>The computation of $A^{-1}$ can be performed <strong>once and reused</strong> for multiple right-hand sides $\mathbf{b}$, making it useful in scenarios where multiple systems need solving with the same matrix $A$.</li>
            </ul>
            <h3 id="limitations">Limitations</h3>
            <ul>
                <li><strong>Not all matrices are invertible.</strong> A matrix must be square (having the same number of rows and columns) and non-singular (having a non-zero determinant) to possess an inverse.</li>
                <li><strong>Computational cost is high</strong> for calculating matrix inverses directly. The process involves determinant calculations and can be computationally prohibitive for large matrices, with complexity on the order of $O(n^3)$ for typical methods like Gaussian elimination.</li>
                <li>Using the inverse to solve $A \mathbf{x} = \mathbf{b}$ is often <strong>less efficient and less numerically stable</strong> than solving the system directly with techniques like LU decomposition or iterative methods, especially for large or sparse systems.</li>
                <li>Small numerical errors in the computation of the inverse can <strong>magnify errors in the solution</strong>, particularly for ill-conditioned matrices, making direct inversion less desirable in sensitive applications.</li>
                <li>The process of inversion does not apply to <strong>non-square or singular matrices,</strong> and alternative approaches like pseudo-inverse computation or regularization methods must be employed for such cases.</li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#matrix-inverse">Matrix Inverse</a>
                <ol>
                    <li><a href="#mathematical-formulation">Mathematical Formulation</a></li>
                    <li><a href="#using-inverse-matrix-to-solve-matrix-equations">Using inverse matrix to solve matrix equations</a></li>
                    <li><a href="#algorithm-steps">Algorithm Steps</a></li>
                    <li><a href="#example">Example</a></li>
                    <li><a href="#advantages">Advantages</a></li>
                    <li><a href="#limitations">Limitations</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Root and Extrema Finding<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/bisection_method.html">Bisection Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/golden_ratio_search.html">Golden Ratio Search</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/gradient_descent.html">Gradient Descent</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/newtons_method.html">Newtons Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/relaxation_method.html">Relaxation Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/root_finding.html">Root Finding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/secant_method.html">Secant Method</a></li>
                        </ol>
                    </li>
                    <li>Systems of Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gauss_seidel.html">Gauss Seidel</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gaussian_elimination.html">Gaussian Elimination</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/inverse_matrix.html">Inverse Matrix</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/jacobi_method.html">Jacobi Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/lu_decomposition.html">Lu Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/systems_of_equations.html">Systems of Equations</a></li>
                        </ol>
                    </li>
                    <li>Differentiation<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/backward_difference.html">Backward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference.html">Central Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/differentiation.html">Differentiation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/forward_difference.html">Forward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/taylor_series.html">Taylor Series</a></li>
                        </ol>
                    </li>
                    <li>Integration<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/integration_introduction.html">Integration Introduction</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/midpoint_rule.html">Midpoint Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/monte_carlo.html">Monte Carlo</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/simpsons_rule.html">Simpsons Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/trapezoidal_rule.html">Trapezoidal Rule</a></li>
                        </ol>
                    </li>
                    <li>Matrices<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigen_value_decomposition.html">Eigen Value Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigenvalues_and_eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/matrix_methods.html">Matrix Methods</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/power_method.html">Power Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/qr_method.html">Qr Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/singular_value_decomposition.html">Singular Value Decomposition</a></li>
                        </ol>
                    </li>
                    <li>Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/cubic_spline_interpolation.html">Cubic Spline Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/gaussian_interpolation.html">Gaussian Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/interpolation.html">Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/lagrange_polynomial_interpolation.html">Lagrange Polynomial Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/least_squares.html">Least Squares</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/linear_interpolation.html">Linear Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/newton_polynomial.html">Newton Polynomial</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/regression.html">Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/thin_plate_spline_interpolation.html">Thin Plate Spline Interpolation</a></li>
                        </ol>
                    </li>
                    <li>Ordinary Differential Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/eulers_method.html">Eulers Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/heuns_method.html">Heuns Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/ordinary_differential_equations.html">Ordinary Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/picards_method.html">Picards Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/runge_kutta.html">Runge Kutta</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>