<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Newtonâ€™s Polynomial</title>
    <meta content="Newtonâ€™s Polynomial, often referred to as Newtonâ€™s Interpolation Formula, is another classical approach to polynomial interpolation." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: May 04, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="newton-s-polynomial">Newtonâ€™s Polynomial</h2>
            <p>Newtonâ€™s Polynomial, often referred to as Newtonâ€™s Interpolation Formula, is another classical approach to polynomial interpolation. Given a set of data points $(x_0,y_0),(x_1,y_1),\dots,(x_n,y_n)$ with distinct $x_i$ values, Newtonâ€™s method constructs an interpolating polynomial in a form that makes it easy to add additional data points without recomputing the entire polynomial. This form involves <strong>divided differences</strong>, which are incremental ratio measures that help build the polynomial step by step.</p>
            <p>While the end result is equivalent to that of Lagrange interpolation, Newtonâ€™s form is particularly convenient when data points are added incrementally. The polynomial can be updated by incorporating a new divided difference term without completely starting over.</p>
            <p><img alt="newton_polynomial" src="https://github.com/user-attachments/assets/b23eba7f-0d87-46d5-a3b3-08c37c9f5dbc" /></p>
            <h3 id="mathematical-formulation">Mathematical Formulation</h3>
            <p>A Newton interpolating polynomial for $n+1$ points $(x_i, y_i)$ can be written as:</p>
            <p>$$P(x) = f[x_0] + f[x - x_0] + f[x - x_0](x - x_1) + \cdots + f[x_0,x_1,\ldots,x_n] (x - x_0)(x - x_1)\cdots(x - x_{n-1})$$</p>
            <p>where $f[x_0,x_1,\ldots,x_k]$ represents the $k$-th order divided difference of the function $f$ evaluated at points $x_0, x_1, \ldots, x_k$.</p>
            <p><strong>Divided Differences</strong>: For a set of points $(x_i,y_i)$, the divided differences are defined recursively:</p>
            <p><strong>Zero-th order divided difference</strong>: </p>
            <p>$$f[x_i] = y_i$$</p>
            <p><strong>First order divided difference</strong>: </p>
            <p>For $i \neq j$:</p>
            <p>$$f[x_i,x_j] = \frac{f[x_j] - f[x_i]}{x_j - x_i}$$</p>
            <p><strong>Higher order divided differences</strong>: </p>
            <p>For $i &lt; j &lt; k$:</p>
            <p>$$f[x_i,x_j,x_k] = \frac{f[x_j,x_k] - f[x_i,x_j]}{x_k - x_i}$$</p>
            <p>and so forth for even higher orders.</p>
            <h3 id="derivation">Derivation</h3>
            <p>Consider the cubic case for intuition (the process generalizes to higher degrees):</p>
            <p>$$P_3(x) = a_0 + (x-x_0)a_1 + (x-x_0)(x-x_1)a_2 + (x-x_0)(x-x_1)(x-x_2)a_3$$</p>
            <p>I. <strong>At $x=x_0$</strong>:</p>
            <p>$$P_3(x_0)=a_0 = y_0.$$</p>
            <p>II. <strong>At $x=x_1$</strong>:</p>
            <p>Substitute $x_1$ into $P_3(x)$:</p>
            <p>$$y_1 = P_3(x_1) = a_0 + (x_1-x_0)a_1.$$</p>
            <p>Since $a_0 = y_0$:</p>
            <p>$$a_1 = \frac{y_1 - y_0}{x_1-x_0} = f[x_0,x_1]$$</p>
            <p>III. <strong>At $x=x_2$</strong>:</p>
            <p>Substitute $x_2$:</p>
            <p>$$y_2 = P_3(x_2)= a_0 + (x_2-x_0)(a_1 + (x_2 - x_1)a_2)$$</p>
            <p>Rearranging terms leads to:</p>
            <p>$$a_2 = \frac{\frac{y_2 - y_0}{x_2 - x_0} - \frac{y_1 - y_0}{x_1 - x_0}}{x_2 - x_1} = f[x_0,x_1,x_2]$$</p>
            <p>Similarly, higher order coefficients ($a_3, a_4, \ldots$) can be obtained, which correspond to higher order divided differences. In general:</p>
            <p>$$a_k = f[x_0,x_1,\ldots,x_k]$$</p>
            <h3 id="algorithm-steps">Algorithm Steps</h3>
            <p>I. <strong>Data Preparation</strong>: </p>
            <p>Given $(x_0,y_0), (x_1,y_1),\ldots,(x_n,y_n)$ sorted so that $x_0 &lt; x_1 &lt; \cdots &lt; x_n$.</p>
            <p>II. <strong>Compute Divided Differences</strong>: </p>
            <ul>
                <li>Start by listing the $y$-values as the zeroth order divided differences.</li>
                <li>Compute the first order divided differences:</li>
            </ul>
            <p>$$f[x_i,x_{i+1}] = \frac{y_{i+1}-y_i}{x_{i+1}-x_i} \quad \text{for } i=0 \ldots n-1$$</p>
            <ul>
                <li>Use these to compute the second order divided differences, and so on, until you have $f[x_0,x_1,\ldots,x_n]$.</li>
            </ul>
            <p>Usually, this is arranged in a <strong>divided difference table</strong>, where each column corresponds to divided differences of increasing order.</p>
            <p>III. <strong>Form the Newton Polynomial</strong>:</p>
            <p>Once you have all the divided differences:</p>
            <p>$$
                P(x) = f[x_0] + f[x_0,x_1](x - x_0) + f[x_0,x_1,x_2](x-x_0)(x-x_1) + \cdots
                $$</p>
            <p>IV. <strong>Use the Polynomial for Interpolation</strong>:</p>
            <p>Substitute the desired $x$-value into $P(x)$ to get the interpolated $y$-value.</p>
            <h3 id="example">Example</h3>
            <p>Consider points $(1,2), (2,3), (3,5)$.</p>
            <p>Zeroth order differences (just $y$-values):</p>
            <p>$$f[x_0]=2, \quad f[x_1]=3, \quad f[x_2]=5$$</p>
            <p>First order differences:</p>
            <p>$$f[x_0,x_1] = \frac{3-2}{2-1}=1, \quad f[x_1,x_2] = \frac{5-3}{3-2}=2$$</p>
            <p>Second order difference:</p>
            <p>$$f[x_0,x_1,x_2] = \frac{f[x_1,x_2] - f[x_0,x_1]}{x_2 - x_0} = \frac{2-1}{3-1}=\frac{1}{2}=0.5$$</p>
            <p>The Newton polynomial is:</p>
            <p>$$P(x)=f[x_0] + f[x - x_0] + f[x - x_0](x - x_1)$$</p>
            <p>Substitute the values:</p>
            <p>$$P(x)=2 + (1)(x - 1) + (0.5)(x - 1)(x - 2)$$</p>
            <p>This matches exactly the polynomial you would get if you used Lagrange or any other method for these points.</p>
            <h3 id="advantages">Advantages</h3>
            <ul>
                <li>When a new data point is added, you can perform <strong>incremental</strong> updating of the polynomial by computing a new set of divided differences without starting over from scratch.</li>
                <li>Newtonâ€™s polynomial produces the same interpolating polynomial as Lagrange interpolation or any other form of <strong>interpolation</strong>.</li>
                <li>The nested form of Newtonâ€™s polynomial, such as $P(x) = a_0 + (x - x_0)(a_1 + (x - x_1)(a_2 + \cdots ))$, is often numerically more <strong>stable</strong> for evaluating and updating the polynomial.</li>
            </ul>
            <h3 id="limitations">Limitations</h3>
            <ul>
                <li>As the number of data points grows large, the computation and maintenance of higher order divided differences can become <strong>computationally</strong> intensive.</li>
                <li>Like any polynomial interpolation, Newtonâ€™s polynomial can suffer from Rungeâ€™s <strong>phenomenon</strong> if the points are not well-distributed, causing oscillations in the polynomial approximation.</li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#newton-s-polynomial">Newtonâ€™s Polynomial</a>
                <ol>
                    <li><a href="#mathematical-formulation">Mathematical Formulation</a></li>
                    <li><a href="#derivation">Derivation</a></li>
                    <li><a href="#algorithm-steps">Algorithm Steps</a></li>
                    <li><a href="#example">Example</a></li>
                    <li><a href="#advantages">Advantages</a></li>
                    <li><a href="#limitations">Limitations</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Root and Extrema Finding<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/bisection_method.html">Bisection Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/golden_ratio_search.html">Golden Ratio Search</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/gradient_descent.html">Gradient Descent</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/newtons_method.html">Newtons Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/relaxation_method.html">Relaxation Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/root_finding.html">Root Finding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/secant_method.html">Secant Method</a></li>
                        </ol>
                    </li>
                    <li>Systems of Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gauss_seidel.html">Gauss Seidel</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gaussian_elimination.html">Gaussian Elimination</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/inverse_matrix.html">Inverse Matrix</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/jacobi_method.html">Jacobi Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/lu_decomposition.html">Lu Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/systems_of_equations.html">Systems of Equations</a></li>
                        </ol>
                    </li>
                    <li>Differentiation<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/backward_difference.html">Backward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference.html">Central Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/differentiation.html">Differentiation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/forward_difference.html">Forward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/taylor_series.html">Taylor Series</a></li>
                        </ol>
                    </li>
                    <li>Integration<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/integration_introduction.html">Integration Introduction</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/midpoint_rule.html">Midpoint Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/monte_carlo.html">Monte Carlo</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/simpsons_rule.html">Simpsons Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/trapezoidal_rule.html">Trapezoidal Rule</a></li>
                        </ol>
                    </li>
                    <li>Matrices<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigen_value_decomposition.html">Eigen Value Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigenvalues_and_eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/matrix_methods.html">Matrix Methods</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/power_method.html">Power Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/qr_method.html">Qr Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/singular_value_decomposition.html">Singular Value Decomposition</a></li>
                        </ol>
                    </li>
                    <li>Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/cubic_spline_interpolation.html">Cubic Spline Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/gaussian_interpolation.html">Gaussian Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/interpolation.html">Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/lagrange_polynomial_interpolation.html">Lagrange Polynomial Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/least_squares.html">Least Squares</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/linear_interpolation.html">Linear Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/newton_polynomial.html">Newton Polynomial</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/regression.html">Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/thin_plate_spline_interpolation.html">Thin Plate Spline Interpolation</a></li>
                        </ol>
                    </li>
                    <li>Ordinary Differential Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/eulers_method.html">Eulers Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/heuns_method.html">Heuns Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/ordinary_differential_equations.html">Ordinary Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/partial_differential_equations.html">Partial Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/picards_method.html">Picards Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/runge_kutta.html">Runge Kutta</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>