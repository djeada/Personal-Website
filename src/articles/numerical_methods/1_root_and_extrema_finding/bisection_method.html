<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Bisection Method</title>
    <meta content="The bisection method is a classical root-finding technique used extensively in numerical analysis to locate a root of a continuous function $f(x)$ within a specified interval $[a, b]$." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>Last modified: September 21, 2022</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="bisection-method">Bisection Method</h2>
            <p>The bisection method is a classical root-finding technique used extensively in numerical analysis to locate a root of a continuous function $f(x)$ within a specified interval $[a, b]$. It belongs to the family of <strong>bracketing methods</strong>, which use intervals known to contain a root and systematically reduce these intervals until the solution is approximated to a desired level of accuracy. While it is not the fastest method, it is revered for its simplicity, guaranteed convergence (under appropriate conditions), and ease of implementation.</p>
            <p>Physically and mathematically, the idea is that if a function $f(x)$ crosses the $x$-axis, then there exists a point $x = \alpha$ such that $f(\alpha) = 0$. If the function is continuous and changes sign over an interval $[a,b]$ (that is, $f(a)f(b) &lt; 0$), then by the Intermediate Value Theorem, there must be at least one root in that interval. The bisection method exploits this fact by repeatedly halving the interval until the resulting interval is sufficiently small to approximate the root.</p>
            <p><strong>Conceptual Illustration</strong>:</p>
            <p><img alt="output(12)" src="https://github.com/user-attachments/assets/12b2d9fa-054b-4e09-ad80-22dc0785c5f0" /></p>
            <p>In the above conceptual plot, the function $f(x)$ crosses the x-axis somewhere between $a$ and $b$. The bisection step chooses the midpoint $c = \frac{a+b}{2}$ to test the sign of $f(c)$. Depending on the sign, the algorithm halves the interval, guaranteeing that the root remains within the new interval. This halving process is repeated iteratively.</p>
            <h3 id="mathematical-formulation">Mathematical Formulation</h3>
            <p>Consider a continuous function $f : \mathbb{R} \to \mathbb{R}$. Suppose that we know there is at least one root in the interval $[a, b]$. By the Intermediate Value Theorem, if $f(a)f(b) &lt; 0$, there must exist at least one $\alpha \in (a, b)$ such that $f(\alpha) = 0$.</p>
            <p>The bisection method proceeds by evaluating the midpoint:</p>
            <p>$$c = \frac{a + b}{2}$$</p>
            <p>We then check the sign of $f(c)$:</p>
            <ul>
                <li>If $f(a)f(c) &lt; 0$, then the root lies between $a$ and $c$.</li>
                <li>If $f(c)f(b) &lt; 0$, then the root lies between $c$ and $b$.</li>
            </ul>
            <p>In either case, we have reduced the interval size by a factor of 2. After $n$ steps, the interval size is $\frac{b-a}{2^n}$, guaranteeing that we approximate the root to within a prescribed tolerance.</p>
            <h3 id="derivation">Derivation</h3>
            <p>I. <strong>Assumption</strong>: We start with a continuous function $f(x)$ and an initial bracketing interval $[a_0, b_0]$ such that:</p>
            <p>$$f(a_0)f(b_0) &lt; 0.$$</p>
            <p>This ensures the existence of at least one root $\alpha$ in $(a_0, b_0)$.</p>
            <p>II. <strong>First Iteration</strong>:</p>
            <p>Compute the midpoint:</p>
            <p>$$c_1 = \frac{a_0 + b_0}{2}.$$</p>
            <p>Evaluate $f(c_1)$:</p>
            <ul>
                <li>If $f(a_0)f(c_1) &lt; 0$, set $a_1 = a_0$ and $b_1 = c_1$.</li>
                <li>Else, set $a_1 = c_1$ and $b_1 = b_0$.</li>
            </ul>
            <p>In either case, the new interval $[a_1, b_1]$ is half the size of $[a_0, b_0]$, and still contains the root.</p>
            <p>III. <strong>Subsequent Iterations</strong>:</p>
            <p>At the $k$-th iteration:</p>
            <p>$$c_k = \frac{a_{k-1} + b_{k-1}}{2}$$</p>
            <p>and based on the sign test:</p>
            <p>$$f(a_{k-1})f(c_k) &lt; 0 \implies [a_k, b_k] = [a_{k-1}, c_k]$$
                or</p>
            <p>$$f(c_k)f(b_{k-1}) &lt; 0 \implies [a_k, b_k] = [c_k, b_{k-1}]$$</p>
            <p>As iterations proceed, the length of the interval containing the root is:</p>
            <p>$$|b_k - a_k| = \frac{|b_0 - a_0|}{2^k}$$</p>
            <p>IV. <strong>Convergence Criterion</strong>:</p>
            <p>The process is repeated until the desired precision $\epsilon$ is reached, i.e., when:</p>
            <p>$$|b_k - a_k| &lt; \epsilon$$</p>
            <p>or until the maximum number of iterations $n_{\max}$ is exhausted.</p>
            <h3 id="algorithm-steps">Algorithm Steps</h3>
            <p><strong>Input</strong>:</p>
            <ul>
                <li>A continuous function $f(x)$.</li>
                <li>Initial interval $[a, b]$ such that $f(a)f(b) &lt; 0$.</li>
                <li>Tolerance $\epsilon &gt; 0$ or maximum iterations $n_{\max}$.</li>
            </ul>
            <p><strong>Initialization</strong>:</p>
            <ul>
                <li>Set iteration counter $k = 0$.</li>
            </ul>
            <p><strong>Iteration</strong>:</p>
            <p>I. Compute the midpoint:</p>
            <p>$$c = \frac{a+b}{2}$$</p>
            <p>II. Evaluate $f(c)$.</p>
            <p>III. If $|b-a| &lt; \epsilon$ or $k \geq n_{\max}$:</p>
            <ul>
                <li>Stop and take $c$ as the approximate root.</li>
            </ul>
            <p>IV. Else, determine the sub-interval:</p>
            <ul>
                <li>If $f(a)f(c) &lt; 0$, set $b = c$.</li>
                <li>Else, set $a = c$.</li>
            </ul>
            <p>V. Increment iteration counter $k = k+1$ and go back to step I.</p>
            <p><strong>Output</strong>:</p>
            <ul>
                <li>Approximate root $c$.</li>
                <li>Number of iterations performed.</li>
            </ul>
            <h3 id="example">Example</h3>
            <p><strong>Given Function:</strong></p>
            <p>$$f(x) = x^2 - 4.$$</p>
            <p>We know $f(0) = -4$ and $f(5) = 25 - 4 = 21$. Thus:</p>
            <p>$$f(0)f(5) = (-4)(21) = -84 &lt; 0,$$</p>
            <p>so there is at least one root in $[0,5]$.</p>
            <p><strong>Initial Setup:</strong></p>
            <ul>
                <li>$a_0 = 0$</li>
                <li>$b_0 = 5$</li>
                <li>Interval length: $b_0 - a_0 = 5$</li>
            </ul>
            <p><strong>Iteration 1</strong>:</p>
            <p>Compute midpoint: </p>
            <p>$$c_1 = \frac{0+5}{2} = 2.5.$$</p>
            <p>Evaluate $f(c_1) = f(2.5) = (2.5)^2 - 4 = 6.25 - 4 = 2.25$.</p>
            <p>Check signs:</p>
            <p>$$f(a_0)f(c_1) = f(0)f(2.5) = (-4)(2.25) = -9 &lt; 0.$$</p>
            <p>Since this is negative, the root lies in $[0, 2.5]$.</p>
            <p>Update interval:</p>
            <p>$$a_1 = 0, \quad b_1 = 2.5.$$</p>
            <p><strong>Iteration 2</strong>:</p>
            <p>New interval: $[0, 2.5]$</p>
            <p>Midpoint:</p>
            <p>$$c_2 = \frac{0+2.5}{2} = 1.25.$$</p>
            <p>Evaluate $f(c_2) = f(1.25) = (1.25)^2 -4 = 1.5625 -4 = -2.4375$.</p>
            <p>Check signs:</p>
            <p>$$f(c_2)f(b_1) = (-2.4375)(2.25) &lt; 0.$$</p>
            <p>This indicates the root is in $[1.25, 2.5]$.</p>
            <p>Update interval:</p>
            <p>$$a_2 = 1.25, \quad b_2 = 2.5.$$</p>
            <p><strong>Iteration 3</strong>:</p>
            <p>New interval: $[1.25, 2.5]$</p>
            <p>Midpoint:</p>
            <p>$$c_3 = \frac{1.25 + 2.5}{2} = 1.875.$$</p>
            <p>Evaluate $f(c_3) = (1.875)^2 -4 = 3.515625 -4 = -0.484375$.</p>
            <p>Check signs:</p>
            <p>$$f(c_3)f(b_2) = (-0.484375)(2.25) &lt; 0.$$</p>
            <p>So the root is now bracketed in $[1.875, 2.5]$.</p>
            <p>Update interval:</p>
            <p>$$a_3 = 1.875, \quad b_3 = 2.5.$$</p>
            <p>Continuing this process, as we further narrow down the interval, we find that the root approaches $x=2$. Indeed, $f(2)=0$ exactly, so the root is $x=2$.</p>
            <h3 id="advantages">Advantages</h3>
            <ol>
                <li><strong>Guaranteed convergence</strong> is ensured if $f$ is continuous and the interval $[a, b]$ satisfies $f(a)f(b) &lt; 0$, making the method reliable for root-finding. </li>
                <li>The <strong>robustness and simplicity</strong> of the method come from its reliance only on function evaluations, requiring no derivatives or complex operations, making it easy to use across various problems. </li>
                <li>The methodâ€™s <strong>stable and predictable behavior</strong> allows for precise estimation of the number of iterations required to achieve a desired accuracy since the interval halves with each iteration. </li>
            </ol>
            <h3 id="limitations">Limitations</h3>
            <ol>
                <li><strong>Slow convergence</strong> is a drawback, as the method converges linearly, making it inefficient compared to faster methods like Newton-Raphson or Secant methods for well-behaved functions. </li>
                <li>The requirement for an <strong>initial bracketing of the root</strong> means that you must first identify two points $[a, b]$ where $f(a)f(b) &lt; 0$, which can be challenging if the functionâ€™s behavior is not well-known. </li>
                <li>The method is limited to <strong>finding a single root</strong> within a given interval, necessitating separate bracketing for each root in cases where multiple roots exist. </li>
                <li><strong>Inapplicability to complex or multiple root situations</strong> arises because the method does not use additional information like derivatives or higher-order approximations, making it less suitable for complicated problems. </li>
            </ol>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#bisection-method">Bisection Method</a>
                <ol>
                    <li><a href="#mathematical-formulation">Mathematical Formulation</a></li>
                    <li><a href="#derivation">Derivation</a></li>
                    <li><a href="#algorithm-steps">Algorithm Steps</a></li>
                    <li><a href="#example">Example</a></li>
                    <li><a href="#advantages">Advantages</a></li>
                    <li><a href="#limitations">Limitations</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Root and Extrema Finding<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/bisection_method.html">Bisection Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/golden_ratio_search.html">Golden Ratio Search</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/gradient_descent.html">Gradient Descent</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/newtons_method.html">Newtons Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/relaxation_method.html">Relaxation Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/root_finding.html">Root Finding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/secant_method.html">Secant Method</a></li>
                        </ol>
                    </li>
                    <li>Systems of Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gauss_seidel.html">Gauss Seidel</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gaussian_elimination.html">Gaussian Elimination</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/inverse_matrix.html">Inverse Matrix</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/jacobi_method.html">Jacobi Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/lu_decomposition.html">Lu Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/systems_of_equations.html">Systems of Equations</a></li>
                        </ol>
                    </li>
                    <li>Differentiation<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/backward_difference.html">Backward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference.html">Central Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/differentiation.html">Differentiation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/forward_difference.html">Forward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/taylor_series.html">Taylor Series</a></li>
                        </ol>
                    </li>
                    <li>Integration<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/integration_introduction.html">Integration Introduction</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/midpoint_rule.html">Midpoint Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/monte_carlo.html">Monte Carlo</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/simpsons_rule.html">Simpsons Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/trapezoidal_rule.html">Trapezoidal Rule</a></li>
                        </ol>
                    </li>
                    <li>Matrices<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigen_value_decomposition.html">Eigen Value Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigenvalues_and_eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/matrix_methods.html">Matrix Methods</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/power_method.html">Power Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/qr_method.html">Qr Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/singular_value_decomposition.html">Singular Value Decomposition</a></li>
                        </ol>
                    </li>
                    <li>Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/cubic_spline_interpolation.html">Cubic Spline Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/gaussian_interpolation.html">Gaussian Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/interpolation.html">Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/lagrange_polynomial_interpolation.html">Lagrange Polynomial Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/least_squares.html">Least Squares</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/linear_interpolation.html">Linear Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/newton_polynomial.html">Newton Polynomial</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/regression.html">Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/thin_plate_spline_interpolation.html">Thin Plate Spline Interpolation</a></li>
                        </ol>
                    </li>
                    <li>Ordinary Differential Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/eulers_method.html">Eulers Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/heuns_method.html">Heuns Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/ordinary_differential_equations.html">Ordinary Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/partial_differential_equations.html">Partial Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/picards_method.html">Picards Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/runge_kutta.html">Runge Kutta</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>