<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Central Difference Method</title>
    <meta content="The central‚Äêdifference method is a finite‚Äêdifference scheme for estimating derivatives that combines forward and backward differences via Taylor‚Äêseries expansions." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <link href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference" rel="canonical" />
    <script id="structured-data" type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "Article",
            "headline": "Central Difference Method",
            "author": {
                "@type": "Person",
                "name": "Adam Djellouli"
            },
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference"
            },
            "url": "https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference",
            "description": "The central\u2010difference method is a finite\u2010difference scheme for estimating derivatives that combines forward and backward differences via Taylor\u2010series expansions.",
            "dateModified": "2019-07-04"
        }
    </script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="../../../index.html">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/courses.html" title="Browse Courses by Adam Djellouli"> Courses </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <aside id="article-sidebar">
            <div id="table-of-contents">
                <h2>Table of Contents</h2>
                <ol><a href="#central-difference-method">Central Difference Method</a>
                    <ol>
                        <li><a href="#mathematical-formulation-and-derivation">Mathematical Formulation and Derivation</a></li>
                        <li><a href="#error-in-central-difference-method">Error in Central Difference Method</a></li>
                        <li><a href="#example">Example</a></li>
                        <li><a href="#advantages">Advantages</a></li>
                        <li><a href="#limitations">Limitations</a></li>
                    </ol>
                </ol>
            </div>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Root and Extrema Finding<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/bisection_method.html">Bisection Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/golden_ratio_search.html">Golden Ratio Search</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/gradient_descent.html">Gradient Descent</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/newtons_method.html">Newtons Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/relaxation_method.html">Relaxation Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/root_finding.html">Root Finding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/1_root_and_extrema_finding/secant_method.html">Secant Method</a></li>
                        </ol>
                    </li>
                    <li>Systems of Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gauss_seidel.html">Gauss Seidel</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/gaussian_elimination.html">Gaussian Elimination</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/inverse_matrix.html">Inverse Matrix</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/jacobi_method.html">Jacobi Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/lu_decomposition.html">Lu Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/2_systems_of_equations/systems_of_equations.html">Systems of Equations</a></li>
                        </ol>
                    </li>
                    <li>Differentiation<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/backward_difference.html">Backward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/central_difference.html">Central Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/differentiation.html">Differentiation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/forward_difference.html">Forward Difference</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/3_differentiation/taylor_series.html">Taylor Series</a></li>
                        </ol>
                    </li>
                    <li>Integration<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/integration_introduction.html">Integration Introduction</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/midpoint_rule.html">Midpoint Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/monte_carlo.html">Monte Carlo</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/simpsons_rule.html">Simpsons Rule</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/4_integration/trapezoidal_rule.html">Trapezoidal Rule</a></li>
                        </ol>
                    </li>
                    <li>Matrices<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigen_value_decomposition.html">Eigen Value Decomposition</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/eigenvalues_and_eigenvectors.html">Eigenvalues and Eigenvectors</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/matrix_methods.html">Matrix Methods</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/power_method.html">Power Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/qr_method.html">Qr Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/5_matrices/singular_value_decomposition.html">Singular Value Decomposition</a></li>
                        </ol>
                    </li>
                    <li>Regression<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/cubic_spline_interpolation.html">Cubic Spline Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/gaussian_interpolation.html">Gaussian Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/interpolation.html">Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/lagrange_polynomial_interpolation.html">Lagrange Polynomial Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/least_squares.html">Least Squares</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/linear_interpolation.html">Linear Interpolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/newton_polynomial.html">Newton Polynomial</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/regression.html">Regression</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/6_regression/thin_plate_spline_interpolation.html">Thin Plate Spline Interpolation</a></li>
                        </ol>
                    </li>
                    <li>Ordinary Differential Equations<ol>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/eulers_method.html">Eulers Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/heuns_method.html">Heuns Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/ordinary_differential_equations.html">Ordinary Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/partial_differential_equations.html">Partial Differential Equations</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/picards_method.html">Picards Method</a></li>
                            <li><a href="https://adamdjellouli.com/articles/numerical_methods/7_ordinary_differential_equations/runge_kutta.html">Runge Kutta</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </aside><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: July 04, 2019</i></p>
            <p style="text-align: right;"><i>This article is written in: üá∫üá∏</i></p>
            <h2 id="central-difference-method">Central Difference Method</h2>
            <p>The central‚Äêdifference method is a finite‚Äêdifference scheme for estimating derivatives that combines forward and backward differences via Taylor‚Äêseries expansions. By evaluating the function at points symmetrically placed around the target, it cancels out many of the lower‚Äêorder error terms, yielding a more accurate approximation than one‚Äêsided methods. This balanced approach is especially useful in numerical analysis and computational applications where closed‚Äêform derivatives are unavailable or costly to compute.</p>
            <p><img alt="Central Difference Method Illustration" src="https://github.com/user-attachments/assets/367d9eb0-a68b-47d4-bace-f0279fd8b1f8" /></p>
            <h3 id="mathematical-formulation-and-derivation">Mathematical Formulation and Derivation</h3>
            <p>The central difference approximation of the first derivative of a function $f$ at a point $x$ with step size $h$ is given by:</p>
            <p>$$
                f'(x) \approx \frac{f(x + h) - f(x - h)}{2h}
                $$</p>
            <p>This formula is derived from the average of the forward and backward difference formulas. </p>
            <p>Let's start with Taylor's formula. For some $\xi_1\in(x,x+h)$ and $\xi_2\in(x-h,x)$, Taylor‚Äôs theorem gives</p>
            <p>$$
                f(x+h) = f(x) + hf'(x) + \frac{h^2}{2}f''(x) + \frac{h^3}{6}f^{(3)}(\xi_1)
                $$</p>
            <p>$$
                f(x-h) = f(x) - hf'(x) + \frac{h^2}{2}f''(x) - \frac{h^3}{6}f^{(3)}(\xi_2)
                $$</p>
            <p>The forward difference approximation is expressed as:</p>
            <p>$$
                \frac{f(x+h)-f(x)}{h}
                = \frac{\bigl[f(x)+h f'(x)+\tfrac{h^2}{2}f''(x)+\tfrac{h^3}{6}f^{(3)}(\xi_1)\bigr] - f(x)}{h}
                $$</p>
            <p>$$
                = f'(x) + \frac{h}{2}f''(x) + \frac{h^2}{6}f^{(3)}(\xi_1)
                $$</p>
            <p>Thus</p>
            <p>$$
                \frac{f(x+h)-f(x)}{h} = f'(x) + \mathcal{O}(h)
                $$</p>
            <p>Similarly, the backward difference approximation is:</p>
            <p>$$
                \frac{f(x)-f(x-h)}{h}
                = \frac{f(x) - \bigl[f(x)-h f'(x)+\tfrac{h^2}{2}f''(x)-\tfrac{h^3}{6}f^{(3)}(\xi_2)\bigr]}{h}
                $$</p>
            <p>$$
                = f'(x) - \frac{h}{2}f''(x) + \frac{h^2}{6}f^{(3)}(\xi_2)
                $$</p>
            <p>Thus</p>
            <p>$$
                \frac{f(x)-f(x-h)}{h} = f'(x) + \mathcal{O}(h)
                $$</p>
            <p>By taking the average of these two approximations, we eliminate the leading error terms, resulting in a more accurate estimate of the derivative. The Taylor series expansion is a representation of a function as an infinite sum of terms calculated from the function's derivatives at a single point. We use this expansion to improve our approximation of derivatives:</p>
            <p>Expanding $f(x_0+h)$ and $f(x_0-h)$ in a Taylor series around $x_0$:</p>
            <p>$$
                f(x_0+h) = f(x_0) + hf'(x_0) + \frac{h^2}{2}f''(x_0) + \mathcal{O}(h^3)
                $$</p>
            <p>$$
                f(x_0-h) = f(x_0) - hf'(x_0) + \frac{h^2}{2}f''(x_0) + \mathcal{O}(h^3)
                $$</p>
            <p>Add the two approximations and divide by 2:</p>
            <p>$$
                \frac12\biggl[\frac{f(x+h)-f(x)}{h} + \frac{f(x)-f(x-h)}{h}\biggr]
                $$</p>
            <p>$$
                = \frac12\Bigl[\bigl(f'(x) + \tfrac{h}{2}f''(x) + \tfrac{h^2}{6}f^{(3)}(\xi_1)\bigr)
                \quad + \bigl(f'(x) - \tfrac{h}{2}f''(x) + \tfrac{h^2}{6}f^{(3)}(\xi_2)\bigr)\Bigr]
                $$</p>
            <p>$$
                = f'(x) + \frac{h^2}{12}\bigl(f^{(3)}(\xi_1)+f^{(3)}(\xi_2)\bigr)
                $$</p>
            <p>Notice the $\pm\tfrac{h}{2}f''(x)$ terms cancel exactly, leaving only an $\mathcal{O}(h^2)$ remainder.</p>
            <p>Rewriting the left side,</p>
            <p>$$
                \frac{1}{2}\Bigl(\tfrac{f(x+h)-f(x)}{h} + \tfrac{f(x)-f(x-h)}{h}\Bigr)
                = \frac{f(x+h)-f(x-h)}{2h}
                $$</p>
            <p>Hence</p>
            <p>$$
                \frac{f(x+h)-f(x-h)}{2h}
                = f'(x) + \underbrace{\frac{h^2}{12}\bigl(f^{(3)}(\xi_1)+f^{(3)}(\xi_2)\bigr)}_{\displaystyle\mathcal{O}(h^2)}
                $$</p>
            <p>or equivalently</p>
            <p>$$
                f'(x)
                = \frac{f(x+h)-f(x-h)}{2h} - \mathcal{O}(h^2)
                $$</p>
            <p>Dropping the explicit remainder,</p>
            <p>$$
                \boxed{
                f'(x)\approx \frac{f(x+h)-f(x-h)}{2h}
                }
                $$</p>
            <p>which is <strong>second‚Äêorder accurate</strong> (error $\propto h^2$) because the leading $h^1$ terms have cancelled.</p>
            <h3 id="error-in-central-difference-method">Error in Central Difference Method</h3>
            <p>The error in the central difference method is of the order $O(h^2)$, which implies that the error decreases quadratically as the step size $h$ approaches zero. This quadratic rate of convergence makes the central difference method significantly more accurate than the forward or backward difference methods, which typically have an error of order $O(h)$. However, while reducing $h$ can enhance accuracy, it must be balanced against potential numerical instability and the limitations of floating-point arithmetic. Extremely small values of $h$ can lead to round-off errors, thereby limiting the practical accuracy achievable with this method.</p>
            <h3 id="example">Example</h3>
            <p>Suppose we have a function $f(x) = x^2$, and we want to approximate the derivative at the point $x = 2$ with a step size $h = 0.01$. Using the central difference method, we get:</p>
            <p>$$
                f'(2) \approx \frac{f(2 + 0.01) - f(2 - 0.01)}{2 \times 0.01} = \frac{4.0401 - 3.9601}{0.02} = 4.00
                $$</p>
            <p>The exact derivative of $f(x) = x^2$ at the point $x = 2$ is $f'(2) = 2 \times 2 = 4$, so the approximation is accurate. This example demonstrates how the central difference method can effectively approximate derivatives with high precision, especially for smooth functions. It also highlights the method's reliance on the choice of step size $h$, which must be sufficiently small to capture the function's behavior without introducing significant numerical errors.</p>
            <h3 id="advantages">Advantages</h3>
            <ul>
                <li>The method offers <strong>higher accuracy</strong> compared to forward or backward difference methods by utilizing function values on both sides of the point, which reduces the error term in derivative approximations.</li>
                <li><strong>Simplicity in implementation</strong> makes it easy to apply, with straightforward formulas that are accessible for use in numerical analysis and computational tasks.</li>
                <li>The central difference method is <strong>applicable to discrete data</strong>, allowing for its use when analytical evaluations are difficult or impossible, such as in cases of data fitting, signal processing, and numerical simulations.</li>
            </ul>
            <h3 id="limitations">Limitations</h3>
            <ul>
                <li>There is always an <strong>approximation error</strong>, even though it is smaller than other difference methods. Decreasing the step size $h$ reduces the error, but excessively small $h$ can lead to numerical instability due to floating-point limitations.</li>
                <li>The method‚Äôs requirement for <strong>function values on both sides</strong> of the point means it cannot be applied directly at the domain boundaries unless the function is defined beyond those boundaries. This restricts its use in finite datasets or boundary value problems without extrapolation or assumptions.</li>
            </ul>
        </article-section>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column footer-about">
                <h2>About</h2>
                <p class="footer-message">Thanks for stopping by. This site is free to use; please be respectful and avoid misuse. For questions or collaboration, reach me on <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn</a> or <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a>.</p>
                <p class="footer-signature">Built with care in Berlin (UTC+1).</p>
            </div>
            <div class="footer-column footer-links">
                <h2>Quick Links</h2>
                <ul class="footer-links-list">
                    <li><a href="https://adamdjellouli.com/index.html" title="Home">Home</a></li>
                    <li><a href="https://adamdjellouli.com/core/projects.html" title="Projects">Projects</a></li>
                    <li><a href="https://adamdjellouli.com/core/tools.html" title="Tools">Tools</a></li>
                    <li><a href="https://adamdjellouli.com/core/courses.html" title="Courses">Courses</a></li>
                    <li><a href="https://adamdjellouli.com/core/resume.html" title="Resume">Resume</a></li>
                    <li><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Privacy Policy</a></li>
                    <li><a href="https://adamdjellouli.com/sitemap.xml" title="Sitemap">Sitemap</a></li>
                </ul>
            </div>
            <div class="footer-column footer-social">
                <h2>Follow</h2>
                <ul class="social-media">
                    <li>
                        <a aria-label="YouTube" class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" rel="noopener" target="_blank" title="YouTube"></a>
                        <span class="social-label">YouTube</span>
                    </li>
                    <li>
                        <a aria-label="LinkedIn" class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" rel="noopener" target="_blank" title="LinkedIn"></a>
                        <span class="social-label">LinkedIn</span>
                    </li>
                    <li>
                        <a aria-label="Instagram" class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" rel="noopener" target="_blank" title="Instagram"></a>
                        <span class="social-label">Instagram</span>
                    </li>
                    <li>
                        <a aria-label="GitHub" class="fa fa-github" href="https://github.com/djeada" title="GitHub"></a>
                        <span class="social-label">GitHub</span>
                    </li>
                </ul>
                <img alt="" aria-hidden="true" class="footer-mark" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
        </div>
        <div class="footer-bottom">
            <p id="copyright">
                ¬© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="/app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>