<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <title>Recommendation Systems</title>
    <meta charset="utf-8" />
    <meta content="A recommender system is a tool used by many businesses, such as Amazon, eBay, and iTunes, to suggest new products or content to their customers based on their previous purchases and interactions with the business." name="description" />
    <meta content="Adam Djellouli" name="keywords" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" type="text/css" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="ie-edge" http-equiv="X-UA-Compatible">
    </meta>
    </meta>
</head>

<body>
    <nav>
        <a class="logo" href="../index.html" title="Adam Djellouli - Home">
            <img alt="Adam Djellouli Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul>
            <li> <a href="../../index.html" title="Home"> Home </a> </li>
            <li> <a class="active" href="../../core/blog.html" title="Adam Djellouli's Blog - Programming, technology and more"> Blog </a> </li>
            <li> <a href="../../core/tools.html" title="Useful Tools by Adam Djellouli"> Tools </a> </li>
            <li> <a href="../../core/projects.html" title="Projects by Adam Djellouli"> Projects </a> </li>
            <li> <a href="../../core/resume.html" title="Adam Djellouli's Resume"> Resume </a> </li>
            <li> <a href="../../core/about.html" title="About Adam Djellouli"> About </a> </li>
            <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
        </ul>
    </nav>
    <section id="article-body"></section>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="recommendation-systems">Recommendation Systems</h2>
            <p>A recommender system is a tool used by many businesses, such as Amazon, eBay, and iTunes, to suggest new products or content to their customers based on their previous purchases and interactions with the business. These systems are not a specific method, but rather a concept. An example of a recommender system is one that predicts movie ratings. In this example, a firm sells movies and allows viewers to rate them on a scale from 1 to 5. The system has data on the ratings given to five films by four users. The system uses this data, along with features such as the number of users and movies, to recommend films to each user. One way to learn the parameters needed for the system to make these recommendations is through the use of collaborative filtering, which has the ability to learn the characteristics it needs to make recommendations on its own. This can be done through the use of algorithms such as gradient descent. Collaborative filtering can be used to find either the preferences of the users or the features of the films, depending on which is unknown.</p>
            <h2 id="the-algorithm">The algorithm</h2>
            <ul>
                <li>Many technological businesses consider recommender systems to be critical (amazon, Ebay, iTunes genius).</li>
                <li>Based on previous purchases, try to propose new content to you.</li>
                <li>It's not so much a method as it is a concept.</li>
            </ul>
            <p>Example: predict movie ratings.</p>
            <ul>
                <li>You work at a firm that sells movies.</li>
                <li>You allow viewers to rate movies on a scale of 1 to 5.</li>
                <li>You have five films.</li>
                <li>You also have four users.</li>
            </ul>
            <p><img alt="movie_recommendation" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/movie_recommendation.png" /></p>
            <ul>
                <li>$n_u$ - number of users.</li>
                <li>$n_m$ - number of movies.</li>
                <li>$r(i,j)$ - 1 if user j has rated movie i.</li>
                <li>$y^{(i,j)}$ - rating given by user j to move i.</li>
                <li>If we have features like this, a feature vector may recommend each film.</li>
                <li>For each film, add an additional feature that is x0 = 1.</li>
                <li>So we have a $[3 \times 1]$ vector for each film, which for film number three ("Cute Puppies of Love") would be:</li>
            </ul>
            <p>$$
                x^{(3)} = \begin{bmatrix}
                1 \\
                0.99 \\
                0
                \end{bmatrix}
                $$</p>
            <p>So, let's take a look at user 1 (Alice) and see what she thinks of the modern classic Cute Puppies of Love (CPOL). She is associated with the following parameter vector:</p>
            <p>$$
                \theta^{(1)} = \begin{bmatrix}
                0 \\
                5 \\
                0
                \end{bmatrix}
                $$</p>
            <p>Our prediction:</p>
            <p>$$(\theta^1)^Tx^3 = (0\cdot1)+(5\cdot0.99)+(0\cdot0)=4.95$$</p>
            <h2 id="how-do-we-learn-theta-j-">How do we learn $(\theta^j)$?</h2>
            <p>This is analogous to linear regression with least-squares error:</p>
            <p>$$min_{\theta^j} = \frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2+\frac{\lambda}{2m^{(j)}}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$</p>
            <p>We have the gradient descent algorithm to find the minimum:</p>
            <p>$$\theta_k^{(j)} := \theta_k^{(j)}-\alpha \sum_{i:r(i,j)=1}((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})x_k^{(i)}\ (for\ k=0)$$
                $$\theta_k^{(j)} := \theta_k^{(j)}-\alpha( \sum_{i:r(i,j)=1}((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})x_k^{(i)} + \lambda \theta_k^{(j)})\ (for\ k\neq0)$$</p>
            <h2 id="collaborative-filtering">Collaborative filtering</h2>
            <p>The collaborative filtering algorithm has a very intriguing property: it can learn what characteristics it needs to learn for itself.</p>
            <p>If we are given user preferences ($\theta^{(1)}, ...,\theta^{(n_u)}$) we may use them to find out the film's features ($x^{(1)}, ...,x^{(n_m)}$) and vice versa:</p>
            <p>$$min_{x^{(1)}, ...,x^{(n_m)}} \frac{1}{2} \sum_{i=1}^{n_m} \sum_{i:r(i,j)=1}((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2$$</p>
            <p>One thing you could do is:</p>
            <ul>
                <li>Randomly initialize parameter.</li>
                <li>Go back and forth in time.</li>
            </ul>
            <h2 id="vectorization-low-rank-matrix-factorization">Vectorization: Low rank matrix factorization</h2>
            <p>How can we enhance the collaborative filtering algorithm now that we've looked at it?</p>
            <p>So, in our previous example, take all ratings from all users and organize them into a matrix Y.</p>
            <p>5 movies and 4 users, give us a $[5 \times 4]$ matrix:</p>
            <p>$$
                Y =
                \begin{pmatrix}
                5 &amp; 5 &amp; 0 &amp; 0 \\
                5 &amp; ? &amp; ? &amp; 0 \\
                ? &amp; 4 &amp; 0 &amp; ? \\
                0 &amp; 0 &amp; 5 &amp; 4 \\
                0 &amp; 0 &amp; 5 &amp; 0
                \end{pmatrix}
                $$</p>
            <p>Given [Y] there's another way of writing out all the predicted ratings:</p>
            <p>$$
                X \cdot \Theta^T =
                \begin{pmatrix}
                (\theta^{(1)})^T(x^{(1)}) &amp; (\theta^{(2)})^T(x^{(1)}) &amp; ... &amp; (\theta^{(n_u)})^T(x^{(1)}) \\
                (\theta^{(1)})^T(x^{(2)}) &amp; (\theta^{(2)})^T(x^{(2)}) &amp; ... &amp; (\theta^{(n_u)})^T(x^{(2)}) \\
                \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
                (\theta^{(1)})^T(x^{(n_m)}) &amp; (\theta^{(2)})^T(x^{(n_m)}) &amp; ... &amp; (\theta^{(n_u)})^T(x^{(n_m)})
                \end{pmatrix}
                $$</p>
            <p>Where matrix X is constructed by taking all the features for each movie and stacking them in rows:</p>
            <p>$$
                X = \begin{bmatrix}
                -(x^{(1)})^T- \\
                -(x^{(2)})^T- \\
                \vdots \\
                -(x^{(n_m)})^T-
                \end{bmatrix}
                $$</p>
            <p>And matrix $\Theta$ is constructed by taking all the features for each movie and stacking them in rows:</p>
            <p>$$
                \Theta = \begin{bmatrix}
                -(\theta^{(1)})^T- \\
                -(\theta^{(2)})^T- \\
                \vdots \\
                -(\theta^{(n_u)})^T-
                \end{bmatrix}
                $$</p>
            <h2 id="mean-normalization">Mean Normalization</h2>
            <p>Consider a user who hasn't reviewed any movies.</p>
            <p><img alt="no_ratings" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/no_ratings.png" /></p>
            <ul>
                <li>There are no films for which r(i,j) = 1.</li>
                <li>So this term places no role in determining $\theta^5$.</li>
                <li>So we're just minimizing the final regularization term.</li>
            </ul>
            <p><img alt="no_ratings_formula" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/no_ratings_formula.png" /></p>
            <ul>
                <li>As previously, put all of our ratings into matrix Y.</li>
                <li>We now compute the average rating for each movie and store it in a $n_m$ - dimensional column vector.</li>
            </ul>
            <p>$$
                \mu = \begin{bmatrix}
                2.5 \\
                2.5 \\
                2 \\
                2.25 \\
                1.25
                \end{bmatrix}
                $$</p>
            <ul>
                <li>If we take a look at all of the movie ratings in [Y], we can subtract the mean rating.</li>
            </ul>
            <p>$$
                Y =
                \begin{pmatrix}
                2.5 &amp; 2.5 &amp; -2.5 &amp; -2.5 &amp; ? \\
                2.5 &amp; ? &amp; ? &amp; -2.5 &amp; ? \\
                ? &amp; 2 &amp; -2 &amp; ? &amp; ? \\
                -2.25 &amp; -2.25 &amp; 2.75 &amp; 1.75 &amp; ? \\
                -1.25 &amp; -1.25 &amp; 3.75 &amp; -1.25 &amp; ?
                \end{pmatrix}
                $$</p>
            <ul>
                <li>That is, we normalize each film to have an average rating of 0.</li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol>
                <li><a href="#recommendation-systems">Recommendation Systems</a></li>
                <li><a href="#the-algorithm">The algorithm</a></li>
                <li><a href="#how-do-we-learn-theta-j-">How do we learn $(\theta^j)$?</a></li>
                <li><a href="#collaborative-filtering">Collaborative filtering</a></li>
                <li><a href="#vectorization-low-rank-matrix-factorization">Vectorization: Low rank matrix factorization</a></li>
                <li><a href="#mean-normalization">Mean Normalization</a></li>
            </ol>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/addjellouli/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../app.js"></script>
    </footer>
</body>

</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>