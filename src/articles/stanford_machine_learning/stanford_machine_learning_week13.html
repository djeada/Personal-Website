<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <title>Clustering</title>
    <meta charset="utf-8" />
    <meta content="Unsupervised learning is a type of machine learning where the goal is to understand the structure of the data without being given any labeled examples or predefined categories." name="description" />
    <meta content="Adam Djellouli" name="keywords" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" type="text/css" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="ie-edge" http-equiv="X-UA-Compatible" />
</head>

<body>
    <nav>
        <a class="logo" href="../index.html" title="Adam Djellouli - Home">
            <img alt="Adam Djellouli Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul>
            <li> <a href="../../index.html" title="Home"> Home </a> </li>
            <li> <a class="active" href="../../core/blog.html" title="Adam Djellouli's Blog - Programming, technology and more"> Blog </a> </li>
            <li> <a href="../../core/tools.html" title="Useful Tools by Adam Djellouli"> Tools </a> </li>
            <li> <a href="../../core/projects.html" title="Projects by Adam Djellouli"> Projects </a> </li>
            <li> <a href="../../core/resume.html" title="Adam Djellouli's Resume"> Resume </a> </li>
            <li> <a href="../../core/about.html" title="About Adam Djellouli"> About </a> </li>
            <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
        </ul>
    </nav>
    <section id="article-body"></section>
    <div id="article-wrapper">
        <section id="article-body">
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="clustering">Clustering</h2>
            <p>Unsupervised learning is a type of machine learning where the goal is to understand the structure of the data without being given any labeled examples or predefined categories. A common task in unsupervised learning is clustering, where the goal is to organize the data into coherent groups or clusters. One popular algorithm for clustering is the K-means algorithm, which involves randomly selecting k initial cluster centroids and then assigning each data point to the cluster that is closest to its centroid. The algorithm then updates the centroids by taking the average of all the points in the cluster, and this process is repeated until convergence. K-means can be used on datasets with poorly defined clusters, such as in market segmentation where the goal is to create categories based on the characteristics of the data. The optimization objective of K-means is to minimize the sum of the squared distances between each data point and the cluster centroid to which it has been assigned. </p>
            <h2 id="unsupervised-learning">Unsupervised learning</h2>
            <ul>
                <li>Try to figure out the structure of the data.</li>
                <li>The clustering algorithm organizes data based on data characteristics.</li>
                <li>Market segmentation is categorizing clients into different market categories.</li>
                <li>Social network analysis.</li>
                <li>Computer clusters and data centers are organized for network structure and location.</li>
                <li>Understanding galaxy creation through astronomical data analysis.</li>
            </ul>
            <h2 id="k-means-algorithm">K-means algorithm</h2>
            <ul>
                <li>Would you like an algorithm to automatically arrange data into coherent clusters?</li>
                <li>By far the most used clustering algorithm is K-means.</li>
            </ul>
            <p>Algorithm overview:</p>
            <ul>
                <li>Assign k locations at random as cluster centroids.</li>
                <li>Go through each example and assign each point to one of the k clusters based on which center it is closest to.</li>
            </ul>
            <p><img alt="kclusters_1" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/kclusters_1.png" /></p>
            <ul>
                <li>Move to the average of the similarly allocated data-points for each centroid.</li>
            </ul>
            <p><img alt="kclusters_2" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/kclusters_2.png" /></p>
            <ul>
                <li>Repeat 2) and 3) until convergence.</li>
            </ul>
            <h2 id="k-means-for-non-separated-clusters">K-means for non-separated clusters</h2>
            <ul>
                <li>So far, we've looked at K-means, which has well-defined clusters.</li>
                <li>However, K-means is frequently used on datasets with poorly defined clusters.</li>
                <li>As an example, consider t-shirt sizes. How large do you make them if you want three sizes (S,M,L)?</li>
                <li>As a result, three clusters are formed, even if they are not actually there.</li>
                <li>This is an example of market segmentation; create items that are tailored to the demands of your subpopulations.</li>
            </ul>
            <p><img alt="t_shirt" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/t_shirt.png" /></p>
            <h2 id="k-means-optimization-objective">K means optimization objective</h2>
            <ul>
                <li>K-means, like the supervised learning functions we've examined, has an optimization goal.</li>
                <li>While K-means is running, we keep track of two sets of variables.</li>
                <li>$c^i$ is the index of clusters ${1,2, ..., K}$ to which $x^i$ is currently assigned.</li>
                <li>$\mu_k$, is the cluster associated with centroid $k$.</li>
                <li>$\mu_c^i$, is the cluster centroid of the cluster to which example $x^i$ has been assigned to.</li>
                <li>We may write the optimization objective using this notation:</li>
            </ul>
            <p>$$J(c^{(1)}, ..., c^{(m)}, \mu_1, ...,\mu_K)=\frac{1}{m}\sum_{i=1}^{m}||x^{(i)}-\mu_{c^{(i)}}||^2$$</p>
            <p>i.e. squared distances between training example $x^i$ and the cluster centroid to which $x^i$ has been assigned to.</p>
            <p><img alt="cost_cluster" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/cost_cluster.png" /></p>
            <p>When we look at the k-means method:</p>
            <ul>
                <li>The cluster assigned step is minimizing $J(...)$ with respect to $c_1, c_2 ... c_i$ i.e. find the centroid closest to each example. Doesn't change the centroids themselves.</li>
                <li>The move centroid step. We can show this step is choosing the values of $\mu$ which minimizes $J(...)$ with respect to $\mu$.</li>
                <li>So, we're partitioning the algorithm into two parts: First part minimizes the $c$ variables. Second part minimizes the $J$ variables.</li>
            </ul>
            <h2 id="random-initialization">Random initialization</h2>
            <p>Depending on the starting setting, K means might converge to different solutions.</p>
            <p><img alt="optimum_cluster" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/optimum_cluster.png" /></p>
            <ul>
                <li>Randomly initialize K-means.</li>
                <li>For each n (e.g. 100) random initialization run K-means.</li>
                <li>Then compute the distortion on the set of cluster assignments and centroids at convergent.</li>
                <li>End with n ways of cluster the data.</li>
                <li>Pick the clustering which gave the lowest distortion.</li>
            </ul>
            <h2 id="elbow-method">Elbow method</h2>
            <ul>
                <li>How do we choose the number of clusters K?</li>
                <li>Vary K and compute cost function at a range of K values.</li>
                <li>$J(...)$'s minimum value should decrease as K rises (i.e. you decrease the granularity so centroids can better optimize).</li>
                <li>Look for the "elbow" on the graph ($K$ vs $J()$).</li>
            </ul>
            <p><img alt="elbow" src="https://raw.githubusercontent.com/djeada/Stanford-Machine-Learning/main/slides/resources/elbow.png" /></p>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol>
                <li><a href="#clustering">Clustering</a></li>
                <li><a href="#unsupervised-learning">Unsupervised learning</a></li>
                <li><a href="#k-means-algorithm">K-means algorithm</a></li>
                <li><a href="#k-means-for-non-separated-clusters">K-means for non-separated clusters</a></li>
                <li><a href="#k-means-optimization-objective">K means optimization objective</a></li>
                <li><a href="#random-initialization">Random initialization</a></li>
                <li><a href="#elbow-method">Elbow method</a></li>
            </ol>
        </div>
    </div>
    <div id="article-wrapper">
        <section id="article-body"></section>
        <div id="related-articles">
            <h2>Related Articles</h2>
            <ol>
                <li><a href="./stanford_machine_learning_week17.html">Stanford Machine Learning Week17</a></li>
                <li><a href="./stanford_machine_learning_week08.html">Stanford Machine Learning Week08</a></li>
                <li><a href="./stanford_machine_learning_week10.html">Stanford Machine Learning Week10</a></li>
                <li><a href="./stanford_machine_learning_week06.html">Stanford Machine Learning Week06</a></li>
                <li><a href="./stanford_machine_learning_week14.html">Stanford Machine Learning Week14</a></li>
                <li><a href="./stanford_machine_learning_week07.html">Stanford Machine Learning Week07</a></li>
                <li><a href="./stanford_machine_learning_week02.html">Stanford Machine Learning Week02</a></li>
                <li><a href="./stanford_machine_learning_week04.html">Stanford Machine Learning Week04</a></li>
                <li><a href="./stanford_machine_learning_week16.html">Stanford Machine Learning Week16</a></li>
                <li><a href="./stanford_machine_learning_week09.html">Stanford Machine Learning Week09</a></li>
                <li><a href="./stanford_machine_learning_week18.html">Stanford Machine Learning Week18</a></li>
                <li><a href="./stanford_machine_learning_week01.html">Stanford Machine Learning Week01</a></li>
                <li><a href="./stanford_machine_learning_week11.html">Stanford Machine Learning Week11</a></li>
                <li><a href="./stanford_machine_learning_week03.html">Stanford Machine Learning Week03</a></li>
                <li><a href="./stanford_machine_learning_week13.html">Stanford Machine Learning Week13</a></li>
                <li><a href="./stanford_machine_learning_week12.html">Stanford Machine Learning Week12</a></li>
                <li><a href="./stanford_machine_learning_week15.html">Stanford Machine Learning Week15</a></li>
            </ol>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/addjellouli/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../app.js"></script>
    </footer>
</body>

</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>