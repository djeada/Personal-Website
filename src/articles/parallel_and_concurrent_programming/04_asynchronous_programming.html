<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Asynchrony</title>
    <meta content="Asynchronous programming is a technique used to achieve concurrency, where tasks can be executed independently without waiting for other tasks to finish." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper"><article-section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: September 13, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: üá∫üá∏</i></p>
            <h2 id="asynchrony">Asynchrony</h2>
            <p>Asynchronous programming is a technique used to achieve concurrency, where tasks can be executed independently without waiting for other tasks to finish. It allows for nonblocking behavior, in contrast to synchronous execution that waits for one task to complete before starting the next task.</p>
            <p>Asynchronous programming is particularly useful for tasks that involve I/O operations, such as fetching data from a database, where waiting for the data retrieval could freeze the user interface.</p>
            <h3 id="building-blocks-of-asynchronous-programming">Building Blocks of Asynchronous Programming</h3>
            <p>Asynchronous programming offers non-blocking execution, which is especially beneficial for I/O-bound operations. The two main pillars of this paradigm are the event loop and async functions.</p>
            <h4 id="function-vs-corutine">Function vs Corutine</h4>
            <ul>
                <li>In programming, a <strong>function</strong> is a block of code that encapsulates a specific task, allowing it to be reused throughout the program. It usually accepts inputs called arguments and may produce a result or output by returning a value.</li>
                <li>Functions help in breaking down complex problems into smaller, manageable pieces, making the code easier to understand and maintain. They follow a synchronous execution model, meaning the program flow waits for a function to complete before proceeding to the next line of code.</li>
                <li>Upon calling a function, the program's execution enters the function, performs the defined operations, and exits once it reaches the end or encounters a return statement. The return statement provides the output of the function, which can then be used elsewhere in the program.</li>
                <li>Unlike functions, <strong>coroutines</strong> are a more advanced feature found in some programming languages, enabling a different style of concurrency. They are special constructs that allow the execution to be paused and resumed, which is useful in handling tasks that might involve waiting, such as I/O operations.</li>
                <li>Coroutines are typically used to write asynchronous code, meaning they can pause their execution at certain points (awaiting some event or resource) and later resume from where they left off. This ability helps in writing non-blocking code, making it possible to handle multiple tasks concurrently without the need for multiple threads.</li>
                <li>When a coroutine is paused, the control returns to the caller, allowing other tasks to execute in the meantime. This makes coroutines particularly useful in scenarios where tasks are I/O-bound or involve waiting for external resources, as they can efficiently manage time by not blocking the execution thread.</li>
                <li>The concept of coroutines includes the ability to yield control back to the caller, either temporarily or until a specific condition is met. This is often done using keywords like <code>yield</code> or <code>await</code>, depending on the programming language.</li>
                <li>While functions have a straightforward call and return structure, coroutines can enter a suspended state and later continue execution, maintaining their state across these suspensions. This feature makes them a powerful tool for implementing complex control flows and handling asynchronous programming patterns.</li>
            </ul>
            <p>
            <div>
                <pre><code class="language-shell">Function:                         Coroutine:
+-------------------+             +-------------------+
|       Start       |             |       Start       |
+-------------------+             +-------------------+
           |                                 |
           v                                 v
+-------------------+             +-------------------+
|   Execute Task    |             |   Execute Part 1  |
+-------------------+             +-------------------+
           |                                 |
           v                                 v
+-------------------+             +-------------------+
|       End         |             |       Pause       |
+-------------------+             +-------------------+
                                             |
                                             v
                                  +-------------------+
                                  |   Execute Part 2  |
                                  +-------------------+
                                             |
                                             v
                                  +-------------------+
                                  |       End         |
                                  +-------------------+</code></pre>
            </div>
            </p>
            <h4 id="event-loop">Event Loop</h4>
            <ul>
                <li>The <strong>event loop</strong> serves as the core mechanism in asynchronous programming, continuously monitoring and managing the execution of tasks. It operates by repeatedly checking for tasks that are ready to execute, ensuring efficient management of operations.</li>
                <li>Key responsibilities of the event loop include the <strong>registration</strong> and <strong>scheduling</strong> of tasks for execution, which involves keeping track of tasks and determining when they should run. It also handles event dispatch, a process crucial for managing I/O operations by directing them to the appropriate handlers once they are complete.</li>
                <li>Additionally, the event loop is responsible for timer management, overseeing <strong>timeouts</strong> and the scheduling of tasks that need to occur at specific times. This includes setting up and triggering tasks based on time-based conditions. A notable aspect of the event loop's functionality is its ability to enable concurrent task execution even within single-threaded environments. By efficiently managing multiple tasks, it allows them to progress without blocking one another, thus maximizing the use of available resources.</li>
            </ul>
            <p>
            <div>
                <pre><code class="language-shell">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ  Code Runs  ‚îÇ
                   ‚îÇ  on Stack   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Async Functions / Web APIs   ‚îÇ
   ‚îÇ  do background tasks, timers, ‚îÇ
   ‚îÇ  network calls, etc.          ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   (Completion triggers callback)
                   ‚îÇ  Callback   ‚îÇ   ‚Üí placed into Task Queue
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ           Task Queue          ‚îÇ
   ‚îÇ   (events, callbacks waiting) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                (Event Loop Checks)
                         ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ  Call Stack ‚îÇ ‚Üê‚îÄ Pushed again
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [ Repeat Cycle... ]</code></pre>
            </div>
            </p>
            <h4 id="futures-and-tasks">Futures and Tasks</h4>
            <ul>
                <li>In asynchronous programming, a <strong>future</strong> serves as a placeholder for a result that will be available at some point in the future, representing the outcome of an asynchronous operation. It can initially be in a pending state, indicating that the operation has not yet completed, and later transitions to a completed state when the result is available or to a failed state if an error occurs.</li>
                <li>Futures are often used to check the <strong>status</strong> of an ongoing operation, allowing developers to determine whether the operation has finished or is still in progress. They can also retrieve the result once the operation is complete or handle any exceptions that might have arisen during execution.</li>
                <li>While futures themselves do not execute tasks, they are associated with the <strong>results</strong> produced by an executor, such as an event loop or a thread pool. This association helps manage and track the completion of asynchronous operations.</li>
                <li>A <strong>task</strong> is a specific type of future designed to represent a coroutine in asynchronous programming. It is used to encapsulate the execution of a coroutine, allowing for the scheduling and management of these coroutines.</li>
                <li>Unlike a general future, a task can be <strong>awaited</strong>, which means that other coroutines can pause their execution until the task is completed. This non-blocking behavior is crucial for maintaining the responsiveness of applications, as it allows other operations to continue running while waiting for the task to finish.</li>
                <li>Tasks are managed by the <strong>event loop</strong>, which schedules them to run concurrently with other tasks. This scheduling capability is essential for handling multiple operations simultaneously, such as processing multiple user requests or performing data analysis in parallel.</li>
                <li>One of the key features of tasks is their ability to be <strong>canceled</strong>, which provides control over the execution flow, especially in situations where the task is no longer needed. Additionally, tasks can be combined or gathered, allowing developers to wait for multiple tasks to complete before proceeding with further actions.</li>
                <li>The use of tasks in asynchronous programming enables developers to <strong>chain dependent operations</strong>, where the completion of one task can trigger the start of another. This chaining helps in creating complex workflows and ensuring that operations occur in the desired sequence.</li>
            </ul>
            <h3 id="asynchrony-vs-multithreading">Asynchrony vs. Multithreading</h3>
            <ul>
                <li>In <em>asynchrony</em>, cooperative scheduling allows tasks to yield at <code>await</code> or callbacks, which works well for I/O-bound concurrency, while omitting this model forces developers to block on slow operations; for example, async HTTP requests let hundreds of downloads proceed concurrently without dedicated threads.</li>
                <li>With <em>threads</em>, the operating system applies preemptive scheduling through time-slicing, which supports CPU-bound parallelism, whereas relying solely on async would underutilize CPU cores; image processing workloads illustrate this by achieving faster performance with multithreading.</li>
                <li>Systems can <em>combine</em> async with threads or processes to handle mixed workloads efficiently, while skipping this layering can cause bottlenecks; for instance, a web server may run async for client connections while delegating encryption or compression to worker threads.</li>
                <li>The concept of <em>concurrency</em> refers to making progress on multiple tasks within the same period, even if interleaved rather than simultaneous, while ignoring concurrency forces strictly sequential execution; a spreadsheet app demonstrates concurrency by saving files while still accepting user input.</li>
                <li>The concept of <em>parallelism</em> involves executing tasks at the same instant across multiple cores or threads, whereas omitting parallelism keeps heavy tasks serial; a video encoding pipeline benefits from true parallelism by distributing frames across cores.</li>
            </ul>
            <p>Async gives you concurrency on one thread by <em>not blocking</em>; threads give you preemptive concurrency and, with multiple cores, true parallelism.</p>
            <p>Legend: letters = task running on CPU; <code>-</code> = not running (blocked, waiting, or preempted)</p>
            <p><strong>I. Synchronous, single thread</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">single thread: AAAA BBBBBBBBBBBBBBBBBBBBBB CCCCCCCCCC</code></pre>
            </div>
            </p>
            <p>Tasks run to completion one after another; others wait.</p>
            <p><strong>II. Synchronous, multiple threads (OS preemption)</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">thread 1: AAAAAAAAAAAA------------------------------
thread 2: ------------BBBBBB------------------------
thread 3: ------------------CCCCCCCCCCCCCCCCCCCCCCCC</code></pre>
            </div>
            </p>
            <p>Each thread can be scheduled independently; with multiple cores, B and C may truly run in parallel.</p>
            <p><strong>III. Asynchronous, single thread (cooperative)</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">single thread: AAAA----BBBB----AA--CCC--AA--BBBB----CCCC</code></pre>
            </div>
            </p>
            <p>Tasks <strong>yield</strong> at awaits; the event loop runs whatever is ready. No parallel CPU work‚Äîjust efficient interleaving during I/O waits.</p>
            <p><strong>IV. Asynchronous + multiple threads (hybrid)</strong></p>
            <p>
            <div>
                <pre><code class="language-shell">thread 1 (event loop): AAAAAA--A--A--C--A--B--C--A------
thread 2 (worker):     ---BBBBBBBB-----------------------
thread 3 (worker):     -----------CCCCCCCC--------------</code></pre>
            </div>
            </p>
            <p>An async event loop offloads blocking/CPU-heavy bits to a thread (or process) pool.</p>
            <p><strong>Quick comparison</strong></p>
            <p>
            <table>
                <tr>
                    <td>Aspect</td>
                    <td>Asynchrony</td>
                    <td>Threads</td>
                </tr>
                <tr>
                    <td>Scheduling</td>
                    <td><strong>Cooperative</strong> (<code>await</code>/callbacks)</td>
                    <td><strong>Preemptive</strong> (OS time slices)</td>
                </tr>
                <tr>
                    <td>Best for</td>
                    <td>Many <strong>I/O-bound</strong> tasks (network, disk)</td>
                    <td><strong>CPU-bound</strong> work; true parallelism</td>
                </tr>
                <tr>
                    <td>Cost</td>
                    <td>Lightweight (no per-task stack)</td>
                    <td>Heavier (stack, context switches)</td>
                </tr>
                <tr>
                    <td>Hazards</td>
                    <td>Blocking the loop stalls everything</td>
                    <td>Races, deadlocks, contention</td>
                </tr>
                <tr>
                    <td>Composition</td>
                    <td>Futures/Promises, event loop</td>
                    <td>Locks, atomics, queues, thread-safe libs</td>
                </tr>
            </table>
            </p>
            <p><strong>When to use what</strong></p>
            <ul>
                <li>When a workload is <em>mostly I/O-bound</em>, using async ensures that the event loop remains responsive by avoiding blocking calls, while omitting async leads to wasted time waiting on network or file operations; for example, a web scraper benefits from async when handling many simultaneous HTTP requests.</li>
                <li>If the workload is <em>mostly CPU-bound</em>, employing threads or processes enables true parallel execution, while sticking to async alone results in slow performance; image rendering pipelines often gain efficiency through multiprocessing rather than async.</li>
                <li>For a <em>mixed workload</em>, combining an async architecture with a worker pool allows I/O tasks to run efficiently alongside offloaded CPU-heavy jobs, whereas not separating these concerns creates bottlenecks; an example is an API server that handles requests asynchronously but delegates data compression to worker threads.</li>
            </ul>
            <p><strong>Practical tips</strong></p>
            <ul>
                <li>Blocking APIs should be offloaded to a pool rather than called directly in an <em>async event loop</em>, since doing so keeps the event loop responsive, whereas failing to offload causes the entire system to stall; for instance, a blocking database driver can freeze an async web server if not isolated.</li>
                <li>Using <em>structured concurrency</em> through task groups or scopes ensures that tasks complete or are cleaned up together, while omitting it risks resource leaks and orphaned operations; a file upload service benefits by grouping related subtasks under one scope for reliable cancellation.</li>
                <li>Applying <em>timeouts</em>, cancellation, and backpressure mechanisms maintains responsiveness under load, whereas skipping them allows unbounded waits or uncontrolled demand; for example, an API gateway can enforce request timeouts and throttle traffic to prevent overload.</li>
                <li>Thread-based programs run more reliably when they emphasize <em>immutable data</em> or message passing, which minimizes shared state, while ignoring this practice increases the risk of race conditions; a logging service illustrates this by passing immutable log messages through queues instead of sharing mutable buffers.</li>
            </ul>
            <h3 id="challenges-and-considerations">Challenges and Considerations</h3>
            <ul>
                <li>In <em>asynchronous programming</em>, functions cooperate by yielding control rather than being preemptively interrupted, which contrasts with multithreading and allows efficient coordination of concurrent tasks.</li>
                <li>When synchronization primitives like <em>locks</em> are unnecessary, systems avoid overhead and complexity, but without this model, developers must manage race conditions manually; for example, file writes in multithreaded applications often require explicit locks.</li>
                <li>Task switching becomes more efficient because transitions are lightweight compared to heavy <em>thread</em> context switches, whereas omitting this model can cause performance degradation; a web server handling many requests demonstrates this efficiency gain.</li>
                <li>Integrating <em>synchronous functions</em> without care can block the event loop and reduce throughput, while properly handling them ensures responsiveness; for instance, a synchronous database call in an async API can stall user requests if left unaddressed.</li>
                <li>Developers who refactor code for <em>asynchronous execution</em> or use utilities like <code>run_in_executor</code> maintain system efficiency, whereas failing to do so can lead to bottlenecks; an example is offloading CPU-heavy image processing to a separate thread.</li>
                <li>Inadequate <em>error handling</em> within coroutines allows exceptions to propagate and disrupt the event loop, while robust handling preserves application stability; for example, catching timeouts in API calls prevents full service outages.</li>
                <li>Propagation of <em>errors</em> through asynchronous chains can spread failures silently if unchecked, but implementing structured exception management ensures predictable behavior; a payment service benefits by isolating transaction failures without crashing the system.</li>
                <li>Debugging becomes more difficult when <em>asynchronous code</em> executes out of sequence, while structured debugging practices provide clarity; for instance, tracing delayed tasks in a chat application is easier with event loop inspection tools.</li>
                <li>Detailed <em>logging</em> and utilities such as <code>asyncio.debug()</code> reveal task states and pauses, aiding problem resolution, whereas relying only on traditional debugging tools leaves gaps; real-world debugging of web crawlers often relies on such logging.</li>
                <li>While <em>I/O-bound operations</em> are well supported, asynchronous models perform poorly for CPU-heavy workloads, making mismatched use inefficient; for example, a machine learning training loop gains little benefit from async patterns.</li>
                <li>A <em>hybrid approach</em> that combines async I/O with multiprocessing or threading handles diverse workloads effectively, while ignoring this option limits scalability; a video streaming service often mixes async network handling with parallel encoding tasks.</li>
                <li>Uncontrolled <em>backpressure</em> overwhelms consumers when producers outpace them, while active regulation prevents overload; streaming platforms, for instance, apply buffering or throttling to stabilize video playback.</li>
                <li>Techniques such as <em>buffering</em> or load shedding smooth data flow, whereas neglecting them risks dropped requests and instability; online gaming servers commonly apply these controls to maintain responsiveness.</li>
                <li>Testing becomes challenging when <em>asynchronous code</em> behaves unpredictably, while tailored testing methods ensure reliability; skipping such methods makes timing issues harder to detect, as in asynchronous chatbots.</li>
                <li>Tools like <em>pytest-asyncio</em> simulate concurrent scenarios accurately, supporting robust testing, whereas generic frameworks miss timing-dependent bugs; for example, async test suites validate the order of financial transaction processing.</li>
            </ul>
            <h3 id="typical-applications">Typical Applications</h3>
            <p>
            <div>
                <pre><code class="language-markdown">| Use case | Pattern summary | C++ (preferred) | Python (preferred) | Why this choice | Shutdown behavior |
|---|---|---|---|---|---|
| High-concurrency HTTP **client** (scraper/crawler) | Fire thousands of non-blocking requests with bounded concurrency | C++20 coroutines + Boost.Asio/Beast; semaphore to cap in-flight | <code>asyncio</code> + <code>aiohttp</code> + <code>asyncio.Semaphore</code> | Excellent overlap of network waits; minimal threads | Cancel pending tasks, close <code>ClientSession</code>, await <code>gather(return_exceptions=True)</code> |
| High-concurrency HTTP **server** (API) | Event-loop reactor accepts and services requests | Boost.Asio/Beast coroutines; strand for handler serialization | FastAPI/Starlette on <code>uvicorn</code>/<code>hypercorn</code> (async) | Scales with connections, low memory/ctx switches | Stop accepting, drain keep-alives, graceful shutdown hook, time-boxed cancel of tasks |
| WebSockets chat/broadcast | Long-lived duplex connections, fan-out messages | Asio coroutines + Beast websockets | <code>websockets</code> / <code>aiohttp</code> WS | Async fits many idle sockets efficiently | Close WS with codes, cancel producers, flush queues |
| Reverse proxy / gateway | Stream request/response bodies, back-pressure | Asio coroutines + Beast, async stream copy | <code>aiohttp</code> proxy / <code>anyio</code> streams | Zero-copy-ish streaming, flow control | Cancel copy tasks, half-close, drain, then close |
| Streaming pipeline (socket‚Üítransform‚Üísink) | Staged coroutines linked by queues | Asio + coroutines + bounded queues | <code>asyncio.Queue</code> + tasks per stage | Back-pressure &amp; simple composition | Send sentinels/cancel, drain queues, await tasks |
| DB access (async driver) | Pooled async connections, transactions | Driver-specific async APIs (e.g., <code>ozo</code> for PG) | <code>asyncpg</code> / <code>databases</code> / SQLAlchemy async | Avoid thread pools for I/O; better throughput | Close pools, finish in-flight txns, cancel long queries |
| Periodic jobs/heartbeats | <code>while</code> loop with async sleep and cancellation | <code>co_await async_timer</code> (Asio steady_timer) | <code>asyncio.TaskGroup</code> + <code>asyncio.sleep()</code> | Cheap timers; easy cooperative cancel | Respect cancel, final iteration optional, stop timers |
| RPC client with retries/timeouts | Issue calls with per-call timeout, jittered retry | Asio + timers + coroutines | <code>asyncio.wait_for</code> + retry (tenacity/hand-rolled) | Compose timeouts &amp; retries declaratively | Cancel on shutdown, abort retries, close transports |
| Bulk cloud uploads/downloads | Many concurrent objects with windowing | Asio coroutines + HTTP/S3 libs | <code>aiohttp</code>/SDK async clients | Hide latency; cap bandwidth with semaphores | Finish in-flight or checkpoint parts; close sessions |
| Batched DNS resolution | Pipeline many lookups concurrently | Asio async resolver + coroutines | <code>asyncio.getaddrinfo</code> in threadpool or <code>aiodns</code> | Parallelize high-latency lookups | Cancel outstanding; cache results; close resolver |
| MQ consumers/producers | Async consume/ack/publish with flow control | Asio + AMQP/Kafka client coroutines | <code>aio-pika</code>, <code>aiokafka</code> | Natural fit for broker I/O | Stop consume, flush acks/publishes, close channels |
| GUI app non-blocking network I/O | Keep UI thread responsive | Qt + coroutines/Asio; integrate event loops | Qt + <code>qasync</code> + <code>asyncio</code> | Avoids UI stalls; fewer threads | Cancel tasks before closing UI; disconnect signals |
| IoT gateway (many devices) | Thousands of idle TCP/MQTT sessions | Asio coroutines + strands | <code>asyncio-mqtt</code> / <code>asyncio</code> sockets | Async handles massive concurrency cheaply | Unsubscribe, close sockets, persist offsets/state |
| Rate-limited API worker | Token bucket + bounded concurrency | Asio timers + custom bucket | <code>anyio</code>/<code>asyncio</code> + leaky/token bucket | Smooths bursts; avoids 429s | Flush queue, stop token refills, cancel waiters |
| Async file‚Üîsocket streaming | Non-blocking file read/write to sockets | <code>io_uring</code> / Asio + files (platform-dep.) | <code>aiofiles</code> + <code>asyncio</code> streams | Preserve event-loop responsiveness | Flush buffers, fsync if needed, close handles |
| Bulk email/SMS send | Many slow servers; pipeline SMTP/API calls | Asio + SMTP/HTTP libs | <code>aiosmtplib</code> / async provider SDKs | Great for I/O-bound fan-out | Drain queues, handle deferred failures, close clients |
| Health checks/monitoring fan-out | Probe many endpoints on schedule | Asio coroutines + timers | <code>asyncio</code> + <code>aiohttp</code> + <code>gather</code> | Concurrency with small footprint | Cancel probes on exit; aggregate partial results |
| Lightweight multiplayer/session server | Many small messages per client | Asio UDP/TCP coroutines | <code>asyncio</code> UDP/TCP protocols | Low latency, single-threaded logic | Kick clients, flush outbound, close transports |
| Metrics fan-in (statsd/OTLP) | Receive, batch, forward asynchronously | Asio + UDP/TCP, batch timers | <code>asyncio</code> datagrams + batch send | High throughput with batching | Flush batch, stop intake, close sockets |
| Async subprocess orchestration | Start many short jobs, stream stdio | Asio + Boost.Process + async pipes | <code>asyncio.create_subprocess_exec</code> | Avoid blocking; supervise easily | Terminate on timeout, drain pipes, await <code>wait()</code> |
| Webhook/event handler workers | Handle many webhooks concurrently | Asio HTTP server + task queue | FastAPI + background <code>TaskGroup</code> | Bursty, I/O-bound workloads | Stop intake, finish tasks (time-boxed), persist offsets |
| ‚ÄúFire-and-forget‚Äù background task | Task not waited but tracked | Coroutine + supervisor registry | <code>asyncio.create_task</code> + tracking | Keep app responsive, but retain control | Store task refs; cancel explicitly on shutdown |
| Bridging blocking call into async | Isolate blocking library call | Thread pool just for the call | <code>asyncio.to_thread()</code> | Keep loop unblocked without full rewrite | Await completion; cap worker threads; cancel if long |</code></pre>
            </div>
            </p>
            <h3 id="examples">Examples</h3>
            <h4 id="examples-in-c-">Examples in C++</h4>
            <p>Asynchronous programming in C++ involves performing tasks without blocking the main thread, allowing other operations to continue in parallel. This can be particularly useful for I/O-bound or computationally intensive tasks. The C++ Standard Library provides facilities for asynchronous programming, including the <code>std::async</code> function, <code>std::future</code>, and <code>std::promise</code>.</p>
            <h5>Asynchronous Tasks with <code>std::async</code></h5>
            <p>The <code>std::async</code> function runs a function asynchronously, returning a <code>std::future</code> that will eventually hold the result of the function.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;

int compute(int x) {
    std::this_thread::sleep_for(std::chrono::seconds(2)); // Simulate a long computation
    return x * x;
}

int main() {
    std::future&lt;int&gt; future = std::async(std::launch::async, compute, 5);

    std::cout &lt;&lt; "Doing other work while waiting for the result..." &lt;&lt; std::endl;

    int result = future.get(); // Wait for the result
    std::cout &lt;&lt; "Result: " &lt;&lt; result &lt;&lt; std::endl;

    return 0;
}</code></pre>
            </div>
            </p>
            <p>In this example, <code>std::async</code> launches the <code>compute</code> function asynchronously, allowing the main thread to continue executing other code. The <code>future.get()</code> method waits for the result and retrieves it once the computation is complete.</p>
            <h5>Using <code>std::future</code> and <code>std::promise</code></h5>
            <p><code>std::future</code> and <code>std::promise</code> provide a way to communicate between threads asynchronously. A <code>std::promise</code> object is used to set a value that will be available to a <code>std::future</code> object.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;

void set_value(std::promise&lt;int&gt;&amp; promise) {
    std::this_thread::sleep_for(std::chrono::seconds(1));
    promise.set_value(10); // Set the value to be retrieved by future
}

int main() {
    std::promise&lt;int&gt; promise;
    std::future&lt;int&gt; future = promise.get_future();

    std::thread t(set_value, std::ref(promise));
    
    std::cout &lt;&lt; "Waiting for value..." &lt;&lt; std::endl;
    int value = future.get(); // Wait for the value
    std::cout &lt;&lt; "Value: " &lt;&lt; value &lt;&lt; std::endl;

    t.join();
    return 0;
}</code></pre>
            </div>
            </p>
            <p>In this example, the <code>set_value</code> function sets a value to the promise, which is then retrieved by the future in the main thread.</p>
            <h5>Asynchronous Waiting with <code>std::future</code></h5>
            <p>The <code>std::future</code> object provides a way to wait for a result that is being computed asynchronously.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;

int slow_add(int a, int b) {
    std::this_thread::sleep_for(std::chrono::seconds(3));
    return a + b;
}

int main() {
    std::future&lt;int&gt; future = std::async(std::launch::async, slow_add, 3, 4);

    while (future.wait_for(std::chrono::milliseconds(500)) != std::future_status::ready) {
        std::cout &lt;&lt; "Waiting for the result..." &lt;&lt; std::endl;
    }

    std::cout &lt;&lt; "Result: " &lt;&lt; future.get() &lt;&lt; std::endl;
    return 0;
}</code></pre>
            </div>
            </p>
            <p>Here, <code>future.wait_for</code> periodically checks if the result is ready, allowing the main thread to perform other tasks while waiting.</p>
            <h5>Exception Handling with Asynchronous Operations</h5>
            <p>Exceptions thrown in asynchronous tasks are captured by <code>std::future</code> and can be re-thrown when <code>future.get()</code> is called.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;stdexcept&gt;

int risky_task() {
    throw std::runtime_error("Something went wrong");
    return 42; // This line won't be reached
}

int main() {
    std::future&lt;int&gt; future = std::async(std::launch::async, risky_task);

    try {
        int result = future.get();
        std::cout &lt;&lt; "Result: " &lt;&lt; result &lt;&lt; std::endl;
    } catch (const std::exception&amp; e) {
        std::cerr &lt;&lt; "Caught exception: " &lt;&lt; e.what() &lt;&lt; std::endl;
    }

    return 0;
}</code></pre>
            </div>
            </p>
            <p>In this code, the exception thrown in <code>risky_task</code> is caught in the main thread when <code>future.get()</code> is called.</p>
            <h5>Asynchronous Data Sharing with <code>std::shared_future</code></h5>
            <p>A <code>std::shared_future</code> allows multiple threads to share the result of an asynchronous operation.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

int compute_value() {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    return 10;
}

int main() {
    std::shared_future&lt;int&gt; shared_future = std::async(std::launch::async, compute_value).share();

    std::vector&lt;std::thread&gt; threads;
    for (int i = 0; i &lt; 5; ++i) {
        threads.emplace_back([shared_future, i]() {
            std::cout &lt;&lt; "Thread " &lt;&lt; i &lt;&lt; ": " &lt;&lt; shared_future.get() &lt;&lt; std::endl;
        });
    }

    for (auto&amp; thread : threads) {
        thread.join();
    }

    return 0;
}</code></pre>
            </div>
            </p>
            <p>In this example, the result of <code>compute_value</code> is shared among multiple threads using <code>std::shared_future</code>.</p>
            <h5>Asynchronous Continuations with <code>std::future</code></h5>
            <p>Asynchronous continuations allow chaining of asynchronous operations.</p>
            <p>
            <div>
                <pre><code class="language-clike">#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;chrono&gt;

int initial_task() {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    return 5;
}

int next_task(int input) {
    return input * 2;
}

int main() {
    auto future = std::async(std::launch::async, initial_task)
                    .then([](std::future&lt;int&gt; fut) {
                        return next_task(fut.get());
                    });

    std::cout &lt;&lt; "Result: " &lt;&lt; future.get() &lt;&lt; std::endl;
    return 0;
}</code></pre>
            </div>
            </p>
            <p>Here, <code>initial_task</code> runs asynchronously, and once it completes, <code>next_task</code> is executed with the result.</p>
            <h5>Performance Considerations and Best Practices</h5>
            <ul>
                <li>Use asynchronous operations for long-running tasks to keep the main thread responsive.</li>
                <li>Ensure that exceptions are properly handled in asynchronous tasks to prevent crashes.</li>
                <li>Be cautious with resources shared between asynchronous tasks; use synchronization mechanisms like mutexes if necessary.</li>
                <li>Creating too many threads can be costly. Use asynchronous mechanisms and thread pools where appropriate.</li>
                <li>Leverage C++11 and later features like <code>std::async</code>, <code>std::future</code>, and <code>std::promise</code> for cleaner and more efficient asynchronous programming.</li>
            </ul>
            <p>
            <table>
                <tr>
                    <td>No.</td>
                    <td>Filename</td>
                    <td>Description</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/01_basic_async.cpp">01_basic_async.cpp</a></td>
                    <td>Create and start a basic asynchronous task</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/02_future_create_task.cpp">02_future_create_task.cpp</a></td>
                    <td>Create a task using Future and run it asynchronously</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/03_future_read_result.cpp">03_future_read_result.cpp</a></td>
                    <td>Read the result of a completed Future task</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/04_pause_resume.cpp">04_pause_resume.cpp</a></td>
                    <td>Pause and resume asynchronous tasks</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/05_run_heavy_functions.cpp">05_run_heavy_functions.cpp</a></td>
                    <td>Execute heavy functions asynchronously</td>
                </tr>
                <tr>
                    <td>6</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/06_data_sharing_queue.cpp">06_data_sharing_queue.cpp</a></td>
                    <td>Share data between asynchronous tasks using a Queue</td>
                </tr>
                <tr>
                    <td>7</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/07_semaphore.cpp">07_semaphore.cpp</a></td>
                    <td>Control access to shared resources with a Semaphore</td>
                </tr>
                <tr>
                    <td>8</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/08_producer_consumer.cpp">08_producer_consumer.cpp</a></td>
                    <td>Implement a producer-consumer pattern asynchronously</td>
                </tr>
                <tr>
                    <td>9</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/09_fetch_parallel.cpp">09_fetch_parallel.cpp</a></td>
                    <td>Fetch data in parallel using async tasks</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/10_mutex.cpp">10_mutex.cpp</a></td>
                    <td>Use a Mutex to synchronize access to shared resources</td>
                </tr>
                <tr>
                    <td>11</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/11_barrier.cpp">11_barrier.cpp</a></td>
                    <td>Synchronize multiple asynchronous tasks using a Barrier</td>
                </tr>
                <tr>
                    <td>12</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/12_async_generator.cpp">12_async_generator.cpp</a></td>
                    <td>Create and use asynchronous generators</td>
                </tr>
                <tr>
                    <td>13</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/13_async_server.cpp">13_async_server.cpp</a></td>
                    <td>Implement an asynchronous server</td>
                </tr>
                <tr>
                    <td>14</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/cpp/asynchrony/14_distributed_computing.cpp">14_distributed_computing.cpp</a></td>
                    <td>Demonstrate distributed computing with async tasks</td>
                </tr>
            </table>
            </p>
            <h4 id="examples-in-python">Examples in Python</h4>
            <p>In Python, asynchronous programming allows you to run code concurrently without creating new threads or processes. This is especially useful for I/O-bound tasks, such as network requests or file operations, where waiting for an operation to complete would otherwise block other code from running. Python's <code>asyncio</code> library provides the primary framework for writing asynchronous code using the <code>async</code> and <code>await</code> keywords.</p>
            <h5>Asynchronous Functions</h5>
            <p>An asynchronous function is defined using the <code>async def</code> syntax. These functions return a coroutine, which is an object representing the eventual result of the function.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio

async def print_message(message):
    print(message)

# Example usage
async def main():
    await print_message("Hello from an asynchronous function!")

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>In this example, <code>print_message</code> is an asynchronous function that prints a message. The <code>main</code> function calls it with <code>await</code>, indicating it will wait for the coroutine to complete.</p>
            <h5>Running Asynchronous Tasks</h5>
            <p>You can run multiple asynchronous tasks concurrently using <code>asyncio.create_task()</code> or by awaiting multiple coroutines.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio

async def print_message(message):
    await asyncio.sleep(1)
    print(message)

async def main():
    task1 = asyncio.create_task(print_message("Task 1"))
    task2 = asyncio.create_task(print_message("Task 2"))
    await task1
    await task2

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>Here, <code>asyncio.create_task()</code> schedules the coroutines to run concurrently. The <code>await</code> statements ensure that <code>main</code> waits for both tasks to finish.</p>
            <h5>Handling Concurrent I/O Operations</h5>
            <p>Asynchronous functions are ideal for I/O-bound tasks where blocking operations can slow down the program. For example, making HTTP requests.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio
import aiohttp

async def fetch(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()

async def main():
    url = "http://example.com"
    html = await fetch(url)
    print(html)

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>In this example, <code>fetch</code> uses <code>aiohttp</code> for asynchronous HTTP requests. This allows multiple requests to be handled without blocking the event loop.</p>
            <h5>Awaiting Multiple Tasks</h5>
            <p>You can run multiple coroutines concurrently using <code>await asyncio.gather()</code>.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio

async def fetch_data(n):
    await asyncio.sleep(n)
    return f"Data {n}"

async def main():
    results = await asyncio.gather(
        fetch_data(1),
        fetch_data(2),
        fetch_data(3)
    )
    print(results)

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p><code>asyncio.gather()</code> waits for all the provided coroutines to finish and returns their results in a list.</p>
            <h5>Using Async Context Managers</h5>
            <p>Async context managers, defined with <code>async with</code>, are used to manage resources that require cleanup after use.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio
import aiofiles

async def write_to_file(filename, content):
    async with aiofiles.open(filename, 'w') as file:
        await file.write(content)

async def main():
    await write_to_file('example.txt', 'Hello, Async World!')

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>In this example, <code>aiofiles</code> is used for asynchronous file operations. The file is automatically closed after writing.</p>
            <h5>Exception Handling in Asynchronous Code</h5>
            <p>Handling exceptions in asynchronous code is similar to synchronous code, using try-except blocks.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio

async def may_raise_exception():
    await asyncio.sleep(1)
    raise ValueError("An error occurred!")

async def main():
    try:
        await may_raise_exception()
    except ValueError as e:
        print(f"Caught an exception: {e}")

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>Here, the exception raised in <code>may_raise_exception</code> is caught and handled in <code>main</code>.</p>
            <h5>Asynchronous Iteration</h5>
            <p>Asynchronous iterators and iterables allow for asynchronous looping, useful when dealing with streams or large datasets.</p>
            <p>
            <div>
                <pre><code class="language-python">import asyncio

class AsyncCounter:
    def __init__(self, limit):
        self.limit = limit
        self.count = 0

    async def __aiter__(self):
        return self

    async def __anext__(self):
        if self.count &lt; self.limit:
            await asyncio.sleep(1)
            self.count += 1
            return self.count
        else:
            raise StopAsyncIteration

async def main():
    async for number in AsyncCounter(3):
        print(number)

asyncio.run(main())</code></pre>
            </div>
            </p>
            <p>In this example, <code>AsyncCounter</code> is an asynchronous iterable that generates numbers with a delay.</p>
            <h5>Performance Considerations and Best Practices</h5>
            <ul>
                <li>Ensure that all time-consuming or blocking calls are made asynchronously. This keeps the event loop responsive.</li>
                <li>Use async context managers to manage resources, such as files or network connections, ensuring proper cleanup.</li>
                <li>Handle exceptions carefully to avoid silent failures, especially when dealing with multiple concurrent tasks.</li>
                <li>Be mindful of task cancellation. Use <code>try...finally</code> blocks to clean up resources if a task is canceled.</li>
                <li>Use mechanisms like semaphores to limit the number of concurrent tasks if interacting with rate-limited resources or APIs.</li>
            </ul>
            <p>
            <table>
                <tr>
                    <td>No.</td>
                    <td>Filename</td>
                    <td>Description</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/01_basic_async.py">01_basic_async.py</a></td>
                    <td>Create and start a basic asynchronous task</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/02_future_create_task.py">02_future_create_task.py</a></td>
                    <td>Create a task using Future and run it asynchronously</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/03_future_read_result.py">03_future_read_result.py</a></td>
                    <td>Read the result of a completed Future task</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/04_pause_resume.py">04_pause_resume.py</a></td>
                    <td>Pause and resume asynchronous tasks</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/05_run_heavy_functions.py">05_run_heavy_functions.py</a></td>
                    <td>Execute heavy functions asynchronously</td>
                </tr>
                <tr>
                    <td>6</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/06_data_sharing_queue.py">06_data_sharing_queue.py</a></td>
                    <td>Share data between asynchronous tasks using a Queue</td>
                </tr>
                <tr>
                    <td>7</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/07_semaphore.py">07_semaphore.py</a></td>
                    <td>Control access to shared resources with a Semaphore</td>
                </tr>
                <tr>
                    <td>8</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/08_producer_consumer.py">08_producer_consumer.py</a></td>
                    <td>Implement a producer-consumer pattern asynchronously</td>
                </tr>
                <tr>
                    <td>9</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/09_fetch_parallel.py">09_fetch_parallel.py</a></td>
                    <td>Fetch data in parallel using async tasks</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/10_mutex.py">10_mutex.py</a></td>
                    <td>Use a Mutex to synchronize access to shared resources</td>
                </tr>
                <tr>
                    <td>11</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/11_barrier.py">11_barrier.py</a></td>
                    <td>Synchronize multiple asynchronous tasks using a Barrier</td>
                </tr>
                <tr>
                    <td>12</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/12_async_generator.py">12_async_generator.py</a></td>
                    <td>Create and use asynchronous generators</td>
                </tr>
                <tr>
                    <td>13</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/13_async_server.py">13_async_server.py</a></td>
                    <td>Implement an asynchronous server</td>
                </tr>
                <tr>
                    <td>14</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/python/asynchrony/14_distributed_computing.py">14_distributed_computing.py</a></td>
                    <td>Demonstrate distributed computing with async tasks</td>
                </tr>
            </table>
            </p>
            <h4 id="examples-in-javascript">Examples in JavaScript</h4>
            <p>Node.js is inherently designed for asynchronous programming, primarily due to its non-blocking I/O model. It uses an event-driven architecture, which allows for efficient handling of concurrent operations. Asynchronous code in Node.js can be written using callbacks, Promises, and the <code>async</code>/<code>await</code> syntax.</p>
            <h5>Asynchronous Programming with Callbacks</h5>
            <p>Callbacks are the traditional way of handling asynchronous operations in Node.js. A callback is a function passed as an argument to another function, which will be called once the operation is complete.</p>
            <p>
            <div>
                <pre><code class="language-javascript">const fs = require('fs');

fs.readFile('example.txt', 'utf8', (err, data) =&gt; {
    if (err) {
        console.error('Error reading file:', err);
        return;
    }
    console.log('File contents:', data);
});

console.log('Reading file...');</code></pre>
            </div>
            </p>
            <p>In this example, <code>fs.readFile</code> reads a file asynchronously and calls the provided callback function when the operation completes, either with an error or the file's data.</p>
            <h5>Asynchronous Programming with Promises</h5>
            <p>Promises provide a more elegant way to handle asynchronous operations by avoiding the callback pyramid of doom (nested callbacks). A Promise represents a value that may be available now, or in the future, or never.</p>
            <p>
            <div>
                <pre><code class="language-javascript">const fs = require('fs').promises;

fs.readFile('example.txt', 'utf8')
    .then(data =&gt; {
        console.log('File contents:', data);
    })
    .catch(err =&gt; {
        console.error('Error reading file:', err);
    });

console.log('Reading file...');</code></pre>
            </div>
            </p>
            <p>Here, <code>fs.promises.readFile</code> returns a Promise. The <code>then</code> method handles the resolved value, while <code>catch</code> handles any errors.</p>
            <h5>Asynchronous Programming with <code>async</code>/<code>await</code></h5>
            <p>The <code>async</code>/<code>await</code> syntax in Node.js (available from ECMAScript 2017) is syntactic sugar over Promises, making asynchronous code look and behave more like synchronous code.</p>
            <p>
            <div>
                <pre><code class="language-javascript">const fs = require('fs').promises;

async function readFile() {
    try {
        const data = await fs.readFile('example.txt', 'utf8');
        console.log('File contents:', data);
    } catch (err) {
        console.error('Error reading file:', err);
    }
}

readFile();
console.log('Reading file...');</code></pre>
            </div>
            </p>
            <p>In this example, <code>async</code> declares an asynchronous function, and <code>await</code> pauses the execution until the Promise is resolved, making the code more readable and maintainable.</p>
            <h5>Handling Multiple Asynchronous Operations</h5>
            <p>Node.js provides several methods to handle multiple asynchronous operations concurrently, such as <code>Promise.all</code>, <code>Promise.race</code>, <code>Promise.allSettled</code>, and <code>Promise.any</code>.</p>
            <p>
            <div>
                <pre><code class="language-javascript">const fetch = require('node-fetch');

async function fetchData() {
    try {
        const [response1, response2] = await Promise.all([
            fetch('https://api.example.com/data1'),
            fetch('https://api.example.com/data2')
        ]);
        
        const data1 = await response1.json();
        const data2 = await response2.json();
        
        console.log('Data 1:', data1);
        console.log('Data 2:', data2);
    } catch (err) {
        console.error('Error fetching data:', err);
    }
}

fetchData();</code></pre>
            </div>
            </p>
            <p>In this example, <code>Promise.all</code> waits for all the promises to resolve before continuing. This is useful when you need to perform multiple independent asynchronous operations and handle their results together.</p>
            <h5>Error Handling in Asynchronous Code</h5>
            <p>Proper error handling is crucial in asynchronous programming to avoid crashes and ensure reliability.</p>
            <p>
            <div>
                <pre><code class="language-javascript">async function getData() {
    try {
        let response = await fetch('https://api.example.com/data');
        if (!response.ok) {
            throw new Error(<code>HTTP error! status: ${response.status}</code>);
        }
        let data = await response.json();
        return data;
    } catch (err) {
        console.error('Error:', err.message);
        // Additional error handling logic
    }
}

getData();</code></pre>
            </div>
            </p>
            <p>In this example, the error is caught using a try-catch block, allowing for graceful handling of potential failures.</p>
            <h5>Asynchronous Iteration with <code>for-await-of</code></h5>
            <p>Node.js supports asynchronous iteration using <code>for-await-of</code>, which is useful for processing streams of data.</p>
            <p>
            <div>
                <pre><code class="language-javascript">const fs = require('fs');
const readline = require('readline');

async function processLineByLine() {
    const fileStream = fs.createReadStream('example.txt');
    const rl = readline.createInterface({
        input: fileStream,
        crlfDelay: Infinity
    });

    for await (const line of rl) {
        console.log(<code>Line from file: ${line}</code>);
    }
}

processLineByLine();</code></pre>
            </div>
            </p>
            <p>Here, <code>for-await-of</code> iterates over each line of a file asynchronously, making it easier to work with data that comes in pieces, like streams.</p>
            <h5>Avoiding Callback Hell</h5>
            <p>To avoid deeply nested callbacks (callback hell), use Promises or the <code>async</code>/<code>await</code> syntax. For example:</p>
            <p>
            <div>
                <pre><code class="language-javascript">// Callback Hell Example
function doSomething(callback) {
    fs.readFile('file1.txt', 'utf8', (err, data1) =&gt; {
        if (err) return callback(err);
        fs.readFile('file2.txt', 'utf8', (err, data2) =&gt; {
            if (err) return callback(err);
            callback(null, data1 + data2);
        });
    });
}

// Using Promises or async/await
async function doSomethingBetter() {
    try {
        const data1 = await fs.readFile('file1.txt', 'utf8');
        const data2 = await fs.readFile('file2.txt', 'utf8');
        return data1 + data2;
    } catch (err) {
        console.error('Error:', err);
    }
}</code></pre>
            </div>
            </p>
            <p>Using Promises or <code>async</code>/<code>await</code> leads to cleaner and more maintainable code compared to deeply nested callbacks.</p>
            <h5>Performance Considerations and Best Practices</h5>
            <ul>
                <li>Always handle errors in asynchronous code to prevent unhandled rejections and crashes.</li>
                <li>Be mindful of concurrency, especially when interacting with rate-limited APIs or performing operations that can overwhelm system resources.</li>
                <li>Watch out for memory leaks, particularly when dealing with streams or large datasets.</li>
                <li>Use tools and techniques like <code>async_hooks</code>, <code>Node.js inspector</code>, and unit testing to debug and test asynchronous code effectively.</li>
            </ul>
            <p>
            <table>
                <tr>
                    <td>No.</td>
                    <td>Filename</td>
                    <td>Description</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/01_basic_async.js">01_basic_async.js</a></td>
                    <td>Create and start a basic asynchronous task</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/02_future_create_task.js">02_future_create_task.js</a></td>
                    <td>Create a task using Future and run it asynchronously</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/03_future_read_result.js">03_future_read_result.js</a></td>
                    <td>Read the result of a completed Future task</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/04_pause_resume.js">04_pause_resume.js</a></td>
                    <td>Pause and resume asynchronous tasks</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/05_run_heavy_functions.js">05_run_heavy_functions.js</a></td>
                    <td>Execute heavy functions asynchronously</td>
                </tr>
                <tr>
                    <td>6</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/06_data_sharing_queue.js">06_data_sharing_queue.js</a></td>
                    <td>Share data between asynchronous tasks using a Queue</td>
                </tr>
                <tr>
                    <td>7</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/07_semaphore.js">07_semaphore.js</a></td>
                    <td>Control access to shared resources with a Semaphore</td>
                </tr>
                <tr>
                    <td>8</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/08_producer_consumer.js">08_producer_consumer.js</a></td>
                    <td>Implement a producer-consumer pattern asynchronously</td>
                </tr>
                <tr>
                    <td>9</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/09_fetch_parallel.js">09_fetch_parallel.js</a></td>
                    <td>Fetch data in parallel using async tasks</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/10_mutex.js">10_mutex.js</a></td>
                    <td>Use a Mutex to synchronize access to shared resources</td>
                </tr>
                <tr>
                    <td>11</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/11_barrier.js">11_barrier.js</a></td>
                    <td>Synchronize multiple asynchronous tasks using a Barrier</td>
                </tr>
                <tr>
                    <td>12</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/12_async_generator.js">12_async_generator.js</a></td>
                    <td>Create and use asynchronous generators</td>
                </tr>
                <tr>
                    <td>13</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/13_async_server.js">13_async_server.js</a></td>
                    <td>Implement an asynchronous server</td>
                </tr>
                <tr>
                    <td>14</td>
                    <td><a href="https://github.com/djeada/Parallel-And-Concurrent-Programming/blob/master/src/js/asynchrony/14_distributed_computing.js">14_distributed_computing.js</a></td>
                    <td>Demonstrate distributed computing with async tasks</td>
                </tr>
            </table>
            </p>
            <h3 id="summary">Summary</h3>
            <p>Here is a table comparing asynchronous programming features in C++, Python, and Node.js:</p>
            <p>
            <table>
                <tr>
                    <td>Concept</td>
                    <td>C++</td>
                    <td>Python</td>
                    <td>Node.js</td>
                </tr>
                <tr>
                    <td><strong>Library</strong></td>
                    <td>Standard Library (<code>std::future</code>, <code>std::promise</code>, <code>std::async</code>) <br /> Boost.Asio</td>
                    <td><code>asyncio</code></td>
                    <td>Native support (callbacks, Promises)</td>
                </tr>
                <tr>
                    <td><strong>Event Loop</strong></td>
                    <td>Depends on the library (e.g., Boost.Asio provides I/O context)</td>
                    <td><code>asyncio</code> event loop</td>
                    <td>Event loop provided by the <code>libuv</code> library</td>
                </tr>
                <tr>
                    <td><strong>Coroutine</strong></td>
                    <td>C++20 coroutines (<code>co_await</code>, <code>co_yield</code>)</td>
                    <td><code>async def</code> (coroutine functions)</td>
                    <td>Async functions (<code>async</code> keyword)</td>
                </tr>
                <tr>
                    <td><strong>Future</strong></td>
                    <td><code>std::future</code> (contains the result of an asynchronous operation)</td>
                    <td><code>asyncio.Future</code> (contains the result of a coroutine)</td>
                    <td><code>Promise</code> (represents the eventual result of an async operation)</td>
                </tr>
                <tr>
                    <td><strong>Await</strong></td>
                    <td><code>co_await</code> (C++20)</td>
                    <td><code>await</code> (used inside <code>async def</code>)</td>
                    <td><code>await</code> (used inside async functions)</td>
                </tr>
                <tr>
                    <td><strong>Async Call</strong></td>
                    <td><code>std::async</code> or custom implementation with Boost.Asio</td>
                    <td><code>asyncio.create_task()</code>, <code>asyncio.gather()</code>, etc.</td>
                    <td>Callbacks, Promises, or <code>async/await</code> syntax</td>
                </tr>
                <tr>
                    <td><strong>Task</strong></td>
                    <td><code>std::packaged_task</code> (wraps a callable target)</td>
                    <td><code>asyncio.Task</code> (wraps a coroutine)</td>
                    <td>Promises, async functions, or callbacks</td>
                </tr>
            </table>
            </p>
        </article-section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#asynchrony">Asynchrony</a>
                <ol>
                    <li><a href="#building-blocks-of-asynchronous-programming">Building Blocks of Asynchronous Programming</a>
                        <ol>
                            <li><a href="#function-vs-corutine">Function vs Corutine</a></li>
                            <li><a href="#event-loop">Event Loop</a></li>
                            <li><a href="#futures-and-tasks">Futures and Tasks</a></li>
                        </ol>
                    </li>
                    <li><a href="#asynchrony-vs-multithreading">Asynchrony vs. Multithreading</a></li>
                    <li><a href="#challenges-and-considerations">Challenges and Considerations</a></li>
                    <li><a href="#typical-applications">Typical Applications</a></li>
                    <li><a href="#examples">Examples</a>
                        <ol>
                            <li><a href="#examples-in-c-">Examples in C++</a></li>
                            <li><a href="#examples-in-python">Examples in Python</a></li>
                            <li><a href="#examples-in-javascript">Examples in JavaScript</a></li>
                        </ol>
                    </li>
                    <li><a href="#summary">Summary</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/01_basic_terminology.html">Basic Terminology</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/02_multithreading.html">Multithreading</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/03_multiprocessing.html">Multiprocessing</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/04_asynchronous_programming.html">Asynchronous Programming</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/05_mpi.html">Mpi</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/06_hardware.html">Hardware</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/07_evaluating_performance.html">Evaluating Performance</a></li>
                    <li><a href="https://adamdjellouli.com/articles/parallel_and_concurrent_programming/08_designing_parallel_programs.html">Designing Parallel Programs</a></li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If you‚Äôd like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                ¬© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>