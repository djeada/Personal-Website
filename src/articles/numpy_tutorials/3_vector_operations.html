<!DOCTYPE html>

<html lang="en">
<head>
<script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
<meta charset="utf-8"/>
<title>Vectors</title>
<meta content="A vector is a mathematical entity characterized by both magnitude and direction." name="description"/>
<meta content="Adam Djellouli" name="author"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet"/>
<link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon"/>
<link href="../../resources/style.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>
<body><nav aria-label="Main navigation">
<a class="logo" href="https://adamdjellouli.com">
<img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG"/>
</a>
<input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox"/>
<ul aria-labelledby="navbar-toggle" role="menu">
<li role="menuitem">
<a href="../../index.html" title="Go to Home Page"> Home </a>
</li>
<li role="menuitem">
<a class="active" href="../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
</li>
<li role="menuitem">
<a href="../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
</li>
<li role="menuitem">
<a href="../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
</li>
<li role="menuitem">
<a href="../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
</li>
<li>
<script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
<div class="gcse-search"></div>
</li>
<li>
<button aria-label="Toggle dark mode" id="dark-mode-button"></button>
</li>
</ul>
</nav>
<div id="article-wrapper"><article-section id="article-body">
<p style="text-align: right;"><i>Last modified: December 25, 2025</i></p>
<p style="text-align: right;"><i>This article is written in: üá∫üá∏</i></p>
<h2 id="vectors">Vectors</h2>
<p>A vector is a mathematical entity characterized by both magnitude and direction. Vectors are essential in various fields such as linear algebra, calculus, physics, computer science, data analysis, and machine learning. In the context of NumPy, vectors are represented as one-dimensional arrays, enabling efficient computation and manipulation. This guide delves into the definition of vectors, their properties, and the operations that can be performed on them using NumPy, complemented by practical examples to illustrate each concept.</p>
<h3 id="definitions">Definitions</h3>
<p>A <strong>vector space</strong> over a field $\mathbb{F}$ (here the reals $\mathbb{R}$) is a set equipped with vector addition and scalar multiplication that satisfy eight axioms (closure, associativity, identity, inverses, distributive laws, etc.).  The canonical example is the <em>n‚Äëdimensional real coordinate space</em> $\mathbb{R}^n$.</p>
<h3 id="vector-in-mathbb-r-n-">Vector in $\mathbb{R}^n$</h3>
<p><em>Formal definition.</em>  An element $\mathbf v \in \mathbb{R}^n$ is an ordered $n$-tuple of real numbers</p>
<p>$$
  \mathbf v = (v_1,\dots,v_n) \equiv \sum_{i=1}^n v_i\mathbf e_i
$$</p>
<p>where ${\mathbf e_i}_{i=1}^n$ is the standard basis with $\mathbf e_i$ having a <em>1</em> in the $i$-th position and zeros elsewhere.</p>
<p>A vector encodes <strong>magnitude</strong> and <strong>direction</strong> relative to the origin.  In data‚Äëscience terms, it stores the <em>feature values</em> of one sample.</p>
<p><em>NumPy quick‚Äëstart.</em></p>
<p><div><pre><code class="language-python">import numpy as np
v = np.array([4, -2, 7])  # element of R^3
type(v), v.shape          # (numpy.ndarray, (3,))</code></pre></div></p>
<h4 id="row-vs-column-representation">Row vs Column Representation</h4>
<p>Vectors can be written in two orientations ‚Äî <strong>row vectors</strong> and <strong>column vectors</strong>‚Äîeach serving different roles in computations. The choice of orientation determines how vectors interact with matrices and with each other.</p>
<h5>Row Vector</h5>
<p>A <strong>row vector</strong> is a $1 \times n$ matrix, meaning it has one row and $n$ columns. Its elements are laid out horizontally:</p>
<p>$$
v = 
\begin{bmatrix}
v_1 &amp; v_2 &amp; \cdots &amp; v_n
\end{bmatrix}
$$</p>
<ul>
<li>It has shape $(1, n)$.</li>
<li>Often used to represent a single data sample with $n$ features (e.g., one row of a dataset).</li>
<li>Can multiply on the right by an $n \times m$ matrix $A$, yielding another row vector of shape $(1, m)$:</li>
</ul>
<p>$$\vec v_{\text{row}}A \in \mathbb{R}^{1 \times m}$$</p>
<p><strong>Example:</strong></p>
<p>$$
\vec v_{\text{row}}
= [1,2,3]
\quad\text{is a }1\times3\text{ row vector in }\mathbb{R}^3.
$$</p>
<h5>Column Vector</h5>
<p>A <strong>column vector</strong> is an $n \times 1$ matrix, with elements displayed vertically:</p>
<p>$$
v =
\begin{bmatrix}
v_1\\
v_2\\
\vdots\\
v_n
\end{bmatrix}
$$</p>
<ul>
<li>It has shape $(n,1)$.</li>
<li>*Central to linear transformations; matrices act on column vectors from the left.</li>
<li>Multiplying an $m \times n$ matrix $A$ by a column vector yields another column vector of shape $(m,1)$:</li>
</ul>
<p>$$A\vec v_{\text{col}} \in \mathbb{R}^{m \times 1}$$</p>
<p><strong>Example:</strong></p>
<p>$$
v =
\begin{bmatrix}
1\\
2\\
3
\end{bmatrix}
$$</p>
<p>$$
\text{is a }3\times1\text{ column vector in }\mathbb{R}^3
$$</p>
<h4 id="transpose">Transpose</h4>
<p>The <strong>transpose</strong> operation switches between row and column orientation:</p>
<p>Denoted by a superscript ‚Äú$^T$‚Äù:</p>
<p>$$\vec v_{\text{row}}^T = \vec v_{\text{col}}$$</p>
<p>and </p>
<p>$$\vec v_{\text{col}}^T = \vec v_{\text{row}}$$</p>
<p>If $v$ is a matrix (or vector) with entries $v_{ij}$, then</p>
<p>$$v^T_{ij} = v_{ji}$$</p>
<p><strong>Why Transpose Matters:</strong></p>
<ul>
<li>Ensures dimensions match: you can only multiply a $(1,n)$ by an $(n,1)$ or an $(n,1)$ by a $(1,n)$, etc.</li>
<li>In more advanced settings (e.g., covariance matrices, orthogonal matrices), transpose plays a key role in defining symmetric and orthogonal properties.</li>
<li>Dot Product:</li>
</ul>
<p>$$\vec u \cdot \vec v = \vec u_{\text{row}}\vec v_{\text{col}} = \sum_i u_iv_i$$</p>
<p>Example of Transpose:</p>
<p>$$
v = \begin{bmatrix} 1 &amp; 2 &amp; 3 \end{bmatrix}
$$</p>
<p>$$
v^T = 
\begin{bmatrix}
1\\
2\\
3
\end{bmatrix}
$$</p>
<h4 id="norms-and-length">Norms and Length</h4>
<p>A <strong>norm</strong> $||\cdot||$ is a function that assigns a non-negative ‚Äúlength‚Äù or ‚Äúsize‚Äù to each vector in a vector space, satisfying three core properties:</p>
<p><strong>Positivity</strong>:</p>
<p>$$||\vec v|| \ge 0$$ </p>
<p>for all $\vec v$, and </p>
<p>$$||\vec v|| = 0$$ </p>
<p>if and only if $\vec v$ is the zero vector.</p>
<p><strong>Homogeneity (Scalability)</strong>:</p>
<p>$$||\alpha \vec v|| = |\alpha|||\vec v||$$ </p>
<p>for any scalar $\alpha$.</p>
<p><strong>Triangle Inequality</strong>:</p>
<p>$$||\vec u + \vec v|| \le ||\vec u|| + ||\vec v||$$ </p>
<p>for any vectors </p>
<p>$$\vec u, \vec v$$</p>
<p>The <strong>p-norm</strong> (or $L^p$ norm) is a family of norms parameterized by $p \ge 1$, defined for a vector </p>
<p>$$\vec v = (v_1, v_2, \ldots, v_n)$$ </p>
<p>as</p>
<p>$$
\lVert \vec v \rVert_p 
= \left( \sum_{i=1}^{n} \lvert v_i \rvert^p \right)^{1/p}
$$</p>
<ul>
<li>When $p=1$, this reduces to the <strong>L1 norm</strong>, the sum of absolute values.</li>
<li>When $p=2$, it gives the familiar <strong>Euclidean norm</strong>.</li>
<li>As $p \to \infty$, it approaches the maximum absolute component.</li>
</ul>
<p><strong>Why the p-Norm Matters</strong></p>
<ul>
<li>By tuning $p$, you emphasize different aspects of the data (e.g., outliers vs.\ aggregate magnitude).</li>
<li>In machine learning, different norms encourage different solution structures (e.g., sparsity with L1, smoothness with L2).</li>
<li>The shape of the ‚Äúball‚Äù ${\vec v : ||\vec v||_p \le 1}$ changes with $p$, affecting feasible regions in optimization.</li>
</ul>
<p>Common Special Cases:</p>
<p>
<table><tr><td>$p$</td><td>Name</td><td>Unit-Ball in $\mathbb{R}^2$</td><td>Geometric Intuition</td></tr><tr><td>1</td><td><strong>Manhattan</strong></td><td>Diamond (rotated square) $\diamond$</td><td>Distance measured along axes (like city blocks)</td></tr><tr><td>2</td><td><strong>Euclidean</strong></td><td>Circle $\bigcirc$</td><td>‚ÄúStraight-line‚Äù distance in the plane</td></tr><tr><td>$\infty$</td><td><strong>Chebyshev</strong></td><td>Axis-aligned square $\square$</td><td>Maximum coordinate difference (chess-king moves)</td></tr></table>
</p>
<p><em>Unit-radius sketches:</em></p>
<p><img alt="Unit balls for p=1,2,‚àû, showing diamond, circle, and square shapes" src="https://github.com/user-attachments/assets/ed74c48f-7af6-47d7-988e-5c6fae7788fd"/></p>
<p>NumPy‚Äôs <strong><code>linalg.norm</code></strong> function makes it easy:</p>
<p><div><pre><code class="language-python">import numpy as np
from numpy.linalg import norm

v = np.array([v1, v2, ..., vn])

# L1 norm: sum of absolute values
l1 = norm(v, ord=1)

# L2 norm: Euclidean length (default)
l2 = norm(v)           # same as norm(v, ord=2)

# Infinity norm: maximum absolute component
linf = norm(v, ord=np.inf)

print(f"L1: {l1}, L2: {l2}, L‚àû: {linf}")</code></pre></div></p>
<ul>
<li><strong><code>ord=1</code></strong> computes $\sum_i |v_i|$.</li>
<li><strong><code>ord=2</code></strong> (or default) computes $\sqrt{\sum_i v_i^2}$.</li>
<li><strong><code>ord=np.inf</code></strong> computes $\max_i |v_i|$.</li>
</ul>
<p>Why Norms Matter in Practice:</p>
<p><strong>Similarity and Distance</strong></p>
<p>In algorithms like <strong>k-Nearest Neighbors (k-NN)</strong>, the choice of norm directly affects which points are deemed ‚Äúclosest,‚Äù altering classification or regression results.</p>
<p><strong>Optimization and Regularization</strong></p>
<ul>
<li><strong>L1 regularization</strong> ($\ell_1$ penalty) tends to produce sparse solutions (many zero coefficients).</li>
<li><strong>L2 regularization</strong> ($\ell_2$ penalty) tends to spread error evenly among parameters, leading to smaller overall weights.</li>
</ul>
<p><strong>Feasible Regions</strong></p>
<p>When you enforce a norm constraint (e.g., $||x||_p \le 1$), the shape of that feasible set changes with $p$, influencing which solutions are accessible in constrained optimization.</p>
<h3 id="vector-operations">Vector Operations</h3>
<h4 id="vector-addition">Vector addition</h4>
<p>For $\mathbf{u},\mathbf{v}\in\mathbb{R}^n$ the sum is</p>
<p>$$
\mathbf{u}+\mathbf{v}= \bigl(u_1+v_1,u_2+v_2,\dots,u_n+v_n\bigr)
$$</p>
<ul>
<li>Commutative‚ÄÉ$\mathbf{u}+\mathbf{v}=\mathbf{v}+\mathbf{u}$</li>
<li>Associative‚ÄÉ$(\mathbf{u}+\mathbf{v})+\mathbf{w}=\mathbf{u}+(\mathbf{v}+\mathbf{w})$</li>
<li>Identity element‚ÄÉ$\mathbf{0}$ (all zeros)</li>
</ul>
<p><div><pre><code class="language-python">import numpy as np

a = np.array([9, 2, 5])
b = np.array([-3, 8, 2])

res = np.add(a, b)          # or simply a + b
print(res)                  # ‚Üí [ 6 10  7]</code></pre></div></p>
<p><strong>Complexity.</strong> $O(n)$ arithmetic operations; NumPy runs this in native C, so it is <em>vectorised</em> and avoids Python loops.</p>
<p><strong>Typical uses.</strong></p>
<ul>
<li>Merging feature vectors from multiple sensors or modalities</li>
<li>Displacement composition in kinematics</li>
<li>Gradient accumulation in machine-learning optimisers</li>
</ul>
<h4 id="scalar-outer-multiplication">Scalar (outer) multiplication</h4>
<p>Given a scalar $\alpha\in\mathbb{R}$ and $\mathbf{u}\in\mathbb{R}^n$,</p>
<p>$$
\alpha\mathbf{u}= \bigl(\alpha u_1,\alpha u_2,\dots,\alpha u_n\bigr)
$$</p>
<p>Multiplies the magnitude by $|\alpha|$; for negative $\alpha$ the direction is flipped (180¬∞ rotation).</p>
<p><div><pre><code class="language-python">v      = np.array([6, 3, 4])
alpha  = 2
scaled = alpha * v          # element-wise; same as np.multiply(alpha, v)
print(scaled)               # ‚Üí [12  6  8]</code></pre></div></p>
<p><strong>Distributive law.</strong> </p>
<p>$$\alpha(\mathbf{u}+\mathbf{v})=\alpha\mathbf{u}+\alpha\mathbf{v}$$</p>
<p>Useful for normalising vectors to unit length: <code>u / np.linalg.norm(u)</code>.</p>
<h4 id="dot-inner-product">Dot (inner) product</h4>
<p><strong>Definition.</strong></p>
<p>$$
\mathbf{u}\cdot\mathbf{v}= \sum_{i=1}^{n}u_i v_i.
$$</p>
<p><strong>Geometry.</strong></p>
<p>$$
\mathbf{u}\cdot\mathbf{v}=\lVert\mathbf{u}\rVert_2\lVert\mathbf{v}\rVert_2 \cos\theta,
$$</p>
<p>so it captures both magnitudes and their relative orientation $\theta$.</p>
<p><div><pre><code class="language-python">u  = np.array([9, 2, 5])
v  = np.array([-3, 8, 2])

dp = np.dot(u, v)           # or u @ v  in NumPy ‚â•1.10
print(dp)                   # ‚Üí -1</code></pre></div></p>
<p>An output of <strong>zero</strong> indicates <em>orthogonality</em>.</p>
<p>Negative values imply an angle greater than 90¬∞, explaining the $-1$ above (‚âà90.6¬∞).</p>
<ul>
<li>Cosine-similarity search in recommender systems</li>
<li>Work done by a force along a displacement ($W=\mathbf{F}\cdot\mathbf{s}$)</li>
<li>Projection of one vector onto another:</li>
</ul>
<p>$$\displaystyle \mathrm{proj}_{\mathbf{v}}(\mathbf{u}) = \frac{\mathbf{u}\cdot\mathbf{v}}{\lVert\mathbf{v}\rVert_2^2}\mathbf{v}$$</p>
<h4 id="cross-product">Cross product</h4>
<p>For $\mathbf{u},\mathbf{v}\in\mathbb{R}^3$,</p>
<p>$$
\mathbf{u}\times\mathbf{v} = \begin{vmatrix}
\mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k}\\
u_1 &amp; u_2 &amp; u_3\\
v_1 &amp; v_2 &amp; v_3
\end{vmatrix} =
\bigl(u_2v_3-u_3v_2,
      u_3v_1-u_1v_3,
      u_1v_2-u_2v_1\bigr).
$$</p>
<p>The resulting vector is perpendicular to the input pair; its magnitude equals the <em>area</em> of the parallelogram spanned by $\mathbf{u}$ and $\mathbf{v}$.</p>
<p><div><pre><code class="language-python">u = np.array([9, 2, 5])
v = np.array([-3, 8, 2])

c = np.cross(u, v)
print(c)                    # ‚Üí [-36 -33  78]</code></pre></div></p>
<p>Use the right-hand rule to fix the orientation: curling your fingers from <strong>u</strong> to <strong>v</strong>, your thumb points along <strong>u √ó v</strong>.</p>
<ul>
<li>Surface normals in graphics shaders (lighting)</li>
<li>Torque $\boldsymbol{\tau} = \mathbf{r}\times\mathbf{F}$</li>
<li>Angular momentum  $\mathbf{L} = \mathbf{r}\times m\mathbf{v}$</li>
</ul>
<h4 id="angle-between-two-vectors">Angle between two vectors</h4>
<p>From the dot-product identity above:</p>
<p>$$
\theta = \arccos!\Bigl(\frac{\mathbf{u}\cdot\mathbf{v}}
                              {\lVert\mathbf{u}\rVert_2\lVert\mathbf{v}\rVert_2}\Bigr)
\qquad
0\le\theta\le\pi
$$</p>
<p><div><pre><code class="language-python">u = np.array([9, 2, 5])
v = np.array([-3, 8, 2])

cosŒ∏  = np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))
cosŒ∏  = np.clip(cosŒ∏, -1.0, 1.0)   # guards against tiny FP overshoots
Œ∏_rad = np.arccos(cosŒ∏)
Œ∏_deg = np.degrees(Œ∏_rad)

print(Œ∏_rad)   # ‚Üí 1.5817 rad
print(Œ∏_deg)   # ‚Üí 90.62 ¬∞</code></pre></div></p>
<p><strong>Edge cases to watch.</strong></p>
<ul>
<li>If either vector is the zero vector, the angle is undefined (division-by-zero).</li>
<li>Numerical rounding can nudge the cosine slightly outside $[-1,1]$; <code>np.clip</code> prevents <code>nan</code>.</li>
</ul>
<h3 id="broadcasting">Broadcasting</h3>
<h4 id="what-broadcasting-means-formally">What broadcasting means‚Äîformally</h4>
<p>For any binary <strong>ufunc</strong> $f$ (e.g., <code>+</code>, <code>*</code>, <code>np.maximum</code>), NumPy will try to apply</p>
<p>$$
C = f(A, B)
$$</p>
<p>element-wise <strong>if and only if</strong> the two input shapes are <em>broadcast-compatible</em>.  Compatibility is checked <strong>right-to-left</strong> over the axes:</p>
<p><strong>Equal length rule.</strong></p>
<p>Pad the shorter shape on the left with 1‚Äôs so both shapes have the same rank.</p>
<p><strong>Axis match rule.</strong></p>
<p>For every axis $k$ from the <em>last</em> to the <em>first</em></p>
<ul>
<li>either $A_k = B_k$, or</li>
<li>one of them equals 1 (that axis will be <em>stretched</em>).</li>
</ul>
<p>When axis $k$ is stretched, NumPy does <strong>not</strong> copy data; it creates a <em>strided view</em> that repeats the existing bytes in memory‚Äîso the cost is $O(1)$ extra space.</p>
<blockquote>
<p><strong>Tip.</strong> Think of a dimension of length 1 as a <em>wildcard</em> that can masquerade as any size.</p>
</blockquote>
<h4 id="scalar-broadcasting">Scalar broadcasting</h4>
<p><div><pre><code class="language-python">import numpy as np

arr    = np.array([1, 2, 3, 4])   # shape (4,)
alpha  = 2                        # shape () ‚Äî rank-0

print("arr + alpha:", arr + alpha)   # [3 4 5 6]
print("arr * alpha:", arr * alpha)   # [2 4 6 8]</code></pre></div></p>
<p><em>The scalar behaves like an invisible array of shape <code>(4,)</code> here.</em></p>
<p>Common uses:</p>
<ul>
<li><strong>Feature scaling / centering:</strong> <code>X -= X.mean(axis=0)</code> subtracts the <em>row-vector</em> of feature means from every sample at once.</li>
<li><strong>Softmax trick:</strong> <code>logits - logits.max(axis=1, keepdims=True)</code> prevents overflow by broadcasting a column vector of maxima.</li>
</ul>
<h4 id="vector-matrix-examples">Vector‚Äìmatrix examples</h4>
<p><div><pre><code class="language-python">M = np.arange(12).reshape(3, 4)      # shape (3,4)
col = np.array([10, 20, 30])[:,None] # shape (3,1)
row = np.array([1, 2, 3, 4])         # shape (4,)

print("M + col  ‚Üí\n", M + col)   # each row shifted by its col entry
print("M + row  ‚Üí\n", M + row)   # each column shifted by row entry</code></pre></div></p>
<p>Shape algebra (after left-padding):</p>
<p>
<table><tr><td>Operand</td><td>Raw shape</td><td>Padded to (3, 4)</td><td>Compatible?</td></tr><tr><td><code>M</code></td><td>(3, 4)</td><td>(3, 4)</td><td>‚Äî</td></tr><tr><td><code>col</code></td><td>(3, 1)</td><td>(3, 1)</td><td>‚úì (second axis 1)</td></tr><tr><td><code>row</code></td><td>(4,)</td><td>(1, 4)</td><td>‚úì (first axis 1)</td></tr></table>
</p>
<p>The result is shape <code>(3, 4)</code> in both cases‚Äîno materialised tile of <code>col</code> or <code>row</code>.</p>
<h4 id="when-broadcasting-fails">When broadcasting fails</h4>
<p><div><pre><code class="language-python">a = np.empty((5, 4))
b = np.empty((3, 1, 4))

# a + b  -&gt; ValueError: operands could not be broadcast together ...</code></pre></div></p>
<p>Reason: after padding, shapes are <code>(1,5,4)</code> and <code>(3,1,4)</code>; axis 0 demands 1 vs 3 (neither is 1), so rule 2 fails.</p>
<h4 id="performance-notes">Performance notes</h4>
<ul>
<li><strong>Aliasing hazards.</strong> <code>out[:] += x</code> is safe; <code>out = out + x</code> makes a <em>new</em> array instead of updating in-place.</li>
<li><strong>Cache friendliness.</strong> Broadcasting keeps the contiguous memory layout of the larger operand; explicit <code>np.tile</code> often degrades performance <strong>and</strong> uses $O(nm)$ extra RAM.</li>
<li><strong>Higher-order views.</strong> Use <code>np.expand_dims</code> or <code>None</code> (<code>[:, None]</code>) to add axes consciously and avoid accidental shape mismatches.</li>
</ul>
<h3 id="practical-applications">Practical Applications</h3>
<p>Vectors and their operations are integral to numerous practical applications across various domains. Mastering these concepts enables efficient data manipulation, analysis, and the implementation of complex algorithms.</p>
<h4 id="accessing-and-modifying-multiple-elements">Accessing and Modifying Multiple Elements</h4>
<p>Beyond single-element access, vectors allow for the manipulation of multiple elements simultaneously using slicing or advanced indexing. This capability is essential for batch processing and data transformation tasks.</p>
<p><div><pre><code class="language-python"># Creating a 1D array
arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])

# Modifying multiple elements
arr[2:5] = [10, 11, 12]
print(arr)</code></pre></div></p>
<p>Expected output:</p>
<p><div><pre><code class="language-shell">[ 1  2 10 11 12  6  7  8]</code></pre></div></p>
<ul>
<li><code>arr[2:5] = [10, 11, 12]</code> assigns the values <code>10</code>, <code>11</code>, and <code>12</code> to the elements at indices <code>2</code>, <code>3</code>, and <code>4</code>, respectively.</li>
<li>The original array <code>[1, 2, 3, 4, 5, 6, 7, 8]</code> is updated to <code>[1, 2, 10, 11, 12, 6, 7, 8]</code>.</li>
<li>Batch updating is useful in data cleaning processes where multiple data points need correction or transformation, such as replacing outliers or applying scaling factors to specific sections of a dataset.</li>
</ul>
<h4 id="boolean-indexing">Boolean Indexing</h4>
<p>Boolean indexing enables the selection of elements based on conditional statements, allowing for dynamic and flexible data selection without the need for explicit loops. This technique is highly efficient and widely used in data analysis.</p>
<p><div><pre><code class="language-python"># Creating a 1D array
arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])
# Boolean indexing
bool_idx = arr &gt; 5
print(arr[bool_idx])</code></pre></div></p>
<p>Expected output:</p>
<p><div><pre><code class="language-shell">[6 7 8]</code></pre></div></p>
<ul>
<li><code>arr &gt; 5</code> creates a boolean array <code>[False, False, False, False, False, True, True, True]</code>.</li>
<li><code>arr[bool_idx]</code> uses this boolean array to filter and retrieve elements where the condition <code>arr &gt; 5</code> is <code>True</code>, resulting in <code>[6, 7, 8]</code>.</li>
<li>Boolean indexing is used to filter datasets based on specific criteria, such as selecting all records where a sales figure exceeds a certain threshold or extracting all entries that meet particular quality standards.</li>
</ul>
<h3 id="summary-table">Summary Table</h3>
<p>All examples are <em>self-contained</em>‚Äîeach row declares the minimal variables it needs‚Äîso you can copy-paste any cell directly into any IDE.</p>
<p>
<table><tr><td>Operation</td><td>Description &amp; Formula</td><td>Example Code</td><td>Expected Output (shape)</td></tr><tr><td><strong>Vector Addition</strong></td><td>Element-wise sum<br/>‚ÄÉ$c_i = a_i + b_i$</td><td><code>arr_1 = np.array([9, 2, 5])</code><br/><code>arr_2 = np.array([-3, 8, 2])</code><br/><code>np.add(arr_1, arr_2)</code></td><td><code>[ 6 10  7]‚ÄÇ(3,)</code></td></tr><tr><td><strong>Scalar Multiplication</strong></td><td>Scale a vector<br/>‚ÄÉ$c_i = k a_i$</td><td><code>scalar = 2</code><br/><code>arr = np.array([6, 3, 4])</code><br/><code>scalar * arr</code></td><td><code>[12  6  8]‚ÄÇ(3,)</code></td></tr><tr><td><strong>Dot Product</strong></td><td>Projection / cosine similarity<br/>‚ÄÉ$a \cdot b = \sum_i a_i b_i$</td><td><code>arr_1 = np.array([9, 2, 5])</code><br/><code>arr_2 = np.array([-3, 8, 2])</code><br/><code>np.dot(arr_1, arr_2)</code></td><td><code>-1‚ÄÇ()</code></td></tr><tr><td><strong>Cross Product</strong></td><td>3-D vector orthogonal to both inputs<br/>‚ÄÉ$a \times b$</td><td><code>arr_1 = np.array([9, 2, 5])</code><br/><code>arr_2 = np.array([-3, 8, 2])</code><br/><code>np.cross(arr_1, arr_2)</code></td><td><code>[-36 -33  78]‚ÄÇ(3,)</code></td></tr><tr><td><strong>Angle Between Vectors</strong></td><td>$\theta = \arccos!\left(\frac{a\cdot b}{\lVert a\rVert\,\lVert b\rVert}\right)$</td><td><code>arr_1 = np.array([9, 2, 5])</code><br/><code>arr_2 = np.array([-3, 8, 2])</code><br/><code>angle = np.arccos(np.dot(arr_1, arr_2) / (np.linalg.norm(arr_1)*np.linalg.norm(arr_2)))</code><br/><code>np.round(angle, 3)</code></td><td><code>1.582 rad</code></td></tr><tr><td><strong>Broadcasting</strong></td><td>NumPy automatically ‚Äústretches‚Äù smaller shapes so element-wise ops make sense.<br/><em>(vector ‚áÑ scalar shown here)</em></td><td><code>arr = np.array([1, 2, 3, 4])</code><br/><code>scalar = 2</code><br/><code>arr + scalar, arr * scalar</code></td><td><code>([3 4 5 6], [2 4 6 8])</code></td></tr></table>
</p>
<p>Tiny Performance Tips:</p>
<ul>
<li><strong>Vectorized &gt; loops</strong> ‚Äì every row above is a single, optimized C call.</li>
<li><strong><code>np.dot</code> &amp; BLAS</strong> ‚Äì use contiguous <code>float64</code> arrays for best throughput.</li>
<li><strong>Broadcast with care</strong> ‚Äì repeated implicit copies are <em>virtual</em>, but an unexpected <code>np.copy()</code> downstream can explode memory; check <code>arr.strides</code>.</li>
</ul>
</article-section><div id="table-of-contents"><h2>Table of Contents</h2><ol><a href="#vectors">Vectors</a><ol><li><a href="#definitions">Definitions</a></li><li><a href="#vector-in-mathbb-r-n-">Vector in $\mathbb{R}^n$</a><ol><li><a href="#row-vs-column-representation">Row vs Column Representation</a></li><li><a href="#transpose">Transpose</a></li><li><a href="#norms-and-length">Norms and Length</a></li></ol></li><li><a href="#vector-operations">Vector Operations</a><ol><li><a href="#vector-addition">Vector addition</a></li><li><a href="#scalar-outer-multiplication">Scalar (outer) multiplication</a></li><li><a href="#dot-inner-product">Dot (inner) product</a></li><li><a href="#cross-product">Cross product</a></li><li><a href="#angle-between-two-vectors">Angle between two vectors</a></li></ol></li><li><a href="#broadcasting">Broadcasting</a><ol><li><a href="#what-broadcasting-means-formally">What broadcasting means‚Äîformally</a></li><li><a href="#scalar-broadcasting">Scalar broadcasting</a></li><li><a href="#vector-matrix-examples">Vector‚Äìmatrix examples</a></li><li><a href="#when-broadcasting-fails">When broadcasting fails</a></li><li><a href="#performance-notes">Performance notes</a></li></ol></li><li><a href="#practical-applications">Practical Applications</a><ol><li><a href="#accessing-and-modifying-multiple-elements">Accessing and Modifying Multiple Elements</a></li><li><a href="#boolean-indexing">Boolean Indexing</a></li></ol></li><li><a href="#summary-table">Summary Table</a></li></ol></ol><div id="related-articles"><h2>Related Articles</h2><ol><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/1_creating_arrays.html">Creating Arrays</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/2_accessing_modifying_elements.html">Accessing Modifying Elements</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/3_vector_operations.html">Vector Operations</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/4_matrix_operations.html">Matrix Operations</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/5_reshaping_arrays.html">Reshaping Arrays</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/6_searching_filtering_and_sorting.html">Searching Filtering and Sorting</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/7_combining_arrays.html">Combining Arrays</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/8_linear_equations.html">Linear Equations</a></li><li><a href="https://adamdjellouli.com/articles/numpy_tutorials/9_statistics_and_random_numbers.html">Statistics and Random Numbers</a></li></ol></div></div></div><footer>
<div class="footer-columns">
<div class="footer-column">
<img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png"/>
</div>
<div class="footer-column">
<h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
<p>Thank you for visiting my personal website. All content here is free to use, but please remember to be respectful and avoid any misuse of the site. If you‚Äôd like to get in touch, feel free to reach out via my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or connect with me on <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have technical questions or ideas to share. Wishing you all the best and a fantastic life ahead!</p>
</div>
<div class="footer-column">
<h2>Follow me</h2>
<ul class="social-media">
<li>
<a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
</a>YouTube
                </li>
<li>
<a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
</a>LinkedIn
                </li>
<li>
<a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
</a>Instagram
                </li>
<li>
<a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
</a>Github
                </li>
</ul>
</div>
</div>
<div>
<p id="copyright">
            ¬© Adam Djellouli. All rights reserved.
        </p>
</div>
<script>
        document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
    </script>
<script src="../../app.js"></script>
</footer></body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script></html>