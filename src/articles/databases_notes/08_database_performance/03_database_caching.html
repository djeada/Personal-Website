<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Database Caching</title>
    <meta content="Database caching is a powerful performance optimization technique that involves temporarily storing frequently accessed data in a cache for quick retrieval." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: May 18, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: 🇺🇸</i></p>
            <h2 id="database-caching">Database Caching</h2>
            <p>Database caching is a powerful performance optimization technique that involves temporarily storing frequently accessed data in a cache for quick retrieval. By keeping commonly requested information readily available, caching reduces the time it takes to access data and lessens the load on the database server. This can significantly enhance the responsiveness and scalability of applications, leading to a better user experience.</p>
            <p>After reading the material, you should be able to answer the following questions:</p>
            <ol>
                <li>What is database caching, and how does it improve the performance and scalability of applications?</li>
                <li>What are the different types of caching strategies, such as in-memory caching, client-side caching, and server-side caching, and when is each type most effectively used?</li>
                <li>How do techniques like query result caching, object caching, database buffer caching, and prepared statement caching enhance database performance? Provide examples for each.</li>
                <li>What are the primary cache invalidation strategies, including Time-to-Live (TTL), event-based invalidation, and manual invalidation, and how do they help maintain data consistency between the cache and the underlying database?</li>
                <li>What are the best practices for implementing database caching, such as selecting which data to cache, setting appropriate TTL values, monitoring cache performance, and ensuring the security of cached data?</li>
            </ol>
            <h3 id="understanding-database-caching">Understanding Database Caching</h3>
            <p>At its core, caching works by storing copies of data in a location that can be accessed more quickly than the original source. In the context of databases, this often means keeping data in memory rather than retrieving it from disk storage each time it is needed. By doing so, applications can serve data faster and handle more concurrent users without overloading the database server.</p>
            <h4 id="how-caching-improves-performance">How Caching Improves Performance</h4>
            <p>To visualize how caching fits into an application architecture, consider the following diagram:</p>
            <p>
            <div>
                <pre><code class="language-shell">#
       +-------------------+
       |    Client App     |
       +---------+---------+
                 |
           Data Request
                 |
                 v
       +---------+---------+
       |        Cache      |
       +---------+---------+
                 |
        Is Data in Cache?
            /        \
          Yes         No
           |           |
    Serve Data      Query Database
     from Cache          |
           |             v
           +-------Update Cache
                         |
                         v
                 Return Data to Client</code></pre>
            </div>
            </p>
            <ul>
                <li>The client application requests data.</li>
                <li>The cache checks if it contains the requested data.</li>
                <li>If the data is found (cache hit), it is served directly from the cache to the client.</li>
                <li>If the data is not found (cache miss), the application queries the database, updates the cache with the new data, and then serves it to the client.</li>
            </ul>
            <p>By serving data from the cache whenever possible, the application reduces the number of direct queries to the database, improving overall performance.</p>
            <h3 id="types-of-caching-strategies">Types of Caching Strategies</h3>
            <p>There are several caching strategies that can be employed, each suited to different scenarios and requirements.</p>
            <h4 id="in-memory-caching">In-Memory Caching</h4>
            <p>In-memory caching stores data in the system's RAM, providing the fastest possible data retrieval. Tools like Redis and Memcached are popular choices for implementing in-memory caches. They allow applications to store key-value pairs, lists, hashes, and other data structures in memory for quick access.</p>
            <h4 id="client-side-caching">Client-Side Caching</h4>
            <p>Client-side caching involves storing data on the client's device, such as in a web browser's cache or local storage. This is particularly useful for static resources like images, stylesheets, and scripts. By caching data on the client side, applications can reduce server load and improve load times. However, this approach has limitations, including limited storage capacity and potential security concerns when storing sensitive data on the client's device.</p>
            <h4 id="server-side-caching">Server-Side Caching</h4>
            <p>Server-side caching stores data on the server, closer to the application logic and database. This approach is effective for dynamic content and API responses that may be expensive to generate. By caching these responses, the server can quickly serve subsequent requests without recomputing the data. Challenges with server-side caching include the need for additional infrastructure and ensuring cache synchronization in distributed systems.</p>
            <h3 id="implementing-database-caching-techniques">Implementing Database Caching Techniques</h3>
            <p>There are various techniques for implementing caching in database applications, each with its own advantages and use cases.</p>
            <h4 id="query-result-caching">Query Result Caching</h4>
            <p>Query result caching involves storing the results of frequently executed database queries. When the same query is requested again, the application retrieves the result from the cache instead of executing the query against the database. This reduces CPU and I/O usage on the database server and speeds up application response times.</p>
            <p>
            <div>
                <pre><code class="language-shell">#
                                 ┌──────────────────┐
                                 │  Client Request  │
                                 └────────┬─────────┘
                                          │
                                          ▼
                                  ┌────────────────┐
                                  │ Check Redis    │
                                  │  (cache_key)   │
                                  └───┬───────────┘
                HIT? Yes ───────────│─────────┐ No
                                  │         ▼
          ┌───────────┐         ┌───────┐  ┌────────────────────┐
          │ Return    │◀────────│Redis  │  │ Query Database     │
          │ Cached    │         │Hit!   │  │ (SELECT * FROM ...)│
          └───────────┘         └───────┘  └─────────┬──────────┘
                                                     │
                                                     ▼
                                              ┌────────────┐
                                              │ Store in   │
                                              │ Redis      │
                                              │ (ex=3600s) │
                                              └────┬───────┘
                                                   │
                                                   ▼
                                             ┌───────────┐
                                             │ Return    │
                                             │ DB Result │
                                             └───────────┘</code></pre>
            </div>
            </p>
            <p><strong>Example in Python using Flask and Redis:</strong></p>
            <p>
            <div>
                <pre><code class="language-python">from flask import Flask, jsonify
import redis
import sqlite3
import json

app = Flask(__name__)
cache = redis.Redis(host='localhost', port=6379, db=0)

def get_db_connection():
    conn = sqlite3.connect('database.db')
    return conn

@app.route('/products')
def get_products():
    cache_key = 'product_list'
    cached_data = cache.get(cache_key)

    if cached_data:
        products = json.loads(cached_data)
        source = 'cache'
    else:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM products')
        products = cursor.fetchall()
        conn.close()
        cache.set(cache_key, json.dumps(products), ex=3600)  # Cache data for 1 hour
        source = 'database'

    return jsonify({'source': source, 'products': products})</code></pre>
            </div>
            </p>
            <ul>
                <li>The application attempts to retrieve the list of products from the cache using a unique cache key.</li>
                <li>If the data is not in the cache (cache miss), it queries the database, stores the result in the cache, and then serves the data.</li>
                <li>If the data is in the cache (cache hit), it serves the data directly from the cache, reducing database load.</li>
            </ul>
            <h4 id="object-caching">Object Caching</h4>
            <p>Object caching involves storing entire objects or data structures in the cache rather than just raw query results. This is especially useful in object-oriented applications where the same data object is used frequently.</p>
            <p>
            <div>
                <pre><code class="language-shell">#
      ┌────────────────────┐
      │ getUserById(123)   │
      └───────┬────────────┘
              │
              ▼
       ┌───────────────┐
       │ userCache.get │
       │ (key = 123)   │
       └───────┬───────┘
 HIT? Yes ─────┤      No ──────────────────────┐
              │                                │
              ▼                                ▼
       ┌─────────────┐                   ┌──────────────────┐
       │ Return      │                   │ Fetch from       │
       │ Cached User │                   │ Database         │
       └─────────────┘                   └────────┬─────────┘
                                                 │
                                                 ▼
                                         ┌──────────────────────┐
                                         │ userCache.put(123,   │
                                         │   &lt;user object=""&gt;)     │
                                         └────────┬─────────────┘
                                                  │
                                                  ▼
                                           ┌─────────────┐
                                           │ Return User │
                                           └─────────────┘</code></pre>
            </div>
            </p>
            <p><strong>Example in Java using Ehcache:</strong></p>
            <p>
            <div>
                <pre><code class="language-java">import net.sf.ehcache.Cache;
import net.sf.ehcache.CacheManager;
import net.sf.ehcache.Element;

public class UserService {
    private CacheManager cacheManager;
    private Cache userCache;

    public UserService() {
        cacheManager = CacheManager.getInstance();
        userCache = cacheManager.getCache("userCache");
    }

    public User getUserById(int userId) {
        Element element = userCache.get(userId);

        if (element != null) {
            return (User) element.getObjectValue();
        } else {
            User user = database.getUserById(userId);
            userCache.put(new Element(userId, user));
            return user;
        }
    }
}</code></pre>
            </div>
            </p>
            <ul>
                <li>The <code>getUserById</code> method first checks if the user object is in the cache.</li>
                <li>If the user is not cached, it retrieves the user from the database, caches the object, and then returns it.</li>
                <li>This reduces the need to query the database for the same user multiple times.</li>
            </ul>
            <h4 id="database-buffer-caching">Database Buffer Caching</h4>
            <p>Databases themselves often implement caching mechanisms to improve performance. Adjusting database configurations can enhance this caching.</p>
            <p>
            <div>
                <pre><code class="language-shell">┌──────────────────────┐
│ PostgreSQL Server    │
└──────────┬───────────┘
           │ shared_buffers
           │  = 256MB
           │
           ▼
┌────────────────────────────┐
│ In‐Memory Buffer Cache     │
│ ┌────────────────────────┐ │
│ │ Data Pages             │ │
│ └────────────────────────┘ │
└──────────┬─────────────────┘
           │
           ▼
┌────────────────────────────┐
│ Disk I/O Reduced           │
│ Faster Query Responses     │
└────────────────────────────┘</code></pre>
            </div>
            </p>
            <p><strong>Configuring buffer cache in PostgreSQL:</strong></p>
            <p>In the <code>postgresql.conf</code> file:</p>
            <p>
            <div>
                <pre><code class="language-shell"># Adjust shared_buffers to increase memory allocated for caching data pages
shared_buffers = 256MB</code></pre>
            </div>
            </p>
            <p>By increasing the <code>shared_buffers</code> setting, PostgreSQL allocates more memory for caching data, which can reduce disk I/O operations and improve query performance.</p>
            <h4 id="prepared-statement-caching">Prepared Statement Caching</h4>
            <p>Caching prepared statements can reduce the overhead of parsing and planning SQL queries, especially for queries that are executed frequently with different parameters.</p>
            <p>
            <div>
                <pre><code class="language-shell">┌───────────────────────────┐
│ PREPARE get_users_by_age  │
│   (INT) AS                │
│ SELECT * FROM users       │
│ WHERE age &gt; $1;           │
└────────────┬──────────────┘
             │
             │   Subsequent EXECUTE calls:
             ▼
┌───────────────────┐      ┌───────────────────┐
│ EXECUTE           │      │ EXECUTE           │
│ get_users_by_age  │      │ get_users_by_age  │
│ (30)              │      │ (40)              │
└──────────┬────────┘      └───────────┬───────┘
           │                           │
           ▼                           ▼
 ┌─────────────────┐         ┌─────────────────┐
 │ Planner &amp; Exec  │         │ Planner &amp; Exec  │
 │ (no re‐parse!)  │         │ (no re‐parse!)  │
 └─────────────────┘         └─────────────────┘</code></pre>
            </div>
            </p>
            <p><strong>Example in PostgreSQL:</strong></p>
            <p>
            <div>
                <pre><code class="language-sql">-- Prepare a statement with a parameter placeholder
PREPARE get_users_by_age(INT) AS
SELECT * FROM users WHERE age &gt; $1;

-- Execute the prepared statement with a specific parameter
EXECUTE get_users_by_age(30);</code></pre>
            </div>
            </p>
            <p>By preparing the statement once, subsequent executions with different parameters can be performed without re-parsing, which improves performance.</p>
            <h3 id="cache-invalidation-strategies">Cache Invalidation Strategies</h3>
            <p>Keeping your cache coherent with the source of truth (the database) is one of the hardest problems in computer science. Below are three classic strategies, each with an ASCII diagram that shows <strong>who</strong> triggers the change and <strong>when</strong> the cached value is refreshed.</p>
            <h4 id="time-to-live-ttl-">Time-to-Live (TTL)</h4>
            <ol>
                <li><strong>Write</strong> – when data is first fetched from the DB, it is inserted into the cache with a fixed expiration time.</li>
                <li><strong>Serve-from-cache</strong> – until that timer “pops,” every read is a fast cache hit.</li>
                <li><strong>Expire &amp; Refresh</strong> – after the TTL elapses, the next read is a miss, so the application reloads the data from the DB and starts a fresh timer.</li>
            </ol>
            <p>
            <div>
                <pre><code class="language-shell">Time ─────────────────────────────────────────────────────────►

 Client  ─►  Cache (HIT)   Cache (HIT)   Cache ✖ (MISS)   Cache (HIT)
                 │             │               │               │
                 │   TTL ticking down…         │               │
                 └───────────────&lt;  TTL  &gt;─────┘               │
                                         fetch ► DB ──► update │</code></pre>
            </div>
            </p>
            <p><strong>Pros</strong></p>
            <ul>
                <li>Simple “set-and-forget”; no need to listen for update events.</li>
                <li>Works even if the application has no write access to the cache layer (e.g., CDN).</li>
            </ul>
            <p><strong>Cons</strong></p>
            <ul>
                <li>Freshness is probabilistic: the <em>worst-case</em> staleness equals the TTL value.</li>
                <li>Choosing the right TTL is tricky—too long gives stale data, too short kills performance.</li>
            </ul>
            <p><strong>Redis snippet</strong></p>
            <p>
            <div>
                <pre><code class="language-python">cache.set('user_123', user_data, ex=3600)  # expires in 1 h</code></pre>
            </div>
            </p>
            <h4 id="event-based-invalidation">Event-Based Invalidation</h4>
            <p>Every mutating operation (INSERT/UPDATE/DELETE) triggers a cache purge for the affected keys:</p>
            <p>
            <div>
                <pre><code class="language-shell">#
            ┌─────────────────────────────┐
            │     UPDATE/INSERT/DELETE    │
            └──────────────┬──────────────┘
                           │ 1.  write to DB
                           ▼
┌───────────┐   2. delete(key)    ┌───────────┐
│   Cache   │◄────────────────────│  App/API  │
└───────────┘                     └───────────┘
       ▲                              │
       │ 3. next read = MISS          │
       └───────────────◄──────────────┘
                           fetch fresh row ► DB</code></pre>
            </div>
            </p>
            <p><strong>Pros</strong></p>
            <ul>
                <li>Near-real-time consistency—staleness is only the network/processing delay after a write.</li>
                <li>No guesswork about TTL values.</li>
            </ul>
            <p><strong>Cons</strong></p>
            <ul>
                <li>You must <strong>own every write path</strong>; a forgotten code path means stale data.</li>
                <li>Extra complexity: publish/subscribe channels or message queues are common to broadcast events reliably.</li>
            </ul>
            <p>
            <div>
                <pre><code class="language-python">def update_user(user_id, new_data):
    database.update_user(user_id, new_data)    # 1️⃣
    cache.delete(f'user_{user_id}')            # 2️⃣</code></pre>
            </div>
            </p>
            <h4 id="manual-invalidation">Manual Invalidation</h4>
            <p>A human (or a one-off script) explicitly removes or refreshes cache entries when they know data changed unexpectedly—e.g., after a hotfix directly in the DB.</p>
            <p>
            <div>
                <pre><code class="language-shell">Administrator / Script
        │  invalidate(key)
        ▼
┌────────────┐
│   Cache    │─────────► subsequent read = MISS → DB
└────────────┘</code></pre>
            </div>
            </p>
            <p><strong>Pros</strong></p>
            <ul>
                <li>Absolute control—great for emergency fixes, migrations, or ad-hoc cleanup.</li>
                <li>Zero code overhead if you already have a cache CLI.</li>
            </ul>
            <p><strong>Cons</strong></p>
            <ul>
                <li>Easy to forget: relies on tribal knowledge and discipline.</li>
                <li>Does not scale for high-write or multi-service architectures.</li>
            </ul>
            <h3 id="choosing-a-strategy">Choosing a Strategy</h3>
            <p>
            <table>
                <tr>
                    <td>Scenario</td>
                    <td>Recommended Approach</td>
                </tr>
                <tr>
                    <td>Read-heavy, infrequent writes</td>
                    <td><strong>TTL</strong> with a moderate timeout</td>
                </tr>
                <tr>
                    <td>Latency-sensitive &amp; write-intensive</td>
                    <td><strong>Event-based</strong> (often + short TTL)</td>
                </tr>
                <tr>
                    <td>One-off data repair or migration</td>
                    <td><strong>Manual</strong></td>
                </tr>
            </table>
            </p>
            <blockquote>
                <p><strong>Hybrid in practice</strong> – Many production systems blend these techniques:
                    <em>short TTL</em> as a safety net <strong>+</strong> <em>event-based</em> purging for critical objects. This “belt-and-suspenders” model keeps data fresh while guarding against missed events.
                </p>
            </blockquote>
            <h3 id="best-practices">Best Practices</h3>
            <p>Below is a “hands-on” playbook that teams actually use when they roll out a cache in front of a relational or NoSQL store. Feel free to cherry-pick the bits that fit your stack—everything is numbered so you can treat it like a checklist.</p>
            <h4 id="pinpoint-the-hot-data-don-t-guess-">Pinpoint the “hot” data (don’t guess)</h4>
            <p>
            <table>
                <tr>
                    <td>Signal</td>
                    <td>How to Capture It (examples)</td>
                    <td>What You Learn</td>
                </tr>
                <tr>
                    <td><strong>Query frequency</strong></td>
                    <td><em>PostgreSQL:</em><br /><code>sql&lt;br/&gt;SELECT query, calls, total_exec_time/1000 AS seconds&lt;br/&gt;FROM pg_stat_statements&lt;br/&gt;ORDER BY calls DESC LIMIT 25;&lt;br/&gt;</code> <br /><em>MySQL 8+</em> <code>sql&lt;br/&gt;SELECT DIGEST_TEXT, COUNT_STAR AS calls&lt;br/&gt;FROM performance_schema.events_statements_summary_by_digest&lt;br/&gt;ORDER BY calls DESC LIMIT 25;&lt;br/&gt;</code></td>
                    <td>Which exact SQL statements hammer the DB.</td>
                </tr>
                <tr>
                    <td><strong>Row/block reads</strong></td>
                    <td>Cloud watch, Azure Monitor, or <code>pg_stat_io</code>, <code>INNODB_METRICS</code></td>
                    <td>Whether repeated reads are on the same few tables or indexes.</td>
                </tr>
                <tr>
                    <td><strong>Application traces</strong></td>
                    <td>App-side APM (OpenTelemetry/SkyWalking/New Relic/DataDog). Filter spans by <strong>percentage of total wall-clock time</strong> rather than pure count.</td>
                    <td>Pinpoints functions / endpoints dominating user latency.</td>
                </tr>
                <tr>
                    <td><strong>Object popularity</strong></td>
                    <td>Log or stream every <strong>cache miss</strong> for a day into BigQuery/Redshift, run a <code>GROUP BY key_id ORDER BY cnt DESC</code>.</td>
                    <td>Even after you add a cache, this tells you if the pattern changed.</td>
                </tr>
            </table>
            </p>
            <blockquote>
                <p><strong>Rule of thumb:</strong> If a query or endpoint accounts for <strong>&gt;3 % of total DB CPU time</strong> or <strong>&gt;100 QPS</strong>, it’s a cache candidate.</p>
            </blockquote>
            <h4 id="segregate-reads-into-buckets-before-you-cache">Segregate “reads” into buckets before you cache</h4>
            <p>
            <table>
                <tr>
                    <td>Bucket</td>
                    <td>Example pattern</td>
                    <td>Caching tactic</td>
                </tr>
                <tr>
                    <td><strong>Immutable</strong> for hours/days</td>
                    <td>Product catalog, static config JSON</td>
                    <td>Set TTL equal to typical update interval. No invalidation headaches.</td>
                </tr>
                <tr>
                    <td><strong>Frequently read, occasionally updated</strong></td>
                    <td>User profile, shopping-cart totals</td>
                    <td><em>Write-through</em> cache + key version (<code>user:123:v5</code>). Bump version on update to guarantee freshness.</td>
                </tr>
                <tr>
                    <td><strong>Write-heavy</strong></td>
                    <td>Orders, ledger balances</td>
                    <td>Usually <strong>don’t</strong> cache. If you must, use <em>read-through with short (≤5 s) TTL</em> and <em>striped locks</em> on cache miss.</td>
                </tr>
                <tr>
                    <td><strong>Fan-out read</strong> (feeds, timelines)</td>
                    <td>Top-N posts, leaderboard</td>
                    <td>Cache the <strong>list</strong> separately from the <strong>objects</strong>. Invalidate the list on write; objects use a longer TTL.</td>
                </tr>
            </table>
            </p>
            <h4 id="decide-ttls-with-data-not-folklore">Decide TTLs with data—not folklore</h4>
            <p>I. <strong>Pull update intervals</strong>: For each key type, compute the 95ᵗʰ percentile of “time between writes.”</p>
            <p><em>Example Postgres:</em></p>
            <p>
            <div>
                <pre><code class="language-sql">WITH history AS (
SELECT user_id, lag(updated_at) OVER (PARTITION BY user_id ORDER BY updated_at) AS prev
FROM user_profile_changes
)
SELECT percentile_cont(0.95) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM (updated_at-prev)))
FROM history WHERE prev IS NOT NULL;</code></pre>
            </div>
            </p>
            <p>II. <strong>Pick TTL ≈ 50 – 80 % of that 95ᵗʰ percentile</strong>. </p>
            <p>This maximizes hit rate while guaranteeing ≤5 % stale probability.</p>
            <p>III. <strong>Review TTLs monthly</strong>—product changes often shorten or lengthen update cycles.</p>
            <blockquote>
                <p><strong>Advanced:</strong> Add <em>stale-while-revalidate</em> (serve stale for ≤X s while a background task refreshes). Redis 7’s <code>CLIENT TRACKING</code> with <code>BCAST</code> or a CDN’s <code>stale-while-revalidate</code> header make this easy.</p>
            </blockquote>
            <h4 id="wire-it-up-language-agnostic-pseudocode-">Wire it up (language-agnostic pseudocode)</h4>
            <p>
            <div>
                <pre><code class="language-python">cache = Redis(..., client_tracking=True)   # enables auto-invalidation messages
db    = PostgreSQL(...)

def get_user(user_id):
    version = db.fetch_value(
        "SELECT cache_version FROM user WHERE id = %s", [user_id]
    )
    key = f"user:{user_id}:v{version}"
    
    if (data := cache.get(key)) is not None:
        metrics.hit.inc()
        return deserialise(data)
    
    # Miss: lock per-key to avoid stampede
    with cache.lock(f"lock:{key}", timeout=3):
        if (data := cache.get(key)) is not None:  # double-check
            return deserialise(data)

        row = db.fetch_row("SELECT ... FROM user WHERE id = %s", [user_id])
        cache.setex(key, ttl_user, serialise(row))
        metrics.miss.inc()
        return row</code></pre>
            </div>
            </p>
            <p><em>Why the version column?</em> An update transaction simply increments <code>cache_version</code>, guaranteeing the next read builds a new key and the old value expires naturally.</p>
            <h4 id="monitor-like-a-sre-not-like-a-developer">Monitor like a SRE, not like a developer</h4>
            <p>
            <table>
                <tr>
                    <td>Metric</td>
                    <td>Target</td>
                    <td>Alert when…</td>
                </tr>
                <tr>
                    <td><strong>Cache hit ratio</strong> <code>(hits / (hits+misses))</code></td>
                    <td>&gt; 0.8 for read-through</td>
                    <td>Drops 10 % in 5 min ⇒ cold keys.</td>
                </tr>
                <tr>
                    <td><strong>p99 latency</strong> (cache &amp; DB)</td>
                    <td>Cache p99 ≤ 3 ms; DB p99 ≤ read SLA</td>
                    <td>Cache ≥ 20 ms ⇒ network, serialization, or swap.</td>
                </tr>
                <tr>
                    <td><strong>Evictions per minute</strong></td>
                    <td>0 on provisioned RAM</td>
                    <td>&gt; 1 % of set rate ⇒ resize or add LRU tiers.</td>
                </tr>
                <tr>
                    <td><strong>Hot key balance</strong></td>
                    <td>No single key &gt; 5 % of gets</td>
                    <td>If violated, consider sharding that key or using <em>local in-process</em> cache for it.</td>
                </tr>
            </table>
            </p>
            <p>Grafana dashboards that plot <strong>hit ratio vs. TTL</strong> and <strong>evictions vs. memory used</strong> are the fastest way to validate sizing.</p>
            <h4 id="scale-harden">Scale &amp; harden</h4>
            <ul>
                <li>Redis Cluster or Memcached’s client-side consistent hashing. Keep <em>slot</em> count ≥ 160 × nodes to smooth key re-distribution.</li>
                <li>For read-only or “mostly read” keys, add an in-process LRU (Guava, Caffeine, <code>functools.lru_cache</code>) sized for 5 – 10 % memory of the app pod.</li>
                <li>TLS everywhere (<code>requirepass</code>, <code>auth</code>, or ACLs).</li>
                <li>Key namespaces (<code>app1:*</code>) to stop accidental collisions.</li>
                <li>Encrypt sensitive blobs → envelope encryption (<code>AES-GCM</code>) before putting them in cache.</li>
            </ul>
            <h4 id="why-it-differs-by-app">Why it differs by app</h4>
            <ul>
                <li><strong>E-commerce</strong>: product listings (immutable) vs. cart totals (write-through). TTL for product ≈ catalog update frequency (often 30 min – 1 h).</li>
                <li><strong>SaaS CRUD</strong> apps: user &amp; org objects updated sporadically—TTL can be hours. Focus more on <em>invalidation correctness</em> than raw hit rate.</li>
                <li><strong>Social feed</strong>: massive read amplification. Split feed metadata (list of IDs) and item bodies, use fan-out on write or “pull with cache”.</li>
            </ul>
            <p>Each app’s <em>write cadence</em> and <em>staleness tolerance</em> ultimately dictate TTL and invalidation strategy—use the measurement steps above to quantify both before you start tweaking configs.</p>
            <h3 id="potential-challenges-and-solutions">Potential Challenges and Solutions</h3>
            <p>While caching can slash response times from ~50 ms to sub‑5 ms and offload 80‑90 % of read traffic, it introduces its own pitfalls.</p>
            <h4 id="stale-data-cache-db-drift-">Stale Data (Cache‑DB Drift)</h4>
            <p>
            <div>
                <pre><code class="language-shell">Time ---&gt;

 [DB   ] v2  ──────────────┐
 [Cache] v1 ──┐            │  (TTL 30 s)
              └─&gt;  *Stale* │
 update()                 invalidate()</code></pre>
            </div>
            </p>
            <p><em>Scenario</em>: A product’s price changes from €29.99 to €24.99 at <strong>13:05:12</strong> but users keep seeing the old price for up to 30 s because that’s the TTL.</p>
            <p><strong>Mitigations</strong></p>
            <ul>
                <li><strong>Short‑lived TTLs</strong> on volatile entities (e.g. prices 30 s, user sessions 15 min, catalog 1 h).</li>
                <li><strong>Write‑through / write‑behind</strong> patterns so the cache is updated in the same transaction that touches the DB.</li>
                <li><strong>Event‑driven invalidation</strong>: emit a <code>product.updated</code> event from the write service; consumers delete or refresh the key in Redis immediately.</li>
                <li><strong>Background refresh</strong> ("refresh‑ahead") so popular keys are re‑fetched a few seconds <em>before</em> they expire.</li>
            </ul>
            <h4 id="cache-miss-penalties-thundering-herd-">Cache Miss Penalties (Thundering Herd)</h4>
            <p>
            <div>
                <pre><code class="language-shell">┌───────────────┐
│  Cache (hit)  │  1 ms
└───────────────┘
     △
     │ miss
     ▼
┌──────────────────┐
│  Primary DB      │  ~40 ms
└──────────────────┘</code></pre>
            </div>
            </p>
            <p><em>Scenario</em>: After a deploy, the cache is cold. 5 k rps hits the DB, which briefly spikes to 90 % CPU causing p99 latency to jump from 60 ms ⇒ 1 s.</p>
            <p><strong>Mitigations</strong></p>
            <ul>
                <li><strong>Warm‑up scripts</strong> at deploy time (<code>redis-cli MSET $(cat hot_keys.json)</code>).</li>
                <li><strong>Probabilistic early refresh</strong> (e.g. ["lazy expiring"] where the first thread refreshes while others keep serving the old value).</li>
                <li><strong>Request coalescing</strong> / <em>single‑flight</em>: the first miss locks the key; other requests wait for the result instead of hammering the DB.</li>
                <li><strong>Read replicas</strong> or CQRS read stores to share the load when misses inevitably happen.</li>
            </ul>
            <h4 id="increased-complexity-operational-overhead-">Increased Complexity (Operational Overhead)</h4>
            <p>
            <div>
                <pre><code class="language-shell">┌────────┐   ┌────────┐   ┌────────────┐   ┌────────┐
│Client  │──▶│ Service│──▶│   Cache    │──▶│Database│
└────────┘   └────────┘   └────────────┘   └────────┘
                   ▲
             eviction policy,
           replication, metrics</code></pre>
            </div>
            </p>
            <p><em>Pain Points</em>: extra moving parts (Redis cluster + Sentinel), failure modes (cache down ≠ DB down), and cognitive load for new devs who must understand eviction policies.</p>
            <p><strong>Mitigations</strong></p>
            <ul>
                <li><strong>Leverage frameworks</strong> (<code>Spring @Cacheable</code>, <code>NestJS cache‑manager</code>, Django’s <code>cache</code> API) so most logic is declarative.</li>
                <li>Keep TTLs, eviction policies, and key naming conventions in a single module.</li>
                <li>Emit <em>hit</em>, <em>miss</em>, <em>eviction</em>, <em>latency</em> metrics; dashboard them next to DB metrics.</li>
                <li>Periodically turn off the cache in staging to prove the app still works (albeit slower).</li>
            </ul>
            <blockquote>
                <p><strong>Tip</strong>: Treat the cache as <em>a copy</em> of the source of truth, never the truth itself. Design every code path to <em>degrade gracefully</em> when the cache is empty or unreachable.</p>
            </blockquote>
            <h3 id="real-world-use-cases">Real-World Use Cases</h3>
            <p>Database caching is used extensively in various applications to improve performance and scalability.</p>
            <h4 id="high-traffic-web-applications">High-Traffic Web Applications</h4>
            <p>Websites that experience high traffic volumes, such as news sites or e-commerce platforms, benefit from caching by reducing database load and serving content more quickly.</p>
            <h4 id="content-delivery-networks-cdns-">Content Delivery Networks (CDNs)</h4>
            <p>CDNs cache static content at servers distributed around the globe, reducing latency by serving content from a location closer to the user.</p>
            <h4 id="session-management">Session Management</h4>
            <p>Applications often use caching to store session data, improving the speed of user authentication and personalization features.</p>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#database-caching">Database Caching</a>
                <ol>
                    <li><a href="#understanding-database-caching">Understanding Database Caching</a>
                        <ol>
                            <li><a href="#how-caching-improves-performance">How Caching Improves Performance</a></li>
                        </ol>
                    </li>
                    <li><a href="#types-of-caching-strategies">Types of Caching Strategies</a>
                        <ol>
                            <li><a href="#in-memory-caching">In-Memory Caching</a></li>
                            <li><a href="#client-side-caching">Client-Side Caching</a></li>
                            <li><a href="#server-side-caching">Server-Side Caching</a></li>
                        </ol>
                    </li>
                    <li><a href="#implementing-database-caching-techniques">Implementing Database Caching Techniques</a>
                        <ol>
                            <li><a href="#query-result-caching">Query Result Caching</a></li>
                            <li><a href="#object-caching">Object Caching</a></li>
                            <li><a href="#database-buffer-caching">Database Buffer Caching</a></li>
                            <li><a href="#prepared-statement-caching">Prepared Statement Caching</a></li>
                        </ol>
                    </li>
                    <li><a href="#cache-invalidation-strategies">Cache Invalidation Strategies</a>
                        <ol>
                            <li><a href="#time-to-live-ttl-">Time-to-Live (TTL)</a></li>
                            <li><a href="#event-based-invalidation">Event-Based Invalidation</a></li>
                            <li><a href="#manual-invalidation">Manual Invalidation</a></li>
                        </ol>
                    </li>
                    <li><a href="#choosing-a-strategy">Choosing a Strategy</a></li>
                    <li><a href="#best-practices">Best Practices</a>
                        <ol>
                            <li><a href="#pinpoint-the-hot-data-don-t-guess-">Pinpoint the “hot” data (don’t guess)</a></li>
                            <li><a href="#segregate-reads-into-buckets-before-you-cache">Segregate “reads” into buckets before you cache</a></li>
                            <li><a href="#decide-ttls-with-data-not-folklore">Decide TTLs with data—not folklore</a></li>
                            <li><a href="#wire-it-up-language-agnostic-pseudocode-">Wire it up (language-agnostic pseudocode)</a></li>
                            <li><a href="#monitor-like-a-sre-not-like-a-developer">Monitor like a SRE, not like a developer</a></li>
                            <li><a href="#scale-harden">Scale &amp; harden</a></li>
                            <li><a href="#why-it-differs-by-app">Why it differs by app</a></li>
                        </ol>
                    </li>
                    <li><a href="#potential-challenges-and-solutions">Potential Challenges and Solutions</a>
                        <ol>
                            <li><a href="#stale-data-cache-db-drift-">Stale Data (Cache‑DB Drift)</a></li>
                            <li><a href="#cache-miss-penalties-thundering-herd-">Cache Miss Penalties (Thundering Herd)</a></li>
                            <li><a href="#increased-complexity-operational-overhead-">Increased Complexity (Operational Overhead)</a></li>
                        </ol>
                    </li>
                    <li><a href="#real-world-use-cases">Real-World Use Cases</a>
                        <ol>
                            <li><a href="#high-traffic-web-applications">High-Traffic Web Applications</a></li>
                            <li><a href="#content-delivery-networks-cdns-">Content Delivery Networks (CDNs)</a></li>
                            <li><a href="#session-management">Session Management</a></li>
                        </ol>
                    </li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Introduction to Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/01_databases_intro.html">Databases Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/02_types_of_databases.html">Types of Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/03_database_management_systems_dbms_.html">Database Management Systems Dbms</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/04_data_models.html">Data Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/05_glossary.html">Glossary</a></li>
                        </ol>
                    </li>
                    <li>Database Design<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/01_requirements_analysis.html">Requirements Analysis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/02_normalization.html">Normalization</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/03_denormalization.html">Denormalization</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/04_indexing_strategies.html">Indexing Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/05_data_integrity.html">Data Integrity</a></li>
                        </ol>
                    </li>
                    <li>Sql<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/01_intro_to_sql.html">Intro to Sql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/02_data_definition_language_ddl.html">Data Definition Language Ddl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/03_data_manipulation_language_dml.html">Data Manipulation Language Dml</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/04_data_control_language_dcl.html">Data Control Language Dcl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/05_transaction_control_language_tcl.html">Transaction Control Language Tcl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/06_joins_subqueries_and_views.html">Joins Subqueries and Views</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/07_stored_procedures_and_functions.html">Stored Procedures and Functions</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/08_triggers.html">Triggers</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/09_hierarchical_data.html">Hierarchical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/10_aggregate_functions.html">Aggregate Functions</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/11_window_functions.html">Window Functions</a></li>
                        </ol>
                    </li>
                    <li>Acid Properties and Transactions<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/01_transactions_intro.html">Transactions Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/02_atomicity.html">Atomicity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/03_consistency.html">Consistency</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/04_isolation.html">Isolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/05_durability.html">Durability</a></li>
                        </ol>
                    </li>
                    <li>Storage and Indexing<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/01_how_tables_and_indexes_are_stored_on_disk.html">How Tables and Indexes Are Stored on Disk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/02_row_based_vs_column_based_databases.html">Row Based vs Column Based Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/03_primary_key_vs_secondary_key.html">Primary Key vs Secondary Key</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/04_database_pages.html">Database Pages</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/05_indexing.html">Indexing</a></li>
                        </ol>
                    </li>
                    <li>Distributed Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/01_distributed_database_systems.html">Distributed Database Systems</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/02_partitioning.html">Partitioning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/03_sharding.html">Sharding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/04_partitioning_vs_sharding.html">Partitioning vs Sharding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/05_consistent_hashing.html">Consistent Hashing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/06_cap_theorem.html">Cap Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/07_eventual_consistency.html">Eventual Consistency</a></li>
                        </ol>
                    </li>
                    <li>Concurrency Control<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/01_shared_vs_exclusive_locks.html">Shared vs Exclusive Locks</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/02_deadlocks.html">Deadlocks</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/03_two_phase_locking.html">Two Phase Locking</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/04_double_booking_problem.html">Double Booking Problem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/05_serializable_vs_repeatable_read.html">Serializable vs Repeatable Read</a></li>
                        </ol>
                    </li>
                    <li>Database Performance<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/01_query_optimization_techniques.html">Query Optimization Techniques</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/02_indexing_strategies.html">Indexing Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/03_database_caching.html">Database Caching</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/04_materialized_views.html">Materialized Views</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/05_accessing_database_in_code.html">Accessing Database in Code</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/06_working_with_billion_row_table.html">Working with Billion Row Table</a></li>
                        </ol>
                    </li>
                    <li>Database Replication<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/01_intro_to_replication.html">Intro to Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/02_master_standby_replication.html">Master Standby Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/03_multi_master_replication.html">Multi Master Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/04_synchronous_vs_asynchronous_replication.html">Synchronous vs Asynchronous Replication</a></li>
                        </ol>
                    </li>
                    <li>Nosql Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/01_nosql_databases_intro.html">Nosql Databases Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/02_types_of_nosql_databases.html">Types of Nosql Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/03_querying_nosql_databases.html">Querying Nosql Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/04_crud_in_sql_vs_nosql.html">Crud in Sql vs Nosql</a></li>
                        </ol>
                    </li>
                    <li>Security Best Practices<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/01_backup_and_recovery_strategies.html">Backup and Recovery Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/02_database_security.html">Database Security</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/03_capacity_planning.html">Capacity Planning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/04_database_migration.html">Database Migration</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/05_performance_monitoring_and_tuning.html">Performance Monitoring and Tuning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/06_sql_injection.html">Sql Injection</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/07_crash_recovery_in_databases.html">Crash Recovery in Databases</a></li>
                        </ol>
                    </li>
                    <li>Database Engines<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/01_sqlite.html">Sqlite</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/02_mysql.html">Mysql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/03_postgresql.html">Postgresql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/04_mongodb.html">Mongodb</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/05_neo4j.html">Neo4J</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/06_aws_services.html">Aws Services</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/07_choosing_database.html">Choosing Database</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                © Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>