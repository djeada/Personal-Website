<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <meta charset="utf-8" />
    <title>Working with Billion-Row Tables</title>
    <meta content="Managing tables that contain billions of rows presents unique challenges in terms of performance, scalability, and maintenance." name="description" />
    <meta content="Adam Djellouli" name="author" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <link crossorigin="" href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../../resources/style.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="https://adamdjellouli.com">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a class="active" href="../../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <div id="article-wrapper">
        <section id="article-body">
            <div class="article-action-buttons"><button class="btn-suggest-edit" title="Suggest Edit">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M4 21h4l11-11-4-4L4 17v4z" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button><button class="btn-create-issue" title="Create Issue">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"></circle>
                        <line stroke="currentColor" stroke-width="2" x1="12" x2="12" y1="8" y2="12"></line>
                        <circle cx="12" cy="16" fill="currentColor" r="1"></circle>
                    </svg>
                </button><button class="btn-download" title="Download">
                    <svg fill="none" height="20" viewbox="0 0 24 24" width="20">
                        <path d="M12 5v14m0 0l-6-6m6 6l6-6" stroke="currentColor" stroke-width="2"></path>
                    </svg>
                </button></div>
            <p style="text-align: right;"><i>Last modified: April 25, 2025</i></p>
            <p style="text-align: right;"><i>This article is written in: ðŸ‡ºðŸ‡¸</i></p>
            <h2 id="working-with-billion-row-tables">Working with Billion-Row Tables</h2>
            <p>Managing tables that contain billions of rows presents unique challenges in terms of performance, scalability, and maintenance. As data volumes grow, it's essential to adopt effective strategies to handle such massive datasets efficiently. This guide explores the challenges associated with billion-row tables and provides techniques and best practices for working with them effectively.</p>
            <p>After reading the material, you should be able to answer the following questions:</p>
            <ul>
                <li>What are the primary challenges associated with managing billion-row tables, and how do they impact database performance and maintenance?</li>
                <li>What partitioning strategies can be employed to handle large tables, and how does each strategy improve performance and scalability?</li>
                <li>How do different indexing techniques, such as B-tree and bitmap indexes, enhance query performance in large datasets, and what are the best practices for their implementation?</li>
                <li>What optimization methods, including query optimization and the use of materialized views, can be applied to efficiently manage and retrieve data from billion-row tables?</li>
                <li>When should strategies like sharding, distributed caching, and utilizing big data technologies be implemented, and what benefits do they offer for handling massive datasets?</li>
            </ul>
            <h3 id="challenges-of-large-tables">Challenges of Large Tables</h3>
            <p>Working with extremely large tables can lead to several issues:</p>
            <ul>
                <li>Queries may run slowly, impacting how responsive your application feels.</li>
                <li>As data volume grows, memory, CPU, and I/O usage increase, potentially overloading system resources and leading to performance bottlenecks.</li>
                <li>Routine operations such as backups, indexing, and updates become progressively slower and more resource-intensive, complicating database management.</li>
                <li>Traditional database systems often face limitations when attempting to scale horizontally, making it difficult to handle ever-expanding datasets effectively.</li>
                <li>If your application requests more rows than its available RAM can process, it may run out of memory and crash, disrupting services and requiring manual intervention.</li>
            </ul>
            <h3 id="techniques-for-handling-billion-row-tables">Techniques for Handling Billion-Row Tables</h3>
            <p>To address these challenges, several strategies can be employed:</p>
            <h4 id="partitioning">Partitioning</h4>
            <p>Partitioning involves dividing a large table into smaller, more manageable pieces called partitions. This can improve performance and simplify maintenance tasks.</p>
            <ul>
                <li><strong>Range Partitioning</strong> organizes data into partitions based on a range of values, such as dates or numerical ranges. </li>
                <li><strong>List Partitioning</strong> creates partitions by grouping specific values into distinct partitions. </li>
                <li><strong>Hash Partitioning</strong> distributes data across partitions using a hash function, ensuring even distribution for load balancing. </li>
                <li><strong>Composite Partitioning</strong> combines multiple partitioning strategies, such as range and hash, to optimize for complex use cases.</li>
            </ul>
            <p><strong>Example: Range Partitioning in PostgreSQL</strong></p>
            <p>Suppose you have a <code>transactions</code> table that you want to partition by year:</p>
            <p>
            <div>
                <pre><code class="language-sql">-- Create partitioned table
CREATE TABLE transactions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER,
    amount DECIMAL(10, 2),
    transaction_date DATE
) PARTITION BY RANGE (transaction_date);

-- Create partitions for each year
CREATE TABLE transactions_2021 PARTITION OF transactions
    FOR VALUES FROM ('2021-01-01') TO ('2022-01-01');

CREATE TABLE transactions_2022 PARTITION OF transactions
    FOR VALUES FROM ('2022-01-01') TO ('2023-01-01');</code></pre>
            </div>
            </p>
            <ul>
                <li><strong>Improved Query Performance</strong> is achieved as queries can focus on specific partitions, reducing the overall data scanned. </li>
                <li><strong>Simplified Maintenance</strong> becomes possible by allowing maintenance operations like backups or repairs to be performed on individual partitions. </li>
                <li><strong>Enhanced Scalability</strong> is supported by distributing data across multiple disks or nodes, accommodating larger datasets efficiently. </li>
            </ul>
            <h4 id="indexing-strategies">Indexing Strategies</h4>
            <p>Proper indexing is crucial for efficient data retrieval in large tables.</p>
            <p><strong>B-tree Indexes</strong></p>
            <p>Ideal for columns frequently used in search conditions and range queries.</p>
            <p>
            <div>
                <pre><code class="language-sql">CREATE INDEX idx_transactions_user_id ON transactions (user_id);</code></pre>
            </div>
            </p>
            <p><strong>Bitmap Indexes</strong></p>
            <p>Effective for columns with low cardinality (few unique values), commonly used in data warehousing.</p>
            <p>
            <div>
                <pre><code class="language-sql">-- Example in Oracle
CREATE BITMAP INDEX idx_transactions_status ON transactions (status);</code></pre>
            </div>
            </p>
            <ul>
                <li><strong>Index Selective Columns</strong> to optimize query performance by targeting columns frequently used in WHERE clauses, joins, and ORDER BY clauses. </li>
                <li><strong>Monitor and Maintain Indexes</strong> by periodically analyzing their usage and rebuilding them when fragmentation affects performance. </li>
                <li><strong>Avoid Over-Indexing</strong> to prevent degradation of write operations caused by excessive indexing. </li>
            </ul>
            <h4 id="query-optimization">Query Optimization</h4>
            <p>Optimizing SQL queries can significantly improve performance.</p>
            <p><strong>Tips for Optimization</strong></p>
            <ul>
                <li><strong>Avoid SELECT *</strong> by retrieving only the columns required to minimize data transfer and improve query efficiency. </li>
                <li><strong>Use Efficient Joins</strong> by optimizing join conditions and evaluating the join order for better performance. </li>
                <li><strong>Filter Early</strong> in queries by applying WHERE clauses at the earliest stage to reduce the dataset size being processed. </li>
            </ul>
            <p><strong>Example</strong></p>
            <p>Inefficient query:</p>
            <p>
            <div>
                <pre><code class="language-sql">SELECT * FROM transactions JOIN users ON transactions.user_id = users.id;</code></pre>
            </div>
            </p>
            <p>Optimized query:</p>
            <p>
            <div>
                <pre><code class="language-sql">SELECT t.amount, t.transaction_date, u.name
FROM transactions t
INNER JOIN users u ON t.user_id = u.id
WHERE t.transaction_date &gt;= '2022-01-01';</code></pre>
            </div>
            </p>
            <h4 id="materialized-views">Materialized Views</h4>
            <p>Materialized views store the result of a query physically and can be refreshed periodically.</p>
            <ul>
                <li><strong>Precompute Complex Queries</strong> by storing the results of resource-intensive operations to reduce repeated calculations. </li>
                <li><strong>Improve Read Performance</strong> by serving precomputed data quickly, minimizing query execution time.</li>
            </ul>
            <p><strong>Example in PostgreSQL</strong></p>
            <p>
            <div>
                <pre><code class="language-sql">CREATE MATERIALIZED VIEW monthly_sales AS
SELECT DATE_TRUNC('month', transaction_date) AS month,
       SUM(amount) AS total_amount
FROM transactions
GROUP BY month;</code></pre>
            </div>
            </p>
            <p>To refresh the materialized view:</p>
            <p>
            <div>
                <pre><code class="language-sql">REFRESH MATERIALIZED VIEW monthly_sales;</code></pre>
            </div>
            </p>
            <h4 id="data-archiving">Data Archiving</h4>
            <p>Archiving old or less frequently accessed data reduces the size of active tables.</p>
            <ul>
                <li><strong>Move Historical Data</strong> to archive tables by transferring records older than a specific date to maintain database efficiency. </li>
                <li><strong>Use Separate Storage</strong> for archived data by leveraging cost-effective storage solutions to reduce primary database overhead.</li>
            </ul>
            <p><strong>Example</strong></p>
            <p>
            <div>
                <pre><code class="language-sql">-- Move transactions older than 2020 to an archive table
INSERT INTO transactions_archive
SELECT * FROM transactions WHERE transaction_date &lt; '2020-01-01';

DELETE FROM transactions WHERE transaction_date &lt; '2020-01-01';</code></pre>
            </div>
            </p>
            <h4 id="hardware-upgrades">Hardware Upgrades</h4>
            <p>Upgrading hardware can provide immediate performance improvements.</p>
            <ul>
                <li><strong>Solid-State Drives (SSDs)</strong> enhance I/O performance with faster read and write speeds compared to traditional hard drives. </li>
                <li><strong>Increase Memory</strong> to allow for larger caches and buffers, reducing the need for frequent disk access. </li>
                <li><strong>CPU Enhancements</strong> with additional cores and higher clock speeds improve the processing capacity for database operations.</li>
            </ul>
            <h4 id="distributed-systems-and-sharding">Distributed Systems and Sharding</h4>
            <p>Distributing the database across multiple servers balances the load and enhances scalability.</p>
            <p><strong>Sharding</strong></p>
            <ul>
                <li>Splitting a large database into smaller pieces, each hosted on a separate server.</li>
                <li><strong>Shard Key</strong> is a critical element that determines how data is distributed across the shards, impacting balance and query efficiency. </li>
            </ul>
            <p><strong>Example with MongoDB</strong></p>
            <p>
            <div>
                <pre><code class="language-javascript">// Enable sharding for the database
sh.enableSharding("myDatabase");

// Shard the 'transactions' collection on 'user_id'
sh.shardCollection("myDatabase.transactions", { "user_id": 1 });</code></pre>
            </div>
            </p>
            <ul>
                <li><strong>Horizontal Scalability</strong> allows for adding more servers seamlessly to manage increasing data volumes and workloads. </li>
                <li><strong>Fault Isolation</strong> ensures that problems in one shard do not impact the performance or availability of other shards.</li>
            </ul>
            <h4 id="utilizing-big-data-technologies">Utilizing Big Data Technologies</h4>
            <p>Leverage big data frameworks designed for handling massive datasets.</p>
            <p><strong>Apache Hadoop and MapReduce</strong></p>
            <ul>
                <li>Batch processing of large datasets across clusters.</li>
                <li>Distributes data and computation across multiple nodes.</li>
            </ul>
            <p><strong>Apache Spark</strong></p>
            <ul>
                <li>In-memory processing for faster computation.</li>
                <li>Supports SQL queries, machine learning, and real-time data processing.</li>
            </ul>
            <h5>Example with Spark (Python)</h5>
            <p>
            <div>
                <pre><code class="language-python">from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("DataProcessing").getOrCreate()

# Load data from a CSV file
df = spark.read.csv("transactions.csv", header=True, inferSchema=True)

# Perform aggregation
monthly_totals = df.groupBy("transaction_date").sum("amount")

# Display results
monthly_totals.show()</code></pre>
            </div>
            </p>
            <h4 id="caching-strategies">Caching Strategies</h4>
            <p>Implementing caching mechanisms can reduce database load and improve response times.</p>
            <p><strong>In-Memory Caching</strong></p>
            <ul>
                <li><strong>Tools</strong> like Redis and Memcached are commonly used for in-memory data storage to improve access speeds. </li>
                <li>Usage involves storing frequently accessed data in memory to reduce latency and improve application performance.</li>
            </ul>
            <p><strong>Example with Redis (Python)</strong></p>
            <p>
            <div>
                <pre><code class="language-python">import redis

# Connect to Redis
cache = redis.Redis(host='localhost', port=6379, db=0)

# Set cache with expiration
cache.set('user_123_data', user_data, ex=3600)  # Expires in 1 hour

# Retrieve from cache
cached_data = cache.get('user_123_data')</code></pre>
            </div>
            </p>
            <h4 id="asynchronous-processing">Asynchronous Processing</h4>
            <p>Offload time-consuming tasks to background processes to keep applications responsive.</p>
            <p><strong>Task Queues and Message Brokers</strong></p>
            <ul>
                <li><strong>Tools</strong> such as Celery with RabbitMQ or Redis and Apache Kafka are widely used for task queuing and message processing. </li>
                <li>Usage involves queuing tasks to be executed asynchronously, improving system responsiveness and scalability. </li>
            </ul>
            <p><strong>Example with Celery (Python)</strong></p>
            <p>
            <div>
                <pre><code class="language-python">from celery import Celery

app = Celery('tasks', broker='pyamqp://guest@localhost//')

@app.task
def process_large_dataset(data_chunk):
    # Perform processing on data_chunk
    pass

# Asynchronously call the task
process_large_dataset.delay(data_chunk)</code></pre>
            </div>
            </p>
            <h3 id="comparison-of-methods-for-handling-large-tables">Comparison of Methods for Handling Large Tables</h3>
            <p>
            <table>
                <tr>
                    <td>Method</td>
                    <td>Benefits</td>
                    <td>Challenges</td>
                    <td>Assessment</td>
                </tr>
                <tr>
                    <td><strong>Brute Force Distributed Processing</strong></td>
                    <td>- Parallel processing reduces execution time<br />- Scalability through added resources</td>
                    <td>- High resource requirements<br />- Complexity in management</td>
                    <td>Effective for large-scale batch processing; resource-intensive and complex to manage.</td>
                </tr>
                <tr>
                    <td><strong>Indexing</strong></td>
                    <td>- Speeds up query performance<br />- Reduces data scanned</td>
                    <td>- Additional storage<br />- Affects write performance</td>
                    <td>Essential for performance; must balance benefits against maintenance overhead.</td>
                </tr>
                <tr>
                    <td><strong>Partitioning</strong></td>
                    <td>- Improved query performance<br />- Easier maintenance</td>
                    <td>- Complexity in partition management<br />- Potential data skew</td>
                    <td>Enhances performance and manageability; requires careful planning and management.</td>
                </tr>
                <tr>
                    <td><strong>Materialized Views</strong></td>
                    <td>- Faster query response<br />- Offloads processing</td>
                    <td>- Data staleness<br />- Storage overhead</td>
                    <td>Ideal for complex queries; must manage refresh strategies to keep data current.</td>
                </tr>
                <tr>
                    <td><strong>Sharding</strong></td>
                    <td>- Scalability and performance<br />- Reduces load per server</td>
                    <td>- Complexity in setup<br />- Query routing challenges</td>
                    <td>Highly scalable; suitable for distributed systems; adds complexity to application logic.</td>
                </tr>
                <tr>
                    <td><strong>Distributed Caching</strong></td>
                    <td>- Reduces database load<br />- Improves read performance</td>
                    <td>- Cache invalidation<br />- Data consistency issues</td>
                    <td>Effective for read-heavy workloads; requires robust cache management strategies.</td>
                </tr>
                <tr>
                    <td><strong>Asynchronous Processing</strong></td>
                    <td>- Keeps application responsive<br />- Scalable background processing</td>
                    <td>- Complexity in task management<br />- Error handling</td>
                    <td>Ideal for handling long-running tasks; adds complexity to application architecture.</td>
                </tr>
                <tr>
                    <td><strong>Reshuffling Design</strong></td>
                    <td>- Simplifies data model<br />- Potential performance gains</td>
                    <td>- Data redundancy<br />- Consistency management</td>
                    <td>Can prevent the need for large tables; must handle denormalization trade-offs.</td>
                </tr>
                <tr>
                    <td><strong>Data Archiving</strong></td>
                    <td>- Reduces active dataset size<br />- Improves performance</td>
                    <td>- Accessibility of archived data<br />- Data migration effort</td>
                    <td>Effective for managing data growth; requires policies for data lifecycle management.</td>
                </tr>
                <tr>
                    <td><strong>Hardware Upgrades</strong></td>
                    <td>- Immediate performance improvement</td>
                    <td>- High costs<br />- Limited scalability</td>
                    <td>Provides performance boost; may not be sufficient for massive datasets in the long term.</td>
                </tr>
            </table>
            </p>
            <h3 id="additional-thoughts">Additional Thoughts</h3>
            <ul>
                <li><strong>Transactional Consistency</strong> is difficult to maintain in distributed environments, where preserving ACID properties can be challenging. Using databases with distributed transaction support can help when consistency is essential. </li>
                <li><strong>Testing with Realistic Data Volumes</strong> helps uncover performance issues that may only emerge at scale. Simulating actual data sizes during testing identifies bottlenecks early. </li>
                <li><strong>Monitoring and Metrics</strong> provide insight into performance, resource usage, and system health. Tools like Prometheus, Grafana, and database-specific monitoring utilities are helpful for tracking key metrics. </li>
                <li><strong>NoSQL Databases</strong> such as Cassandra, HBase, or MongoDB are designed for scalability and distributed data handling, making them effective for large datasets. </li>
                <li><strong>Data Compression</strong> techniques reduce storage demands and enhance I/O performance, with many databases offering built-in compression features. </li>
                <li><strong>Message Queues and Event-Driven Architecture</strong> decouple data ingestion from processing using tools like Apache Kafka or RabbitMQ, improving scalability and resilience. </li>
                <li><strong>Cloud Services</strong> such as Amazon Redshift or Google BigQuery are tailored for large-scale data warehousing and analytics, offering scalability and performance optimization. </li>
            </ul>
        </section>
        <div id="table-of-contents">
            <h2>Table of Contents</h2>
            <ol><a href="#working-with-billion-row-tables">Working with Billion-Row Tables</a>
                <ol>
                    <li><a href="#challenges-of-large-tables">Challenges of Large Tables</a></li>
                    <li><a href="#techniques-for-handling-billion-row-tables">Techniques for Handling Billion-Row Tables</a>
                        <ol>
                            <li><a href="#partitioning">Partitioning</a></li>
                            <li><a href="#indexing-strategies">Indexing Strategies</a></li>
                            <li><a href="#query-optimization">Query Optimization</a></li>
                            <li><a href="#materialized-views">Materialized Views</a></li>
                            <li><a href="#data-archiving">Data Archiving</a></li>
                            <li><a href="#hardware-upgrades">Hardware Upgrades</a></li>
                            <li><a href="#distributed-systems-and-sharding">Distributed Systems and Sharding</a></li>
                            <li><a href="#utilizing-big-data-technologies">Utilizing Big Data Technologies</a></li>
                            <li><a href="#caching-strategies">Caching Strategies</a></li>
                            <li><a href="#asynchronous-processing">Asynchronous Processing</a></li>
                        </ol>
                    </li>
                    <li><a href="#comparison-of-methods-for-handling-large-tables">Comparison of Methods for Handling Large Tables</a></li>
                    <li><a href="#additional-thoughts">Additional Thoughts</a></li>
                </ol>
            </ol>
            <div id="related-articles">
                <h2>Related Articles</h2>
                <ol>
                    <li>Introduction to Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/01_databases_intro.html">Databases Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/02_types_of_databases.html">Types of Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/03_database_management_systems_dbms_.html">Database Management Systems Dbms</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/04_data_models.html">Data Models</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/01_introduction_to_databases/05_glossary.html">Glossary</a></li>
                        </ol>
                    </li>
                    <li>Database Design<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/01_requirements_analysis.html">Requirements Analysis</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/02_normalization.html">Normalization</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/03_denormalization.html">Denormalization</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/04_indexing_strategies.html">Indexing Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/02_database_design/05_data_integrity.html">Data Integrity</a></li>
                        </ol>
                    </li>
                    <li>Sql<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/01_intro_to_sql.html">Intro to Sql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/02_data_definition_language_ddl.html">Data Definition Language Ddl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/03_data_manipulation_language_dml.html">Data Manipulation Language Dml</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/04_data_control_language_dcl.html">Data Control Language Dcl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/05_transaction_control_language_tcl.html">Transaction Control Language Tcl</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/06_joins_subqueries_and_views.html">Joins Subqueries and Views</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/07_stored_procedures_and_functions.html">Stored Procedures and Functions</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/08_triggers.html">Triggers</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/09_hierarchical_data.html">Hierarchical Data</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/10_aggregate_functions.html">Aggregate Functions</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/03_sql/11_window_functions.html">Window Functions</a></li>
                        </ol>
                    </li>
                    <li>Acid Properties and Transactions<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/01_transactions_intro.html">Transactions Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/02_atomicity.html">Atomicity</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/03_consistency.html">Consistency</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/04_isolation.html">Isolation</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/04_acid_properties_and_transactions/05_durability.html">Durability</a></li>
                        </ol>
                    </li>
                    <li>Storage and Indexing<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/01_how_tables_and_indexes_are_stored_on_disk.html">How Tables and Indexes Are Stored on Disk</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/02_row_based_vs_column_based_databases.html">Row Based vs Column Based Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/03_primary_key_vs_secondary_key.html">Primary Key vs Secondary Key</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/04_database_pages.html">Database Pages</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/05_storage_and_indexing/05_indexing.html">Indexing</a></li>
                        </ol>
                    </li>
                    <li>Distributed Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/01_distributed_database_systems.html">Distributed Database Systems</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/02_partitioning.html">Partitioning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/03_sharding.html">Sharding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/04_partitioning_vs_sharding.html">Partitioning vs Sharding</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/05_consistent_hashing.html">Consistent Hashing</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/06_cap_theorem.html">Cap Theorem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/06_distributed_databases/07_eventual_consistency.html">Eventual Consistency</a></li>
                        </ol>
                    </li>
                    <li>Concurrency Control<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/01_shared_vs_exclusive_locks.html">Shared vs Exclusive Locks</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/02_deadlocks.html">Deadlocks</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/03_two_phase_locking.html">Two Phase Locking</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/04_double_booking_problem.html">Double Booking Problem</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/07_concurrency_control/05_serializable_vs_repeatable_read.html">Serializable vs Repeatable Read</a></li>
                        </ol>
                    </li>
                    <li>Database Performance<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/01_query_optimization_techniques.html">Query Optimization Techniques</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/02_indexing_strategies.html">Indexing Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/03_database_caching.html">Database Caching</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/04_materialized_views.html">Materialized Views</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/05_accessing_database_in_code.html">Accessing Database in Code</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/08_database_performance/06_working_with_billion_row_table.html">Working with Billion Row Table</a></li>
                        </ol>
                    </li>
                    <li>Database Replication<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/01_intro_to_replication.html">Intro to Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/02_master_standby_replication.html">Master Standby Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/03_multi_master_replication.html">Multi Master Replication</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/09_database_replication/04_synchronous_vs_asynchronous_replication.html">Synchronous vs Asynchronous Replication</a></li>
                        </ol>
                    </li>
                    <li>Nosql Databases<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/01_nosql_databases_intro.html">Nosql Databases Intro</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/02_types_of_nosql_databases.html">Types of Nosql Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/03_querying_nosql_databases.html">Querying Nosql Databases</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/10_nosql_databases/04_crud_in_sql_vs_nosql.html">Crud in Sql vs Nosql</a></li>
                        </ol>
                    </li>
                    <li>Security Best Practices<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/01_backup_and_recovery_strategies.html">Backup and Recovery Strategies</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/02_database_security.html">Database Security</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/03_capacity_planning.html">Capacity Planning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/04_database_migration.html">Database Migration</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/05_performance_monitoring_and_tuning.html">Performance Monitoring and Tuning</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/06_sql_injection.html">Sql Injection</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/11_security_best_practices/07_crash_recovery_in_databases.html">Crash Recovery in Databases</a></li>
                        </ol>
                    </li>
                    <li>Database Engines<ol>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/01_sqlite.html">Sqlite</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/02_mysql.html">Mysql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/03_postgresql.html">Postgresql</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/04_mongodb.html">Mongodb</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/05_neo4j.html">Neo4J</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/06_aws_services.html">Aws Services</a></li>
                            <li><a href="https://adamdjellouli.com/articles/databases_notes/12_database_engines/07_choosing_database.html">Choosing Database</a></li>
                        </ol>
                    </li>
                </ol>
            </div>
        </div>
    </div>
    <footer>
        <div class="footer-columns">
            <div class="footer-column">
                <img alt="Adam Djellouli Symbol" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
            <div class="footer-column">
                <h2><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Our Privacy Policy</a></h2>
                <p>
                    Thank you for visiting my personal website. All of the <br />
                    content on this site is free to use, but please remember <br />
                    to be a good human being and refrain from any abuse<br />
                    of the site. If you would like to contact me, please use <br />
                    my <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn profile</a> or my <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a> if you have any technical <br />
                    issues or ideas to share. I wish you the best and hope you <br />
                    have a fantastic life. <br />
                </p>
            </div>
            <div class="footer-column">
                <h2>Follow me</h2>
                <ul class="social-media">
                    <li>
                        <a class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" target="_blank" title="YouTube">
                        </a>YouTube
                    </li>
                    <li>
                        <a class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" target="_blank" title="LinkedIn">
                        </a>LinkedIn
                    </li>
                    <li>
                        <a class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" target="_blank" title="Instagram">
                        </a>Instagram
                    </li>
                    <li>
                        <a class="fa fa-github" href="https://github.com/djeada" title="GitHub">
                        </a>Github
                    </li>
                </ul>
            </div>
        </div>
        <div>
            <p id="copyright">
                Â© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="../../../app.js"></script>
    </footer>
    <div id="pdf-spinner-overlay">
        <div class="spinner"></div>
    </div>
</body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-cpp.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
jax: ["input/TeX", "output/HTML-CSS"],
extensions: ["tex2jax.js"],
"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
tex2jax: { inlineMath: [ ["$", "$"] ], displayMath: [ ["$$","$$"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
messageStyle: "none"
});
</script>
<script async="" id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

</html>