{
    "questions": [
        {
            "correctOptionIndex": 0,
            "options": [
                "identical; shared",
                "dissimilar; shared",
                "dissimilar; distributed",
                "identical; distributed",
                "asynchronous; shared"
            ],
            "text": "A Symmetric Multi-Processing (SMP) system has two or more _____ processors connected to a single _____ main memory."
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "process; other processes",
                "thread; processes",
                "thread; other threads",
                "process; threads"
            ],
            "text": "A _____ contains one or more _____."
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "lower",
                "higher",
                "equivalent",
                "variable"
            ],
            "text": "A hyperthreaded processor with 8 logical cores will usually provide _____ performance compared to a regular processor with 8 physical cores."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "only occurs when there is",
                "can occur independently of",
                "is just another name for",
                "is more severe than",
                "is unrelated to"
            ],
            "text": "A race condition _____ a data race."
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "new",
                "runnable",
                "terminated",
                "blocked",
                "waiting"
            ],
            "text": "A thread that calls the join method on another thread will enter a _____ state until the other thread finishes executing."
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "upper and lower limit",
                "lower limit",
                "upper limit",
                "average value",
                "median value"
            ],
            "text": "Amdahl's Law calculates a(n) _____ for the overall speedup that parallelizing a program will achieve."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "runaway threads to prevent memory leaks",
                "the relative order in which threads execute certain operations",
                "when operations are executed atomically",
                "the priority that determines which threads get scheduled first",
                "the maximum number of threads that can be created"
            ],
            "text": "Barriers can be used to control _____."
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "storage location; save their current state information",
                "conditional statement; pick among several possible paths of execution",
                "holding place; wait for a certain condition before continuing execution",
                "checkpoint; synchronize their execution steps",
                "lock; ensure mutual exclusion"
            ],
            "text": "Condition variables serve as a _____ for threads to _____."
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "a mutex",
                "a thread",
                "the OS execution scheduler",
                "a process",
                "a semaphore"
            ],
            "text": "Condition variables work together with which other mechanism to serve as a monitor?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "more responsive",
                "more scalable",
                "easier to program for",
                "less complex",
                "more cost-effective"
            ],
            "text": "Distributed memory architectures are often considered _____ compared to shared memory systems."
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "FALSE",
                "TRUE",
                "It depends on the operating system",
                "It depends on the language used"
            ],
            "text": "Every thread is independent and has its own separate address space in memory."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "input; output",
                "instruction; data",
                "program; data",
                "memory; I/O",
                "data; cache"
            ],
            "text": "Flynn's Taxonomy categorizes computer architectures based on the number of concurrent _____ streams and _____ streams."
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "speedup; number of processors",
                "tasks; time",
                "tasks; number of processors",
                "computation; communication",
                "workload; processors"
            ],
            "text": "Granularity can be described as the ratio of _____ over _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Larger problems always have lower speedup",
                "Larger problems often achieve better speedup because parallel overhead becomes a smaller fraction of total work",
                "Problem size doesn't affect speedup",
                "Smaller problems always have better speedup",
                "Only medium-sized problems benefit from parallelization"
            ],
            "text": "How does problem size affect parallel speedup?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "The consumption and production rates must be exactly the same.",
                "The consumption rate should be greater than or equal to the production rate.",
                "It does not matter.",
                "The consumption rate should be less than or equal to the production rate.",
                "The production rate should always exceed the consumption rate."
            ],
            "text": "How should the average rates of production and consumption be related in a producer-consumer architecture?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "4.62",
                "5.1",
                "1",
                "6",
                "5.5"
            ],
            "text": "If 85% of a program is parallelizable so that using a 6-core processor will produce a 6x speedup for that portion of the code, what is the maximum overall speedup the program can achieve?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "multiple times by different threads",
                "multiple times by the same thread",
                "once by multiple threads at the same time",
                "only once in total",
                "depends on the compiler settings"
            ],
            "text": "In C++, a recursive_mutex can be locked _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "wait(); before",
                "wait(); after",
                "notify_all(); after",
                "notify_all(); before",
                "signal(); before"
            ],
            "text": "In C++, a thread that needs to execute a section of code before the barrier should call the Barrier's _____ function _____ executing the code."
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "FALSE",
                "TRUE",
                "It depends on the thread state.",
                "Only if the thread has not started yet."
            ],
            "text": "In C++, calling the detach() function on a thread makes it joinable."
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "1",
                "2",
                "no limit",
                "0",
                "depends on the operating system"
            ],
            "text": "In C++, how many threads can take shared ownership of a shared_mutex while another thread has exclusive ownership of it?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "once",
                "none because multiple threads can lock a recursive_mutex at the same time",
                "as many times as that thread locked it",
                "twice",
                "depends on the priority of the threads"
            ],
            "text": "In C++, how many times must a thread unlock a recursive_mutex before another thread can acquire it?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "It begins execution, pending OS scheduling.",
                "It waits in a \"blocked\" state until the parent thread starts it.",
                "It waits in a \"new thread\" state until the parent thread starts it.",
                "It remains idle until explicitly started."
            ],
            "text": "In C++, what happens to a std::thread object immediately after being instantiated?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The function will block execution until the mutex is available, then lock it and return true.",
                "The function immediately locks the mutex and returns true.",
                "The function will block execution until the mutex is available, then lock it and return false.",
                "The function immediately locks the mutex and returns false.",
                "The function does nothing and returns false."
            ],
            "text": "In C++, what happens when a thread calls the try_lock() function on a mutex that is NOT currently locked by another thread?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "try_lock() checks whether or not a mutex is already taken without actually locking it.",
                "try_lock() will not block execution if the mutex is already taken by another thread.",
                "try_lock() will continuously try to lock the mutex if it is already taken by another thread.",
                "lock() returns a boolean value to indicate whether or not it was successful.",
                "lock() can be used only with specific mutex types."
            ],
            "text": "In C++, what is the difference between the try_lock() and regular lock() functions?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "1",
                "no limit",
                "2",
                "0",
                "depends on the operating system"
            ],
            "text": "In C++, what is the maximum number of threads that can have exclusive ownership of a shared_mutex at the same time?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "1",
                "2",
                "0",
                "no limit",
                "depends on the implementation"
            ],
            "text": "In C++, what is the maximum number of threads that can have shared ownership of a shared_mutex at the same time?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "Lots of threads need to modify the value of a shared variable, but only a few threads need to read its value.",
                "Only a few threads need to both read and modify the value of a shared variable.",
                "Lots of threads need to both read and modify the value of a shared variable.",
                "Lots of threads need to read the value of a shared variable, but only a few threads need to modify its value.",
                "All threads need exclusive access to the shared variable."
            ],
            "text": "In C++, which of these scenarios describes the best use case for using a shared_mutex?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "It enables a thread to execute alternate operations if the mutex it needs to acquire is already taken.",
                "It enforces fairness among multiple threads competing for ownership of the same mutex.",
                "If multiple threads try to lock a mutex simultaneously, the try_lock() method will randomly pick one to succeed.",
                "It includes built-in protection against common locking errors.",
                "It guarantees immediate access to the mutex."
            ],
            "text": "In C++, why is the try_lock() function useful?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To make a variable constant",
                "To prevent garbage collection of the variable",
                "To ensure that changes to the variable are visible to all threads",
                "To make the variable private to a thread",
                "To make the variable faster to access"
            ],
            "text": "In Java, what is the purpose of the volatile keyword?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The priority of a process",
                "A unique identifier for each process in a communicator",
                "The speed of a process",
                "The memory size allocated to a process",
                "The CPU core assignment"
            ],
            "text": "In MPI, what is a \"rank\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A process that handles communication",
                "A group of processes that can communicate with each other",
                "A network connection",
                "A message buffer",
                "A synchronization primitive"
            ],
            "text": "In MPI, what is a communicator?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "start_task()",
                "new_task()",
                "create_task()",
                "schedule_task()",
                "add_task()"
            ],
            "text": "In Python's asyncio module, which function is used to create a new task?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "run()",
                "execute()",
                "perform()",
                "run_until_complete()",
                "run_forever()"
            ],
            "text": "In Python's asyncio module, which function runs the event loop until the future (task) completes?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "fetch()",
                "obtain()",
                "result()",
                "acquire()",
                "get_value()"
            ],
            "text": "In Python's asyncio module, which method of a future object returns the result or raises the exception of the future?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Protects code from exceptions",
                "Protects a coroutine from being cancelled",
                "Shields memory from other tasks",
                "Prevents timeout errors",
                "Hides task exceptions"
            ],
            "text": "In Python's asyncio, what does asyncio.shield() do?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A unit of work assigned to a thread",
                "A wrapper around a coroutine that schedules it to run on the event loop",
                "A synchronous function",
                "A type of future that cannot be cancelled",
                "A debugging object"
            ],
            "text": "In Python's asyncio, what is a Task?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To prioritize tasks",
                "To provide async-safe communication between coroutines",
                "To store event loop references",
                "To queue network requests",
                "To manage thread pools"
            ],
            "text": "In Python's asyncio, what is an asyncio.Queue used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They do the same thing",
                "asyncio.run() starts the event loop and runs a coroutine; create_task() schedules a coroutine in an already running loop",
                "create_task() is deprecated",
                "asyncio.run() is for synchronous code",
                "create_task() starts a new thread"
            ],
            "text": "In Python's asyncio, what is the difference between asyncio.run() and asyncio.create_task()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To collect garbage from async tasks",
                "To merge multiple event loops",
                "To run multiple coroutines concurrently and collect their results",
                "To cancel all running tasks",
                "To synchronize async tasks"
            ],
            "text": "In Python's asyncio, what is the purpose of asyncio.gather()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "ThreadPool",
                "ThreadPoolExecutor",
                "ThreadManager",
                "TaskPool",
                "ConcurrentExecutor"
            ],
            "text": "In Python's concurrent.futures module, which class is used to create a pool of threads?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "stop()",
                "terminate()",
                "interrupt()",
                "cancel()",
                "halt()"
            ],
            "text": "In Python's concurrent.futures module, which method is used to cancel a future that has not started execution?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "fetch()",
                "obtain()",
                "get()",
                "result()",
                "acquire()"
            ],
            "text": "In Python's concurrent.futures module, which method is used to get the result of a future?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "run()",
                "execute()",
                "start()",
                "begin()",
                "launch()"
            ],
            "text": "In Python's multiprocessing module, which method is used to start a new process?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Makes the process run with elevated privileges",
                "Makes the process terminate when the main program exits",
                "Makes the process run in the background",
                "Makes the process immune to signals",
                "Makes the process share memory with other daemons"
            ],
            "text": "In Python's multiprocessing, what does the daemon attribute do when set to True?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "The parent process crashes",
                "The exception is silently ignored",
                "The exception is propagated when join() or get() is called",
                "All child processes are terminated",
                "The exception is logged automatically"
            ],
            "text": "In Python's multiprocessing, what happens if a child process raises an exception?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "map() is for single tasks; apply_async() is for multiple tasks",
                "map() blocks until all results are ready; apply_async() returns immediately",
                "map() is faster; apply_async() is slower",
                "map() is deprecated; apply_async() is the new method",
                "There is no difference"
            ],
            "text": "In Python's multiprocessing, what is the difference between map() and apply_async()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To limit memory usage",
                "To create shared variables",
                "To manage a pool of worker processes for parallel task execution",
                "To store process results",
                "To handle process exceptions"
            ],
            "text": "In Python's multiprocessing, what is the purpose of Pool?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "1",
                "2",
                "no limit",
                "0",
                "depends on the operating system"
            ],
            "text": "In Python's threading module, how many threads can take shared ownership of a Lock while another thread has exclusive ownership of it?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Returns the thread's priority",
                "Returns the thread's current state",
                "Returns whether the thread is still running",
                "Returns the thread's identifier",
                "Returns the thread's exit code"
            ],
            "text": "In Python's threading module, what does the is_alive() method do?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "try_lock() checks whether or not a mutex is already taken without actually locking it.",
                "try_lock() (try_acquire()) will not block execution if the mutex is already taken by another thread.",
                "try_lock() (try_acquire()) will continuously try to lock the mutex if it is already taken by another thread.",
                "lock() (acquire()) returns a boolean value to indicate whether or not it was successful.",
                "lock() (acquire()) can be used only with specific mutex types."
            ],
            "text": "In Python's threading module, what is the difference between the try_lock() (try_acquire() in Python) and regular lock() (acquire() in Python) functions?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "To start a thread",
                "To pause a thread",
                "To stop a thread",
                "To wait for a thread to finish",
                "To notify a thread"
            ],
            "text": "In Python's threading module, what is the purpose of the join() method?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "BackgroundTask",
                "Timer",
                "PeriodicExecutor",
                "IntervalThread",
                "PeriodicTask"
            ],
            "text": "In Python's threading module, which class provides a way to run code periodically in the background?"
        },
        {
            "correctOptionIndex": 4,
            "options": [
                "Lock",
                "Semaphore",
                "Event",
                "Timer",
                "RLock"
            ],
            "text": "In Python's threading module, which class should be used to implement a thread-safe counter?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "wait()",
                "hold()",
                "wait() on a Condition object",
                "sleep()",
                "pause()"
            ],
            "text": "In Python's threading module, which method allows a thread to wait until it is notified?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "rest()",
                "wait()",
                "sleep()",
                "pause()",
                "delay()"
            ],
            "text": "In Python's threading module, which method can be used to put the current thread to sleep for a specified amount of time?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "release()",
                "unlock()",
                "free()",
                "open()",
                "exit()"
            ],
            "text": "In Python's threading module, which method is used to release a lock?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "run()",
                "create()",
                "start()",
                "initiate()",
                "launch()"
            ],
            "text": "In Python's threading module, which method is used to start a new thread?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "Timer",
                "Barrier",
                "Lock",
                "Event",
                "Semaphore"
            ],
            "text": "In Python's threading module, which object can be used to wake up all threads waiting on it?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Barrier",
                "Semaphore",
                "Event",
                "Timer",
                "Lock"
            ],
            "text": "In Python's threading module, which synchronization primitive allows multiple threads to synchronize on a shared resource by acquiring and releasing it?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "wait(); before",
                "wait(); after",
                "notify_all(); after",
                "notify_all(); before",
                "signal(); before"
            ],
            "text": "In Python, a thread that needs to execute a section of code before the barrier should call the Barrier's _____ function _____ executing the code."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Use the Queue module",
                "Use a Lock",
                "Use a Semaphore",
                "Use an Event",
                "Use a Timer"
            ],
            "text": "In Python, how can you ensure a section of code is executed by only one thread at a time?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Creates a new thread",
                "Blocks the entire program",
                "Pauses the coroutine until the awaited operation completes, allowing other coroutines to run",
                "Terminates the coroutine",
                "Raises an exception"
            ],
            "text": "In Python, what does the 'await' keyword do?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To ensure a future never fails",
                "To schedule a coroutine or wrap a future, ensuring it will be executed",
                "To wait for a future to complete",
                "To cancel a future",
                "To chain multiple futures"
            ],
            "text": "In Python, what is asyncio.ensure_future() used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To iterate faster",
                "To iterate over an asynchronous iterator that yields values asynchronously",
                "To run a for loop in a thread",
                "To iterate over futures",
                "To iterate in parallel"
            ],
            "text": "In Python, what is the purpose of async for (async iteration)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To create async variables",
                "To properly manage resources in async code that require setup and cleanup",
                "To convert sync code to async",
                "To handle exceptions in async code",
                "To run code in parallel"
            ],
            "text": "In Python, what is the purpose of async with (async context manager)?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "SharedState",
                "ProcessState",
                "Value or Array",
                "SharedMemory only",
                "GlobalVar"
            ],
            "text": "In Python, which class from the multiprocessing module is used to share state between processes?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Threading, because it has less overhead",
                "Multiprocessing, because it can use multiple CPU cores effectively",
                "Neither, Python cannot handle CPU-bound tasks",
                "Both perform equally well",
                "Threading, because the GIL helps with CPU tasks"
            ],
            "text": "In Python, which is more appropriate for CPU-bound tasks: threading or multiprocessing?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "stop()",
                "terminate()",
                "cancel()",
                "abort()",
                "kill()"
            ],
            "text": "In Python, which method is used to cancel an asyncio Task?"
        },
        {
            "correctOptionIndex": 4,
            "options": [
                "terminate()",
                "kill()",
                "exit()",
                "stop()",
                "None of the above"
            ],
            "text": "In Python, which method is used to stop a thread immediately?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "threading",
                "multiprocessing",
                "asyncio",
                "concurrent",
                "sched"
            ],
            "text": "In Python, which module provides a way to create and manage threads?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "asyncio",
                "threading",
                "multiprocessing",
                "concurrent",
                "sched"
            ],
            "text": "In Python, which module provides support for high-level asynchronous I/O?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "block and wait until the semaphore is available",
                "nothing else",
                "block all other threads waiting on the semaphore",
                "signal another thread waiting to acquire the semaphore",
                "reset the semaphore's counter"
            ],
            "text": "In addition to modifying the counter value, what else does calling the semaphore's release() function do?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "user",
                "application software",
                "operating system",
                "processor hardware",
                "compiler"
            ],
            "text": "In most modern multi-core CPUs, cache coherency is usually handled by the _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "operating system",
                "processor hardware",
                "application software",
                "user",
                "scheduler algorithm"
            ],
            "text": "In most operating systems the _____ determines when each of the threads and processes gets scheduled to execute."
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A mechanism to prevent program termination",
                "A way to share data between processes",
                "Ensuring only one thread can access a critical section at a time",
                "A method to parallelize sequential code",
                "A technique for load balancing"
            ],
            "text": "In the context of concurrent programming, what is \"mutual exclusion\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A thread that is permanently locked",
                "Another name for deadlock",
                "A situation where threads keep changing state in response to each other without making progress",
                "A thread that runs forever",
                "A lock that keeps a thread alive"
            ],
            "text": "In the context of threading, what is a \"livelock\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "more work; more time",
                "same work; less time",
                "more work; less time",
                "more work; same time",
                "less work; same time"
            ],
            "text": "Increasing the number of processors with a fixed problem size per processor leverages weak scaling to accomplish _____ in _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "more work; less time",
                "same work; less time",
                "more work; same time",
                "more work; more time",
                "less work; more time"
            ],
            "text": "Increasing the number of processors with a fixed total problem size leverages strong scaling to accomplish _____ in _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "in parallel",
                "concurrently",
                "concurrently or in parallel",
                "sequentially"
            ],
            "text": "It is possible for two tasks to execute _____ using a single-core processor."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "number of tasks a program executes in a set time",
                "speed at which a program executes a set number of tasks",
                "scale of problems a program can tackle",
                "all of these answers",
                "efficiency of memory usage"
            ],
            "text": "Parallel computing primarily enhances the _____."
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "are simpler to communicate between",
                "are considered more \"lightweight\"",
                "are faster to switch between",
                "require more overhead to create"
            ],
            "text": "Processes _____ than threads."
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "process ID number",
                "CPU core",
                "process name",
                "number of threads",
                "memory address"
            ],
            "text": "The operating system assigns each process a unique _____."
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Plan, Code, Analyze, Monitor",
                "Partitioning, Communication, Agglomeration, Mapping",
                "Prepare, Compute, Aggregate, Merge",
                "Problem, Compute, Analyze, Measure",
                "Partition, Combine, Assign, Map"
            ],
            "text": "What are the four stages of Foster's parallel design methodology (PCAM)?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "It's slower than message passing",
                "It can only share strings",
                "It requires explicit synchronization and can lead to race conditions if not managed properly",
                "It only works on Linux",
                "It's deprecated in Python 3"
            ],
            "text": "What are the limitations of shared memory in multiprocessing?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Bugs in the code",
                "Using too many threads",
                "Different possible interleavings of thread execution depending on scheduling",
                "Using different compilers",
                "Running on different hardware"
            ],
            "text": "What causes \"non-deterministic\" behavior in concurrent programs?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Speedup that exceeds expectations",
                "Speedup greater than the number of processors (greater than linear), often due to cache effects",
                "The maximum possible speedup",
                "Speedup using special hardware",
                "A theoretical impossibility"
            ],
            "text": "What does \"superlinear speedup\" mean?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A thread that cannot crash",
                "A thread that runs in a protected environment",
                "Code that can be safely executed by multiple threads concurrently without data corruption",
                "A thread that has priority over others",
                "A thread that is immune to deadlocks"
            ],
            "text": "What does \"thread-safe\" mean?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Broadcasts a message to all computers in a network",
                "Sends data from one process (root) to all other processes in the communicator",
                "Broadcasts an error message",
                "Creates new processes",
                "Collects data from all processes"
            ],
            "text": "What does MPI_Bcast() do?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "Mutual exclusion, hold-and-wait, no preemption, and circular wait",
                "Mutual exclusion alone",
                "Only circular wait and preemption",
                "Only preemption and no waiting",
                "Only resource abundance"
            ],
            "text": "What does a deadlock require to occur?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "Stop subdividing the current problem and solve it.",
                "Recursively solve a set of smaller subproblems.",
                "Solve all of the subproblems that have been created.",
                "Divide the problem into two smaller subproblems.",
                "Return the initial problem unchanged."
            ],
            "text": "What does a divide-and-conquer algorithm do when it reaches the base case?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "A parallelized version of the program will execute faster than the sequential version.",
                "A parallelized version of the program will execute in the same amount of time as the sequential version.",
                "The work-to-span ratio cannot be less than one.",
                "A parallelized version of the program will execute slower than the sequential version.",
                "The program has no parallelism opportunities."
            ],
            "text": "What does a work-to-span ratio less than one indicate?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "They are identical",
                "asyncio.sleep() is faster",
                "asyncio.sleep() yields control to the event loop; time.sleep() blocks the entire thread",
                "asyncio.sleep() only works in threads",
                "time.sleep() is asynchronous"
            ],
            "text": "What does asyncio.sleep() do differently from time.sleep()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "the maximum number of parallel processors the program can utilize",
                "how well the parallel program is performing compared to its sequential implementation",
                "how well the parallel processing resources are being utilized",
                "the optimal number of parallel processors for the program to use",
                "the minimum number of processors needed"
            ],
            "text": "What does calculating a program's efficiency (speedup divided by number of parallel processors) provide an indicator of?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "always decrement the counter's value",
                "if the counter is positive, increment its value",
                "always increment the counter's value",
                "if the counter is positive, decrement its value",
                "reset the counter value"
            ],
            "text": "What does the semaphore's acquire() function do to the counter value?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "if the counter is positive, decrement its value",
                "if the counter is positive, increment its value",
                "always increment the counter's value",
                "always decrement the counter's value",
                "reset the counter to zero"
            ],
            "text": "What does the semaphore's release() function do to the counter value?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "The thread restarts from the beginning",
                "Nothing, the second call is ignored",
                "A RuntimeError is raised",
                "The thread runs twice as fast",
                "The second call blocks until the first run completes"
            ],
            "text": "What happens if you call start() twice on the same Thread object in Python?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "It runs in the background",
                "An error is raised immediately",
                "The coroutine never executes and you get a warning",
                "It runs synchronously",
                "The program crashes"
            ],
            "text": "What happens if you forget to await a coroutine?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are closed in the child process",
                "They are duplicated in the child process",
                "They become invalid",
                "They are shared with read-only access",
                "They point to different files"
            ],
            "text": "What happens to file descriptors when a process is forked?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "The thread is terminated",
                "The thread runs at reduced speed",
                "The thread is waiting for a resource and cannot proceed",
                "The thread is prevented from accessing memory",
                "The thread is locked by another thread"
            ],
            "text": "What happens when a thread is \"blocked\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "It is silently ignored",
                "It crashes the entire program",
                "It propagates to the caller when the coroutine is awaited",
                "It is logged automatically",
                "The coroutine restarts"
            ],
            "text": "What happens when an exception is raised inside a coroutine?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "The function runs synchronously",
                "An error is raised immediately",
                "A coroutine object is returned but the code inside doesn't execute",
                "The function runs in a background thread",
                "The function runs but results are discarded"
            ],
            "text": "What happens when you call an async function without using 'await'?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A random number used in algorithms",
                "The fraction of a program that cannot be parallelized",
                "The number of processors needed",
                "The maximum speedup possible",
                "The efficiency rating"
            ],
            "text": "What is \"Amdahl's number\" or the sequential fraction in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Graphics processing for games",
                "Using graphics processing units for general-purpose computing tasks",
                "A graphics programming language",
                "A type of GPU architecture",
                "Graphics debugging"
            ],
            "text": "What is \"GPGPU\" computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A metric for memory usage",
                "A metric to measure the serial fraction of a parallel program empirically",
                "A metric for network latency",
                "A metric for cache efficiency",
                "A metric for power consumption"
            ],
            "text": "What is \"Karp-Flatt metric\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "How complex the math operations are",
                "The ratio of floating-point operations to bytes of data moved from memory",
                "The speed of arithmetic operations",
                "The number of arithmetic units",
                "A measure of CPU capability"
            ],
            "text": "What is \"arithmetic intensity\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "An operation that uses atomic energy",
                "A very small operation",
                "An operation that completes in a single step without interruption",
                "An operation that cannot fail",
                "An operation that is very fast"
            ],
            "text": "What is \"atomic operation\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Memory pressure from async operations",
                "A mechanism to slow down producers when consumers can't keep up",
                "CPU pressure from too many coroutines",
                "Network congestion",
                "A type of error handling"
            ],
            "text": "What is \"backpressure\" in async programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Breaking code into blocks",
                "Dividing data into contiguous blocks assigned to different processors",
                "A memory management technique",
                "A compilation strategy",
                "A debugging technique"
            ],
            "text": "What is \"block decomposition\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Predicting which branch of code to compile",
                "CPU technique to guess which way a branch will go to continue executing without waiting",
                "A debugging technique",
                "Predicting memory access patterns",
                "A parallel execution technique"
            ],
            "text": "What is \"branch prediction\" in modern CPUs?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Linking caches together",
                "The number of cache locations where a memory block can be placed",
                "The speed of cache access",
                "The association between cache levels",
                "Cache sharing between cores"
            ],
            "text": "What is \"cache associativity\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Deliberately destroying cache data",
                "Repeated cache misses when data is constantly evicted and reloaded",
                "A cache optimization technique",
                "An attack on cache memory",
                "A debugging process"
            ],
            "text": "What is \"cache thrashing\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A situation where callbacks run too fast",
                "Deeply nested callbacks that make code hard to read; async/await provides a more linear, readable syntax",
                "An error that occurs in callback functions",
                "A memory leak caused by callbacks",
                "Callbacks that never execute"
            ],
            "text": "What is \"callback hell\" and how does async/await help address it?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Making algorithms simpler",
                "Combining fine-grained tasks into larger tasks to reduce overhead",
                "Increasing granularity of data",
                "A debugging technique",
                "Reducing precision of calculations"
            ],
            "text": "What is \"coarsening\" in parallel algorithm design?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "I/O performed by all processes",
                "Coordinated I/O operations where multiple processes combine their I/O requests for efficiency",
                "Writing to a shared file",
                "Reading from the network",
                "Debugging I/O operations"
            ],
            "text": "What is \"collective I/O\" in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The bandwidth of the network",
                "The time spent sending and receiving messages between processors instead of computing",
                "The complexity of the communication protocol",
                "The cost of communication hardware",
                "The error rate in communication"
            ],
            "text": "What is \"communication overhead\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The ratio of network to CPU usage",
                "The ratio of time spent communicating to time spent computing, indicating parallel efficiency",
                "The number of messages per computation",
                "A hardware specification",
                "A debugging metric"
            ],
            "text": "What is \"communication to computation ratio\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Multiple event loops working together",
                "Tasks voluntarily yield control at await points, allowing other tasks to run",
                "Threads cooperating to share memory",
                "Processes sharing CPU time",
                "A type of load balancing"
            ],
            "text": "What is \"cooperative multitasking\" in the context of asyncio?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A technique to copy processes faster",
                "An optimization where memory is shared until either process writes to it",
                "A way to write to multiple processes simultaneously",
                "A file copying technique for processes",
                "A debugging feature"
            ],
            "text": "What is \"copy-on-write\" in the context of process forking?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Repeating decomposition",
                "Distributing data in a round-robin fashion among processors",
                "A circular data structure",
                "A scheduling algorithm",
                "A memory recycling technique"
            ],
            "text": "What is \"cyclic decomposition\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Dividing data for backup",
                "Dividing data among processors so each works on a subset",
                "Creating data partitions on disk",
                "Separating data from code",
                "A security technique"
            ],
            "text": "What is \"data partitioning\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Executing data operations in order",
                "Converting data structures to a format that can be transmitted between processes",
                "Prioritizing data transfers",
                "Compressing data",
                "Encrypting data"
            ],
            "text": "What is \"data serialization\" in distributed computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Execution that is predetermined by the OS",
                "Execution that produces the same result given the same inputs, regardless of scheduling",
                "Execution that uses a fixed amount of memory",
                "Execution that runs in constant time",
                "Execution that cannot be interrupted"
            ],
            "text": "What is \"deterministic\" execution in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Breaking down the problem domain into smaller domains",
                "Dividing a computational domain among multiple processors, each handling a subdomain",
                "Decomposing complex functions into simpler ones",
                "Separating data from code",
                "Breaking up network domains"
            ],
            "text": "What is \"domain decomposition\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Splitting a program into different domains",
                "Dividing a problem based on the data domain, distributing data among processors",
                "Separating the problem domain from the solution domain",
                "A network partitioning technique",
                "Decomposing function domains"
            ],
            "text": "What is \"domain decomposition\" in parallel design?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A computation that is too simple",
                "A computation that can be easily divided into independent tasks with little or no communication needed",
                "A poorly designed parallel algorithm",
                "A computation that embarrasses other algorithms",
                "A computation with many bugs"
            ],
            "text": "What is \"embarrassingly parallel\" computation?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Consistency that takes forever",
                "A model where replicas will eventually converge to the same value if no new updates occur",
                "Inconsistent data",
                "Real-time consistency",
                "A debugging concept"
            ],
            "text": "What is \"eventual consistency\" in distributed systems?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Sharing invalid data between cores",
                "Performance degradation when threads modify different variables that happen to be on the same cache line",
                "Incorrect data sharing due to bugs",
                "Sharing memory that shouldn't be shared",
                "A security vulnerability"
            ],
            "text": "What is \"false sharing\" in multi-core systems?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Breaking functions into smaller functions",
                "Dividing a problem based on the different operations (functions) that need to be performed",
                "Decomposing functional requirements",
                "A debugging technique",
                "Removing unnecessary functions"
            ],
            "text": "What is \"functional decomposition\" in parallel design?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A graphics algorithm",
                "Partitioning a problem's data domain into regular geometric shapes (like tiles or blocks)",
                "A pattern recognition technique",
                "A compression algorithm",
                "A mathematical decomposition method"
            ],
            "text": "What is \"geometric decomposition\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Time when the computer is in sleep mode",
                "Time when a processor is not doing useful work while waiting for data or synchronization",
                "Time between program runs",
                "Time to initialize the system",
                "Time to shut down the system"
            ],
            "text": "What is \"idle time\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Parallel execution of programs",
                "CPU technique of executing multiple instructions simultaneously within a single core",
                "Parallelism between different programming languages",
                "A compiler optimization",
                "Parallel instruction decoding"
            ],
            "text": "What is \"instruction-level parallelism\" (ILP)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Equal efficiency across all processors",
                "The rate at which problem size must grow with the number of processors to maintain constant efficiency",
                "A measure of energy efficiency",
                "The efficiency of I/O operations",
                "A debugging metric"
            ],
            "text": "What is \"isoefficiency\" in the context of parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Hiding network delays from users",
                "Overlapping communication with computation to reduce the impact of communication delays",
                "Reducing latency through compression",
                "A debugging technique",
                "Caching frequently used data"
            ],
            "text": "What is \"latency hiding\" in distributed computing?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Balancing memory usage",
                "Balancing network traffic",
                "Distributing work evenly across processors to maximize efficiency",
                "Balancing power consumption",
                "Balancing data storage"
            ],
            "text": "What is \"load balancing\" in distributed computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "An error in load balancing algorithms",
                "When work is unevenly distributed among processors, causing some to wait while others are busy",
                "When the load is too heavy for processors",
                "A network bandwidth issue",
                "A memory allocation problem"
            ],
            "text": "What is \"load imbalance\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Programming without any synchronization",
                "Designing algorithms that don't use traditional locks but still ensure thread safety",
                "Programming that automatically handles locking",
                "Single-threaded programming",
                "Programming that ignores race conditions"
            ],
            "text": "What is \"lock-free\" programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Making loops run faster",
                "Converting sequential loop iterations to run in parallel across multiple processors",
                "Unrolling loops",
                "Optimizing loop conditions",
                "Removing loops from code"
            ],
            "text": "What is \"loop parallelization\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The width of memory chips",
                "The rate at which data can be read from or written to memory",
                "The range of memory addresses",
                "The number of memory channels",
                "The size of memory"
            ],
            "text": "What is \"memory bandwidth\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The size of memory",
                "The time delay between requesting data from memory and receiving it",
                "The speed of memory",
                "The age of memory hardware",
                "Memory allocation time"
            ],
            "text": "What is \"memory latency\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A file stored in memory instead of disk",
                "A technique where a file is mapped to memory allowing multiple processes to share data",
                "A compressed file format",
                "A backup of memory to disk",
                "An encrypted file system"
            ],
            "text": "What is \"memory-mapped file\" and how is it used in IPC?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Adding labels for debugging",
                "Integer values used to distinguish different types of messages between the same pair of processes",
                "Compressing message headers",
                "Logging message traffic",
                "Encrypting messages"
            ],
            "text": "What is \"message tagging\" in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Executing code in random order",
                "CPU technique of executing instructions in an order different from the program order to maximize efficiency",
                "Executing code without compilation",
                "A bug in program execution",
                "Executing instructions backwards"
            ],
            "text": "What is \"out-of-order execution\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The processor that owns code executes it",
                "The processor that owns a piece of data is responsible for computing its values",
                "A licensing rule",
                "A security policy",
                "A debugging principle"
            ],
            "text": "What is \"owner computes\" rule?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "How efficiently parallel code is written",
                "The ratio of speedup to the number of processors (speedup/P), measuring resource utilization",
                "The energy efficiency of parallel computing",
                "The memory efficiency of parallel programs",
                "The ratio of communication to computation"
            ],
            "text": "What is \"parallel efficiency\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The memory used by parallel programs",
                "Extra time spent on coordination, communication, and synchronization that wouldn't exist in sequential execution",
                "The cost of parallel hardware",
                "The complexity of parallel code",
                "The power consumption of parallel systems"
            ],
            "text": "What is \"parallel overhead\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Running the same code on different systems",
                "Achieving good performance across different hardware architectures without major code changes",
                "Porting code between languages",
                "Moving performance data between systems",
                "Portable performance monitoring"
            ],
            "text": "What is \"performance portability\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "When low priority tasks run before high priority ones intentionally",
                "When a high-priority task waits for a low-priority task holding a needed resource",
                "When all tasks have the same priority",
                "When priority values are inverted in memory",
                "A debugging technique"
            ],
            "text": "What is \"priority inversion\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Priority determines which process starts first",
                "Higher priority processes get more CPU time and are scheduled more frequently",
                "Priority determines how much memory a process gets",
                "Priority only affects I/O operations",
                "All processes have the same priority"
            ],
            "text": "What is \"process priority\" and how does it affect scheduling?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Creating user profiles",
                "Measuring and analyzing where a program spends its time to identify bottlenecks",
                "Profiling hardware capabilities",
                "Creating performance profiles for different users",
                "A security analysis technique"
            ],
            "text": "What is \"profiling\" in the context of parallel performance?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A mathematical technique",
                "A decomposition strategy where a problem is repeatedly divided into subproblems (like in divide-and-conquer)",
                "A pattern for recursive functions",
                "A debugging technique",
                "A memory management strategy"
            ],
            "text": "What is \"recursive decomposition\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Making code smaller",
                "Combining multiple values into a single value using an operation (like sum or max)",
                "Reducing memory usage",
                "Simplifying parallel code",
                "Reducing the number of processors"
            ],
            "text": "What is \"reduction\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Analyzing code size",
                "Studying how performance changes as the number of processors or problem size increases",
                "Analyzing hardware capabilities",
                "Measuring memory scalability",
                "A type of security analysis"
            ],
            "text": "What is \"scalability analysis\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Executing code that might not be needed",
                "CPU technique of executing instructions before knowing if they're needed, rolling back if wrong",
                "A debugging mode",
                "Parallel execution of speculative code paths",
                "A compiler optimization"
            ],
            "text": "What is \"speculative execution\" in modern CPUs?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Untested parallel algorithms",
                "Executing tasks in parallel before knowing if they will be needed, discarding results if not",
                "Random parallel execution",
                "Debugging parallel code",
                "Hypothetical parallelism"
            ],
            "text": "What is \"speculative parallelism\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Static is for static data; dynamic is for changing data",
                "Static assigns work upfront; dynamic adjusts work distribution during runtime",
                "Static is faster; dynamic is slower",
                "They are the same concept",
                "Static uses more memory"
            ],
            "text": "What is \"static vs dynamic load balancing\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Increasing both workload size and processor count together",
                "Keeping workload size fixed while increasing the number of processors to see speedup",
                "Reducing workload size while reducing processor count",
                "Measuring performance by decreasing processors gradually",
                "Scaling only memory bandwidth"
            ],
            "text": "What is \"strong scaling\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The cost of buying synchronization hardware",
                "Time spent waiting at synchronization points (barriers, locks) instead of computing",
                "The complexity of synchronization code",
                "Network synchronization delays",
                "Clock synchronization time"
            ],
            "text": "What is \"synchronization overhead\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A security vulnerability",
                "A load balancing technique where idle processors steal tasks from busy processors' queues",
                "Removing tasks from the queue",
                "A type of race condition",
                "A debugging technique"
            ],
            "text": "What is \"task stealing\" or \"work stealing\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A thread that uses too much memory",
                "A thread that runs out of work",
                "A thread that cannot access resources because other threads monopolize them",
                "A thread that has been terminated",
                "A thread with no input data"
            ],
            "text": "What is \"thread starvation\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Storage that is locked by a thread",
                "Memory that is unique to each thread and not shared with other threads",
                "Temporary storage for thread data",
                "Storage located near the CPU for threads",
                "Encrypted storage for sensitive thread data"
            ],
            "text": "What is \"thread-local storage\" (TLS)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Keeping workload fixed while reducing processors",
                "Increasing workload size proportionally with processor count to keep work per processor constant",
                "Running fewer processors for the same workload",
                "Decreasing workload as processors increase",
                "Ignoring communication costs when scaling"
            ],
            "text": "What is \"weak scaling\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Writing data through multiple caches",
                "Writing data to both cache and main memory simultaneously",
                "A faster writing technique",
                "Writing through a buffer",
                "A debugging mode"
            ],
            "text": "What is \"write-through\" cache policy?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are the same law",
                "Gustafson's Law considers that problem size can grow with processors (weak scaling), showing more optimistic speedup potential",
                "Gustafson's Law is for single processors",
                "Gustafson's Law is deprecated",
                "Gustafson's Law applies only to shared memory"
            ],
            "text": "What is Gustafson's Law and how does it differ from Amdahl's Law?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A reduce operation that fails silently",
                "A reduce operation where all processes get the result, not just the root",
                "A faster version of MPI_Reduce",
                "A reduce that works on all data types",
                "An asynchronous reduce operation"
            ],
            "text": "What is MPI_Allreduce()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To broadcast to all processes",
                "To send distinct data from each process to every other process (complete exchange)",
                "To reduce data from all processes",
                "To synchronize all processes",
                "To gather data at all processes"
            ],
            "text": "What is MPI_Alltoall() used for?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To block messages from other processes",
                "To limit communication bandwidth",
                "To synchronize all processes in a communicator; no process proceeds until all have reached the barrier",
                "To create a new communicator",
                "To handle errors"
            ],
            "text": "What is MPI_Barrier() used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To rank processes by speed",
                "To get the unique identifier (rank) of the calling process in a communicator",
                "To assign priority to processes",
                "To count the number of ranks",
                "To reorder process rankings"
            ],
            "text": "What is MPI_Comm_rank() used for?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To get the size of a message",
                "To get memory size",
                "To get the total number of processes in a communicator",
                "To get the buffer size",
                "To get the network bandwidth"
            ],
            "text": "What is MPI_Comm_size() used for?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To reduce the number of processes",
                "To compress message size",
                "To combine data from all processes using an operation (like sum) and store result at root process",
                "To reduce memory usage",
                "To reduce communication overhead"
            ],
            "text": "What is MPI_Reduce() used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To scan for errors in MPI code",
                "To perform a prefix reduction (each process receives partial result from preceding processes)",
                "To scan network for available nodes",
                "To check message integrity",
                "To scan memory for leaks"
            ],
            "text": "What is MPI_Scan() used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To send and receive to the same process",
                "To simultaneously send to one process and receive from another, avoiding potential deadlock",
                "To send large messages",
                "To send messages reliably",
                "To send encrypted messages"
            ],
            "text": "What is MPI_Sendrecv() used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A cache coherence protocol",
                "A memory architecture where access time depends on the memory's proximity to a processor",
                "A type of GPU memory",
                "A network topology",
                "A data compression scheme"
            ],
            "text": "What is NUMA (Non-Uniform Memory Access)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A programming language",
                "A parallel processing technique where one instruction operates on multiple data elements simultaneously",
                "A type of memory architecture",
                "A network protocol",
                "A debugging tool"
            ],
            "text": "What is SIMD (Single Instruction, Multiple Data)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A mathematical concept only",
                "A virtual process arrangement in a grid pattern (1D, 2D, 3D, etc.)",
                "A type of network cable layout",
                "A memory organization scheme",
                "A debugging visualization"
            ],
            "text": "What is a \"Cartesian topology\" in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A group of messages",
                "An operation that must be called by all processes in a communicator",
                "A shared variable",
                "A type of buffer",
                "A process group"
            ],
            "text": "What is a \"collective\" in MPI terminology?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "An operation that compares two values and swaps them",
                "An atomic operation that updates a value only if it matches an expected value",
                "A sorting algorithm",
                "A memory allocation technique",
                "A debugging operation"
            ],
            "text": "What is a \"compare-and-swap\" (CAS) operation?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A workload bound to a specific computer",
                "A workload whose performance is limited by CPU speed, not memory or I/O",
                "A workload that cannot be parallelized",
                "A workload that uses extensive computation",
                "A workload limited by network speed"
            ],
            "text": "What is a \"compute-bound\" workload?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Switching between different programming languages",
                "The process of saving and restoring the state of a thread/process so another can run",
                "Switching between user mode and kernel mode",
                "Changing the priority of a thread",
                "Switching between different memory regions"
            ],
            "text": "What is a \"context switch\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "The main function of a program",
                "A section of code that runs very fast",
                "A section of code that accesses shared resources and must not be executed by multiple threads simultaneously",
                "The initialization code of a program",
                "A section that handles errors"
            ],
            "text": "What is a \"critical section\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A program that stops responding",
                "A situation where two or more threads are waiting for each other to release resources, causing all to be blocked indefinitely",
                "A memory leak in threaded applications",
                "A situation where a thread runs too fast",
                "A crashed program"
            ],
            "text": "What is a \"deadlock\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A graph of software dependencies",
                "A graph showing which tasks depend on others, determining what can run in parallel",
                "A debugging visualization",
                "A network topology",
                "A memory layout diagram"
            ],
            "text": "What is a \"dependency graph\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A cell that stores deleted data",
                "Boundary data copied from neighboring processes to enable local computation",
                "A debugging technique",
                "A cell that is not used",
                "An error handling mechanism"
            ],
            "text": "What is a \"ghost cell\" or \"halo exchange\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A model of physical RAM",
                "Rules defining how memory operations appear to execute relative to each other across threads",
                "A diagram of memory layout",
                "A technique for memory allocation",
                "A debugging tool for memory leaks"
            ],
            "text": "What is a \"memory model\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A workload limited by memory size",
                "A workload whose performance is limited by memory bandwidth or latency, not CPU speed",
                "A workload that uses all memory",
                "A workload that cannot use cache",
                "A workload that is restricted to certain memory regions"
            ],
            "text": "What is a \"memory-bound\" workload?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A debugging tool for threads",
                "A synchronization construct that combines mutex and condition variables",
                "A thread that watches other threads",
                "A process that monitors system resources",
                "A logging mechanism for threads"
            ],
            "text": "What is a \"monitor\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A pipe that has been given a string name",
                "A pipe that exists as a file in the filesystem and can be used between unrelated processes",
                "A faster type of pipe",
                "A pipe used only for text data",
                "A pipe that only works on Windows"
            ],
            "text": "What is a \"named pipe\" (FIFO)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A scheduling algorithm",
                "A one-way or two-way communication channel between processes",
                "A memory allocation technique",
                "A type of process pool",
                "A debugging tool"
            ],
            "text": "What is a \"pipe\" in the context of multiprocessing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Checking strings for prefixes",
                "An operation that computes all prefix sums/products of a sequence (running totals)",
                "A string search algorithm",
                "A sorting operation",
                "A memory allocation technique"
            ],
            "text": "What is a \"prefix sum\" (or \"scan\") operation?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A pool of worker processes",
                "A collection of related processes that can receive signals together",
                "Processes sharing the same memory",
                "Processes on the same CPU core",
                "A debugging concept only"
            ],
            "text": "What is a \"process group\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A lock that prevents process creation",
                "A synchronization primitive to ensure only one process accesses a resource at a time",
                "A security feature for processes",
                "A lock on process termination",
                "A debugging tool"
            ],
            "text": "What is a \"process lock\" (multiprocessing.Lock)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The physical arrangement of computers",
                "A virtual arrangement of processes that reflects the communication pattern of an application",
                "The network topology",
                "The memory layout",
                "The scheduling order"
            ],
            "text": "What is a \"process topology\" in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A type of process",
                "A synchronization primitive that controls access to shared resources using a counter",
                "A signal sent between processes",
                "A memory region shared between processes",
                "A process priority mechanism"
            ],
            "text": "What is a \"semaphore\" in the context of multiprocessing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A lock that permanently holds a thread in place",
                "A lock where a thread continuously checks (spins) until the lock becomes available, useful for short wait times",
                "A lock that rotates between threads automatically",
                "A lock that prevents threads from running too fast",
                "A lock used exclusively for disk I/O operations"
            ],
            "text": "What is a \"spinlock\" and when is it useful?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A template for parallel programs",
                "A pattern where each element's new value depends on a fixed pattern of neighboring elements",
                "A debugging tool",
                "A type of load balancing",
                "A communication protocol"
            ],
            "text": "What is a \"stencil\" pattern in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A processor that handles graphics",
                "A processor designed to perform the same operation on multiple data elements simultaneously",
                "A processor for mathematical calculations only",
                "A processor with multiple cores",
                "A processor for vector graphics"
            ],
            "text": "What is a \"vector processor\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Writing data back to the program",
                "Writing modified data to main memory only when the cache line is evicted",
                "Undoing write operations",
                "A backup mechanism",
                "Writing data immediately to disk"
            ],
            "text": "What is a \"write-back\" cache policy?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A process that has crashed",
                "A process that runs slowly",
                "A process that has completed execution but still has an entry in the process table",
                "A process that consumes too much memory",
                "A process that cannot be terminated"
            ],
            "text": "What is a \"zombie process\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Running operating system code",
                "Managing file systems",
                "Parallel processing of many similar operations (high throughput)",
                "Single-threaded performance",
                "Memory management"
            ],
            "text": "What is a GPU (Graphics Processing Unit) architecture optimized for?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Processes share memory by default",
                "Processes are faster to create",
                "Processes provide better isolation and fault tolerance",
                "Processes can run on a single core only",
                "Processes don't require synchronization"
            ],
            "text": "What is a key advantage of using processes over threads?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Processes always share the same address space",
                "Processes have separate address spaces, providing stronger isolation",
                "Processes cannot communicate with each other",
                "Processes never incur context-switch overhead",
                "Processes must run on different machines"
            ],
            "text": "What is a key characteristic of processes compared to threads?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Blocking I/O will make coroutines run faster",
                "Blocking calls can freeze the event loop, preventing other coroutines from running",
                "Blocking I/O is automatically converted to non-blocking by asyncio",
                "Blocking I/O always raises an exception in async code",
                "Blocking I/O cannot occur in async programs"
            ],
            "text": "What is a potential pitfall when mixing blocking I/O with an async event loop?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Replication always reduces latency",
                "Replication improves availability and read performance but can increase consistency overhead",
                "Replication removes the need for fault tolerance",
                "Replication eliminates the need for synchronization",
                "Replication only benefits write-heavy workloads"
            ],
            "text": "What is a primary trade-off when using replication in distributed systems?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To signal task completion",
                "To limit the number of concurrent coroutines accessing a resource",
                "To prioritize async tasks",
                "To handle timeouts",
                "To manage memory"
            ],
            "text": "What is a semaphore used for in asyncio?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Single long-running task",
                "Tasks requiring exclusive hardware access",
                "Many short-lived tasks to amortize creation overhead",
                "Tasks that must run sequentially",
                "Tasks that cannot be parallelized"
            ],
            "text": "What is a thread pool best suited for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A generator that runs faster",
                "A generator function defined with async def that yields values asynchronously",
                "A tool for generating async code",
                "A class for creating coroutines",
                "A debugging tool"
            ],
            "text": "What is an \"async generator\" in Python?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "high computation-to-communication ratio",
                "poor load balancing",
                "low computation-to-communication ratio",
                "good load-balancing",
                "reduced memory overhead"
            ],
            "text": "What is an advantage of using coarse-grained parallelism with a small number of large tasks?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "high computation-to-communication ratio",
                "poor load balancing",
                "low computation-to-communication ratio",
                "good load-balancing",
                "reduced synchronization overhead"
            ],
            "text": "What is an advantage of using fine-grained parallelism with a large number of small tasks?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A loop that waits for user events",
                "A mechanism that runs and coordinates asynchronous tasks by scheduling and executing them",
                "A loop that processes network events only",
                "A debugging tool for async code",
                "A type of infinite loop"
            ],
            "text": "What is an event loop in asynchronous programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To check if the event loop is running",
                "To allow coroutines to wait for some condition to become true",
                "To set conditions on task execution",
                "To debug async code",
                "To check network conditions"
            ],
            "text": "What is asyncio.Condition used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Reading files asynchronously",
                "Reading data from a stream (like a network connection) asynchronously",
                "Reading from stdin",
                "Reading configuration",
                "Streaming video data"
            ],
            "text": "What is asyncio.StreamReader used for?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A measure of cache speed",
                "Ensuring that all caches in a multiprocessor system have consistent copies of shared data",
                "The size of the cache",
                "The organization of cache memory",
                "A cache optimization technique"
            ],
            "text": "What is cache coherency?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Communication between two processes",
                "Communication operations that involve all processes in a communicator",
                "Communication over the network",
                "Communication using shared memory",
                "Communication between different MPI programs"
            ],
            "text": "What is collective communication in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Running threads at hyper speed",
                "A technique that allows a single CPU core to execute multiple threads by sharing core resources",
                "A type of multi-core processor",
                "Threading across multiple computers",
                "A debugging technique"
            ],
            "text": "What is hyperthreading (simultaneous multithreading)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Communication between threads in the same process",
                "Mechanisms that allow processes to exchange data and signals",
                "Communication between CPUs",
                "Network communication between computers",
                "Communication between the OS and processes"
            ],
            "text": "What is inter-process communication (IPC)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The amount of memory available",
                "The rate at which data can be read from or written to memory",
                "The delay in accessing memory",
                "The size of the CPU cache",
                "The number of memory channels"
            ],
            "text": "What is memory bandwidth?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Running identical tasks on identical data",
                "Randomly assigning tasks to processors",
                "Organizing tasks into stages where each stage processes data and passes it to the next",
                "Duplicating the same stage across all processors",
                "Splitting each task into unrelated subtasks"
            ],
            "text": "What is pipeline parallelism?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "When a low-priority thread always preempts high-priority threads",
                "When a low-priority thread holds a resource needed by a higher-priority thread, blocking it",
                "When thread priorities are randomly shuffled",
                "When all threads run at the same priority",
                "When a thread's priority increases without reason"
            ],
            "text": "What is priority inversion?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A measure of how well processes work together",
                "The ability to bind a process to specific CPU cores",
                "The memory sharing between processes",
                "The priority level of a process",
                "The relationship between parent and child processes"
            ],
            "text": "What is process affinity?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Replicating the same data to multiple nodes",
                "Partitioning data horizontally across nodes to scale writes and storage",
                "Compressing data before storage",
                "Encrypting data across nodes",
                "Caching data at the edge only"
            ],
            "text": "What is sharding?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A database model",
                "A programming model where all processors run the same program but on different data",
                "A graphics processing model",
                "A network protocol",
                "A memory model"
            ],
            "text": "What is the \"SPMD\" (Single Program Multiple Data) model?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A storage pattern",
                "A pattern where a pool of workers pulls tasks from a shared queue, enabling dynamic load balancing",
                "A debugging technique",
                "A network pattern",
                "A memory allocation pattern"
            ],
            "text": "What is the \"bag of tasks\" or \"work queue\" pattern?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A model for bulk data processing",
                "A model where computation proceeds in supersteps with computation, communication, and synchronization phases",
                "A synchronous communication protocol",
                "A hardware architecture",
                "A debugging framework"
            ],
            "text": "What is the \"bulk synchronous parallel\" (BSP) model?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Parallel programs being less efficient",
                "As you add more processors, efficiency typically decreases even as speedup increases",
                "Sequential programs being more efficient",
                "A bug in efficiency calculations",
                "The cost of efficiency optimizations"
            ],
            "text": "What is the \"efficiency paradox\" in parallel computing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A model for database operations",
                "A pattern where a task forks into multiple parallel subtasks, which later join back",
                "A model for file operations",
                "A network connection pattern",
                "A memory allocation model"
            ],
            "text": "What is the \"fork-join\" model?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A debugging concept",
                "A guarantee that one operation's effects are visible to another operation",
                "The order in which code is written",
                "The order in which functions are called",
                "A compilation order constraint"
            ],
            "text": "What is the \"happens-before\" relationship?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A debugging pattern",
                "A pattern where one process (master) distributes work to multiple worker processes and collects results",
                "A pattern for handling errors",
                "A network communication pattern",
                "A memory management pattern"
            ],
            "text": "What is the \"master-worker\" (or \"master-slave\") pattern in parallel programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A physical limit on memory size",
                "The growing disparity between CPU speed and memory access speed",
                "A security barrier for memory",
                "A debugging challenge",
                "A memory corruption issue"
            ],
            "text": "What is the \"memory wall\" problem?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A pattern for data storage",
                "A pattern where tasks are arranged in stages, with output of one stage becoming input of the next",
                "A pattern for network communication",
                "A debugging pattern",
                "A memory access pattern"
            ],
            "text": "What is the \"pipeline\" pattern in parallel programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A model for ceiling height calculations",
                "A visual performance model that shows the upper bound on performance based on compute and memory bandwidth",
                "A model for network topology",
                "A hardware architecture model",
                "A cost estimation model"
            ],
            "text": "What is the \"roofline model\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "How large the program can grow",
                "How well performance improves as more processors are added",
                "How many features the program has",
                "The maximum number of processors it can use",
                "The size of problems it can solve"
            ],
            "text": "What is the \"scalability\" of a parallel program?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Too many threads accessing memory at once",
                "Many waiting threads all being woken up when only one can proceed, causing contention",
                "Threads creating too many child threads",
                "A memory leak caused by threads",
                "Threads consuming too much CPU"
            ],
            "text": "What is the \"thundering herd\" problem in threading?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A bottleneck in the CPU",
                "The limitation of having a single path between CPU and memory for both instructions and data",
                "A software design problem",
                "A network bottleneck",
                "A memory allocation issue"
            ],
            "text": "What is the \"von Neumann bottleneck\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A theorem about data compression",
                "States that a distributed system can only guarantee two of three properties: Consistency, Availability, Partition tolerance",
                "A theorem about CPU allocation",
                "A security theorem",
                "A theorem about caching"
            ],
            "text": "What is the CAP theorem in distributed systems?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "GIL prevents all parallelism in Python",
                "Multiprocessing also uses the GIL",
                "Multiprocessing bypasses the GIL by using separate processes with their own interpreter",
                "GIL only affects multiprocessing, not threading",
                "GIL was removed in Python 3"
            ],
            "text": "What is the Global Interpreter Lock (GIL) and how does multiprocessing relate to it?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "It cancels all tasks on first success",
                "It lets other tasks continue and collects exceptions instead of failing immediately",
                "It retries failed tasks automatically",
                "It enforces execution order",
                "It converts exceptions to log messages only"
            ],
            "text": "What is the benefit of using gather() with return_exceptions=True?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are the same thing",
                "Wall clock time is actual elapsed time; CPU time is only the time the CPU spent on the task",
                "Wall clock is for sequential; CPU time is for parallel",
                "Wall clock includes sleep time; CPU time doesn't",
                "CPU time is always longer"
            ],
            "text": "What is the difference between \"wall clock time\" and \"CPU time\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They store different types of data",
                "L1 is smallest and fastest; L2 is larger and slower; L3 is largest and slowest among the three",
                "Only L1 is used for data; others are for instructions",
                "They are in different physical locations",
                "L3 is private; L1 and L2 are shared"
            ],
            "text": "What is the difference between L1, L2, and L3 caches?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Scatter is faster than Gather",
                "Scatter distributes data from root to all processes; Gather collects data from all processes to root",
                "They do the same thing",
                "Scatter is for small data; Gather is for large data",
                "Scatter is synchronous; Gather is asynchronous"
            ],
            "text": "What is the difference between MPI_Scatter and MPI_Gather?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "MPI_Send is safer",
                "MPI_Send blocks until buffer can be reused; MPI_Isend returns immediately (non-blocking)",
                "MPI_Isend is for integers only",
                "MPI_Send is deprecated",
                "There is no difference"
            ],
            "text": "What is the difference between MPI_Send and MPI_Isend?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "NUMA is newer than UMA",
                "In UMA, memory access time is uniform; in NUMA, it varies depending on memory location relative to processor",
                "NUMA uses less memory",
                "UMA is for single processors only",
                "There is no significant difference"
            ],
            "text": "What is the difference between NUMA and UMA architectures?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Heavyweight processes use more memory",
                "Lightweight processes are faster",
                "Threads are lightweight (share address space); processes are heavyweight (separate address space)",
                "Heavyweight processes have higher priority",
                "There is no difference"
            ],
            "text": "What is the difference between a \"heavyweight\" and \"lightweight\" process?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Signals are faster than messages",
                "Signals are asynchronous notifications; messages are data exchanges",
                "Messages can only be sent between threads",
                "There is no difference",
                "Signals can carry more data"
            ],
            "text": "What is the difference between a \"signal\" and a \"message\" in IPC?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Lock is for single-threaded programs; RLock is for multi-threaded",
                "Lock is faster than RLock",
                "RLock can be acquired multiple times by the same thread; Lock cannot",
                "Lock is deprecated; RLock is the modern replacement",
                "There is no difference"
            ],
            "text": "What is the difference between a Lock and an RLock in Python?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Coroutines are faster",
                "Coroutines cannot return values",
                "Coroutines can pause execution and resume later; regular functions run to completion",
                "Coroutines can only be used in web applications",
                "There is no difference"
            ],
            "text": "What is the difference between a coroutine and a regular function?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are the same exception",
                "asyncio.TimeoutError is for async operations; concurrent.futures.TimeoutError is for thread/process pool operations",
                "One is deprecated",
                "They handle different types of timeouts",
                "asyncio.TimeoutError is more detailed"
            ],
            "text": "What is the difference between asyncio.TimeoutError and concurrent.futures.TimeoutError?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are identical",
                "asyncio.run() creates a new event loop and closes it when done; run_until_complete() uses an existing loop",
                "asyncio.run() is deprecated",
                "run_until_complete() is faster",
                "asyncio.run() is for threads"
            ],
            "text": "What is the difference between asyncio.run() and loop.run_until_complete()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "They are identical",
                "wait() gives more control over when to return (first completed, all completed, etc.); gather() waits for all and returns results in order",
                "gather() is deprecated",
                "wait() is for threads; gather() is for coroutines",
                "wait() returns immediately"
            ],
            "text": "What is the difference between asyncio.wait() and asyncio.gather()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Blocking is faster",
                "Non-blocking is more reliable",
                "Blocking waits until the operation completes; non-blocking returns immediately and operation continues in background",
                "Blocking is for large messages only",
                "There is no significant difference"
            ],
            "text": "What is the difference between blocking and non-blocking MPI communication?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "Concurrency is about managing multiple tasks at once; parallelism is about executing multiple tasks simultaneously",
                "Concurrency requires multiple processors; parallelism can work on a single processor",
                "They are the same concept with different names",
                "Parallelism is about I/O operations; concurrency is about CPU operations",
                "Concurrency is faster than parallelism"
            ],
            "text": "What is the difference between concurrency and parallelism?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Data parallelism is faster",
                "Data parallelism applies the same operation to different data; task parallelism applies different operations simultaneously",
                "Task parallelism uses more memory",
                "They are the same concept",
                "Data parallelism is only for databases"
            ],
            "text": "What is the difference between data parallelism and task parallelism?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "fork() is faster; spawn() is slower",
                "fork() copies the parent process; spawn() starts a fresh Python interpreter",
                "fork() is for Windows; spawn() is for Linux",
                "There is no difference",
                "fork() is deprecated"
            ],
            "text": "What is the difference between fork() and spawn() process creation methods?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "kill() is gentler than terminate()",
                "terminate() is deprecated",
                "kill() sends SIGKILL (force stop); terminate() sends SIGTERM (request stop)",
                "They are the same",
                "kill() is for threads; terminate() is for processes"
            ],
            "text": "What is the difference between kill() and terminate() in Python's multiprocessing?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Physical cores are real hardware; logical are software simulations",
                "Physical cores are actual hardware units; logical cores are the threads a physical core can run (e.g., with hyperthreading)",
                "Logical cores are faster",
                "Physical cores handle data; logical handle instructions",
                "There is no difference"
            ],
            "text": "What is the difference between physical and logical cores?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "In preemptive, the OS can interrupt tasks; in cooperative, tasks must voluntarily yield",
                "Preemptive is faster than cooperative",
                "Cooperative requires more memory",
                "They are the same thing with different names",
                "Preemptive is only for single-core systems"
            ],
            "text": "What is the difference between preemptive and cooperative multitasking?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Shared is faster; distributed is slower",
                "In shared memory, all processors access the same memory; in distributed, each has its own memory",
                "Shared is for small systems; distributed is for large",
                "They are the same concept",
                "Shared uses more power"
            ],
            "text": "What is the difference between shared and distributed memory systems?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Strong is for large problems; weak is for small problems",
                "Strong scaling: fixed problem size with more processors; weak scaling: problem size grows with processors",
                "They are the same concept",
                "Strong is theoretical; weak is practical",
                "Strong uses more memory"
            ],
            "text": "What is the difference between strong and weak scaling?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Synchronous is faster",
                "Synchronous blocks until the receiver has started receiving; asynchronous returns immediately",
                "Asynchronous is only for large messages",
                "They use different protocols",
                "There is no difference"
            ],
            "text": "What is the difference between synchronous and asynchronous communication in MPI?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "Keeping data in local files",
                "Ensuring processors work on data that's close to them in memory to reduce communication overhead",
                "Keeping data in local variables",
                "A security measure",
                "A debugging technique"
            ],
            "text": "What is the importance of \"data locality\" in parallel design?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "A management structure for memory allocation",
                "The organization of memory from fastest/smallest (registers, cache) to slowest/largest (RAM, disk)",
                "A debugging tool for memory",
                "A way to organize data in memory",
                "A security feature"
            ],
            "text": "What is the memory hierarchy in modern computers?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To speed up program execution",
                "To coordinate access to shared resources and prevent data corruption",
                "To reduce memory usage",
                "To simplify program logic",
                "To improve cache performance"
            ],
            "text": "What is the primary purpose of synchronization in concurrent programming?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To communicate with external systems",
                "The default communicator that includes all processes in an MPI program",
                "To create new processes",
                "To handle global variables",
                "To manage file I/O"
            ],
            "text": "What is the purpose of MPI_COMM_WORLD?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To send final messages",
                "To wait for all messages to be delivered",
                "To clean up MPI resources and terminate MPI operations",
                "To finalize computation results",
                "To synchronize all processes one last time"
            ],
            "text": "What is the purpose of MPI_Finalize()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To probe network connectivity",
                "To check for incoming messages without actually receiving them",
                "To test if a process is alive",
                "To measure network latency",
                "To debug communication issues"
            ],
            "text": "What is the purpose of MPI_Probe()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To make a process wait for user input",
                "To wait for a non-blocking operation to complete",
                "To pause execution",
                "To synchronize clocks",
                "To wait for a barrier"
            ],
            "text": "What is the purpose of MPI_Wait()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To manage process priorities",
                "To monitor process health",
                "To create shared objects that can be modified by multiple processes",
                "To handle exceptions in processes",
                "To manage memory allocation"
            ],
            "text": "What is the purpose of Manager in Python's multiprocessing module?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To prevent threads from reading and writing",
                "To allow multiple readers or one writer at a time, but not both simultaneously",
                "To log all read and write operations",
                "To alternate between read and write modes",
                "To compress data during read/write operations"
            ],
            "text": "What is the purpose of a \"read-write lock\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To organize processes by priority",
                "To limit the number of processes",
                "To enable safe inter-process communication",
                "To store process IDs",
                "To synchronize process clocks"
            ],
            "text": "What is the purpose of a Queue in multiprocessing?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To translate code between languages",
                "To buffer network translations",
                "To cache virtual-to-physical address translations for faster memory access",
                "To translate data formats",
                "To store translation logs"
            ],
            "text": "What is the purpose of a TLB (Translation Lookaside Buffer)?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To connect cache to main memory",
                "To debug cache operations",
                "The basic unit of data transfer between cache and main memory",
                "To store cache metadata",
                "To synchronize cache access"
            ],
            "text": "What is the purpose of a cache line?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "It serves as the counterpart to a programming past.",
                "It is a task that can be assigned to a thread pool for execution.",
                "It serves as a placeholder to access a result that may not been computed yet.",
                "It allows a program to change how it will function the next time it is run.",
                "It provides error handling for asynchronous operations."
            ],
            "text": "What is the purpose of a future?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To protect memory from unauthorized access",
                "To allocate memory",
                "To ensure memory operations complete in a specific order",
                "To compress memory",
                "To debug memory issues"
            ],
            "text": "What is the purpose of a memory barrier (memory fence)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To lock files for async access",
                "To provide mutual exclusion for coroutines accessing shared resources",
                "To lock the event loop",
                "To prevent task cancellation",
                "To lock memory regions"
            ],
            "text": "What is the purpose of asyncio.Lock()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To set a global timeout for all operations",
                "To set a timeout for a block of async code using async context manager",
                "To cancel timeouts",
                "To extend timeout values",
                "To log timeout information"
            ],
            "text": "What is the purpose of asyncio.timeout() (Python 3.11+)?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To wait for the event loop to start",
                "To wait for a coroutine with a timeout",
                "To wait for multiple coroutines",
                "To wait for a specific time",
                "To wait for user input"
            ],
            "text": "What is the purpose of asyncio.wait_for()?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "To split a file in half",
                "To create a new thread",
                "To create a new child process that is a copy of the parent",
                "To fork the execution path",
                "To handle exceptions"
            ],
            "text": "What is the purpose of os.fork() in Python?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To fetch data before the program starts",
                "To load data into cache before it's actually needed to reduce wait time",
                "To prefetch instructions for compilation",
                "To organize data in memory",
                "To debug memory access"
            ],
            "text": "What is the purpose of prefetching in modern CPUs?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "To gracefully shut down a process",
                "To forcefully stop a process immediately",
                "To pause a process",
                "To restart a process",
                "To send a signal to a process"
            ],
            "text": "What is the purpose of the terminate() method in Python's multiprocessing module?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "Future",
                "Thread",
                "Thread Pool",
                "Boolean",
                "Promise"
            ],
            "text": "What type of object does the std::async() function return?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "When processes run on different physical machines",
                "When high-throughput, low-latency communication on the same host is needed",
                "When avoiding synchronization primitives",
                "When messages must be persisted",
                "When communication must traverse a network"
            ],
            "text": "When is shared memory preferable over message passing between processes?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Before locking the associated mutex",
                "It does not matter",
                "After doing something to change the state associated with the condition_variable and unlocking the associated mutex",
                "After locking the associated mutex and checking whether or not the condition is true",
                "Before checking the condition"
            ],
            "text": "When should a thread typically notify a condition_variable?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "FIFO",
                "pipeline",
                "distributed",
                "client-server",
                "hierarchical"
            ],
            "text": "Which architecture consists of a chained together series of producer-consumer pairs?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "SIMD",
                "MISD",
                "SISD",
                "MIMD",
                "SPMD"
            ],
            "text": "Which classification of Flynn's Taxonomy do modern multi-core PCs fall under?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "functional decomposition",
                "data decomposition",
                "recursive decomposition",
                "speculative decomposition",
                "pipeline decomposition"
            ],
            "text": "Which decomposition strategy divides work based on the data each task processes?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "std::async()",
                "boost::asio::submit()",
                "boost::asio::post()",
                "boost::asio::swim()",
                "boost::asio::execute()"
            ],
            "text": "Which function can be used to submit tasks to a Boost C++ Library thread_pool?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "submit_task()",
                "add_task()",
                "submit()",
                "enqueue()",
                "execute()"
            ],
            "text": "Which function can be used to submit tasks to a concurrent.futures ThreadPoolExecutor in Python?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "A thread that consumes too much memory",
                "A thread that runs without stopping",
                "A situation where a thread is perpetually denied access to resources it needs",
                "A deadlock between multiple threads",
                "A thread that has no work to do"
            ],
            "text": "Which of the following best describes \"starvation\" in concurrent programming?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "Pipes",
                "Shared memory",
                "Message queues",
                "Thread-local storage",
                "Sockets"
            ],
            "text": "Which of the following is NOT a common IPC mechanism?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "tool for downloading multiple files from the Internet at the same time",
                "math library for processing large matrices",
                "system logging application that frequently writes to a database",
                "graphical user interface (GUI) for an accounting application",
                "real-time data streaming service"
            ],
            "text": "Which of these applications would benefit the most from parallel execution?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "longest series of sequential operations through the program",
                "sum of the time for all task nodes in a computational graph",
                "sum of the time for all task nodes along the critical path",
                "shortest execution path through the program"
            ],
            "text": "Which of these describes a program's \"critical path\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "ratio of sequential execution time to the parallel execution time with some number of processors",
                "amount of time a task takes to execute",
                "number of tasks that can be executed in a certain amount of time",
                "number of processors used by the program"
            ],
            "text": "Which of these describes a program's \"latency\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "longest series of sequential operations through the program",
                "sum of the time for all task nodes along the critical path",
                "sum of the time for all task nodes in a computational graph",
                "total execution time of the program"
            ],
            "text": "Which of these describes a program's \"span\"?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "amount of time a task takes to execute",
                "ratio of sequential execution time to the parallel execution time with some number of processors",
                "number of tasks that can be executed in a certain amount of time",
                "number of processors used by the program"
            ],
            "text": "Which of these describes a program's \"speedup\"?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "number of tasks that can be executed in a certain amount of time",
                "ratio of sequential execution time to the parallel execution time with some number of processors",
                "amount of time a task takes to execute",
                "number of processors used by the program"
            ],
            "text": "Which of these describes a program's \"throughput\"?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "sum of the time for all task nodes along the critical path",
                "longest series of sequential operations through the program",
                "sum of the time for all task nodes in a computational graph",
                "total number of operations performed by the program"
            ],
            "text": "Which of these describes a program's \"work\"?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "track the availability of a limited resource",
                "track how many threads the program has created",
                "track how long a program has been running",
                "enforce mutual exclusion in a critical section of code",
                "monitor memory usage"
            ],
            "text": "Which of these is a common use case for a counting semaphore?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "corrupted memory",
                "the execution scheduler",
                "a slow Internet connection",
                "not using a semaphore",
                "inadequate CPU resources"
            ],
            "text": "Which of these is responsible for causing a race condition?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "the order in which two threads execute their respective operations will change the output",
                "one thread is modifying a shared variable while another thread concurrently reads its value",
                "a single-threaded program is competing with other processes for execution time on the CPU",
                "two threads are concurrently reading and writing the same shared variable",
                "multiple threads are waiting for a condition variable to be notified"
            ],
            "text": "Which scenario creates the potential for a race condition to occur?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "A small number of tasks need to send data a large number of other tasks.",
                "A large number of tasks will be sending data to a small number of receiving tasks.",
                "A large number of tasks need to communicate with each other.",
                "A small number of tasks need to communicate with each other.",
                "All tasks need to broadcast to all other tasks."
            ],
            "text": "Which scenario describes the best use case for a point-to-point communication strategy?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "mapping",
                "agglomeration",
                "communication",
                "partitioning",
                "synchronization"
            ],
            "text": "Which stage of the parallel design process focuses on breaking the problem down into discrete pieces of work?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "mapping",
                "agglomeration",
                "communication",
                "partitioning",
                "synchronization"
            ],
            "text": "Which stage of the parallel design process focuses on combining tasks and replicating data or computation as needed to increase program efficiency?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "mapping",
                "agglomeration",
                "partitioning",
                "communication",
                "synchronization"
            ],
            "text": "Which stage of the parallel design process focuses on coordinating task execution and how they share information?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "communication",
                "mapping",
                "agglomeration",
                "partitioning",
                "load balancing"
            ],
            "text": "Which stage of the parallel design process focuses on specifying where each task will execute?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Orphan processes are automatically terminated",
                "Orphan processes cannot run",
                "Orphan processes are adopted by the init (PID 1) process",
                "Orphan processes cause memory leaks",
                "Orphan processes are the same as zombie processes"
            ],
            "text": "Which statement about orphan processes is correct?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Concurrency always runs tasks at the same time",
                "Parallelism means tasks never overlap",
                "Concurrency is about dealing with multiple tasks at once, parallelism is about executing multiple tasks simultaneously",
                "Concurrency only applies to distributed systems",
                "Parallelism is only possible with GPUs"
            ],
            "text": "Which statement best distinguishes concurrency from parallelism?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "The binary semaphore will have a value of 0, 1, 2, 3, etc.",
                "The binary semaphore can be acquired and released by different threads.",
                "The binary semaphore can only be acquired and released by the same thread.",
                "The binary semaphore can have a positive or negative value.",
                "The binary semaphore does not enforce mutual exclusion."
            ],
            "text": "Which statement describes a difference between a binary semaphore and a mutex?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "semaphore and condition_variable",
                "mutex and semaphore",
                "standard C++ queues are already thread-safe",
                "mutex and condition_variable",
                "atomic variables and spinlocks"
            ],
            "text": "Which two mechanisms can be used together with a queue to make it thread-safe?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "They include all of the tasks within a program, from start to finish.",
                "They help to identify critical sections of code that will require mutual exclusion.",
                "They provide a good excuse to practice your drawing skills.",
                "They help to identify opportunities for parallel execution.",
                "They simplify the debugging process."
            ],
            "text": "Why are computational graphs useful?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "Threads like to relax and go for a swim every once in a while.",
                "Threads within the same thread pool can more easily share data with each other than standard non-pool threads.",
                "They provide a convenient way to group and organize a collection of related threads.",
                "They reuse threads to reduce the overhead that would be required to create a new, separate thread for every concurrent task.",
                "They automatically manage thread synchronization issues."
            ],
            "text": "Why are thread pools useful?"
        },
        {
            "correctOptionIndex": 2,
            "options": [
                "Daemons only write their own name, so the log will just say \"Daemon, Daemon, Daemon, etc.\"",
                "Daemon threads cannot read or write files.",
                "The log file could be corrupted.",
                "The log file could end up with multiple, duplicate entries.",
                "Daemon threads might not have file access permissions."
            ],
            "text": "Why can it be risky to use a detached daemon thread to perform a task that involves writing data to a log file?"
        },
        {
            "correctOptionIndex": 0,
            "options": [
                "The operating system automatically handles scheduling threads to execute on each processor core.",
                "Desktop computers do not have enough processor cores for mapping to be a concern.",
                "Most desktop computers only have one processor core.",
                "The mapping design stage is not necessary for modern applications.",
                "Mapping is handled by the application itself."
            ],
            "text": "Why does the mapping design stage not apply to applications written for common desktop operating systems?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "You need to group the tasks together before planning the most effective communication strategy between them.",
                "You need to know how the problem will be divided in order to assess the communication needs between individual tasks.",
                "You need to know where each of the tasks will physically execute before deciding on a communication strategy.",
                "The \"order\" of the four design stages is arbitrary and does not really matter.",
                "Communication requirements determine how tasks are grouped."
            ],
            "text": "Why does the partitioning design stage occur before the communication stage?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "The system clock used to determine the start and end times of the program is inconsistent and may fluctuate randomly.",
                "It's good luck to do things multiple times.",
                "The program might crash so you should measure it multiple times to make sure you get at least one good run.",
                "The execution time will vary from run-to-run depending on how the operating system chooses to schedule your program.",
                "To account for hardware variability."
            ],
            "text": "Why should you average the execution time across multiple runs when measuring a program's performance?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "ThreadB needs to wait until after ThreadA has terminated to continue.",
                "ThreadA needs to wait until after ThreadB has terminated to continue.",
                "ThreadB is blocked so ThreadA needs to tell it to continue executing.",
                "ThreadA needs to terminate ThreadB immediately.",
                "ThreadA and ThreadB need to synchronize execution."
            ],
            "text": "Why would ThreadA call the join() function on ThreadB?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "Daemon threads always execute at the lowest priority which makes them ideal for background tasks.",
                "Daemon threads will automatically spawn additional helper threads as needed when their workload increases.",
                "You should never trust a daemon. They're mischievous!",
                "The daemon thread will not prevent the program from terminating when the main thread is finished.",
                "Daemon threads are more efficient for high-priority tasks."
            ],
            "text": "Why would you use detached daemon threads to handle continuous background tasks?"
        },
        {
            "correctOptionIndex": 3,
            "options": [
                "You need to wake up a random number of waiting threads.",
                "You need all of the waiting threads to wake up and continue executing.",
                "You need to wake up one specific waiting thread.",
                "You only need to wake up one waiting thread and it does not matter which one.",
                "You want to ensure maximum efficiency."
            ],
            "text": "Why would you use the condition_variable's notify_one() function instead of notify_all()?"
        },
        {
            "correctOptionIndex": 1,
            "options": [
                "TRUE",
                "FALSE",
                "It depends on the operating system",
                "It depends on the processor"
            ],
            "text": "You can safely expect threads to execute in the same relative order that you create them."
        }
    ]
}