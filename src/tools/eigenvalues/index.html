<!DOCTYPE html>

<html lang="en">

<head>
    <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5593122079896089"></script>
    <title>Matrix Eigenvalues and Eigenvectors</title>
    <meta charset="utf-8" />
    <meta content="Compute eigenvalues and eigenvectors of a 3√ó3 matrix, both analytically and via power iteration. Part of Adam Djellouli's linear algebra tools." name="description" />
    <meta content="matrix, eigenvalues, eigenvectors, calculator, Adam Djellouli, linear algebra" name="keywords" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css" rel="stylesheet" />
    <link href="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/icon.ico" rel="icon" />
    <link href="../../resources/style.css" rel="stylesheet" type="text/css" />
    <link href="style.css" rel="stylesheet" type="text/css" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <meta content="ie-edge" http-equiv="X-UA-Compatible" />
    <link href="https://adamdjellouli.com/tools/eigenvalues/" rel="canonical" />
    <script id="structured-data" type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "WebPage",
            "name": "Matrix Eigenvalues and Eigenvectors",
            "url": "https://adamdjellouli.com/tools/eigenvalues/",
            "description": "Compute eigenvalues and eigenvectors of a 3\u00d73 matrix, both analytically and via power iteration. Part of Adam Djellouli's linear algebra tools."
        }
    </script>
</head>

<body>
    <nav aria-label="Main navigation">
        <a class="logo" href="../../index.html">
            <img alt="Adam Djellouli - Home Page Logo" id="logo-image" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/logo.PNG" />
        </a>
        <input aria-label="Toggle navigation menu" id="navbar-toggle" type="checkbox" />
        <ul aria-labelledby="navbar-toggle" role="menu">
            <li role="menuitem">
                <a href="../../index.html" title="Go to Home Page"> Home </a>
            </li>
            <li role="menuitem">
                <a href="../../core/blog.html" title="Read Adam Djellouli Blog on Programming and Technology"> Blog </a>
            </li>
            <li role="menuitem">
                <a href="../../core/tools.html" title="Discover Tools Created by Adam Djellouli"> Tools </a>
            </li>
            <li role="menuitem">
                <a href="../../core/projects.html" title="Explore Projects Developed by Adam Djellouli"> Projects </a>
            </li>
            <li role="menuitem">
                <a href="../../core/courses.html" title="Browse Courses by Adam Djellouli"> Courses </a>
            </li>
            <li role="menuitem">
                <a href="../../core/resume.html" title="View Adam Djellouli Professional Resume"> Resume </a>
            </li>
            <li>
                <script async="" src="https://cse.google.com/cse.js?cx=8160ef9bb935f4f68"></script>
                <div class="gcse-search"></div>
            </li>
            <li>
                <button aria-label="Toggle dark mode" id="dark-mode-button"></button>
            </li>
        </ul>
    </nav>
    <section>
        <header>
            <h1>Matrix Eigenvalues and Eigenvectors</h1>
            <p>Enter the values of a 4√ó4 matrix below (you can also input a smaller n√ón sub-matrix by filling in just the top-left n rows and n columns), then select a method to compute its eigenvalues and eigenvectors.</p>
        </header>
        <div id="container">
            <!-- Matrix Input Table -->
            <table class="matrix" id="matrix-input">
                <caption>4√ó4 Matrix (or sub-matrix)</caption>
                <tr>
                    <td><input placeholder="a11" type="text" /></td>
                    <td><input placeholder="a12" type="text" /></td>
                    <td><input placeholder="a13" type="text" /></td>
                    <td><input placeholder="a14" type="text" /></td>
                </tr>
                <tr>
                    <td><input placeholder="a21" type="text" /></td>
                    <td><input placeholder="a22" type="text" /></td>
                    <td><input placeholder="a23" type="text" /></td>
                    <td><input placeholder="a24" type="text" /></td>
                </tr>
                <tr>
                    <td><input placeholder="a31" type="text" /></td>
                    <td><input placeholder="a32" type="text" /></td>
                    <td><input placeholder="a33" type="text" /></td>
                    <td><input placeholder="a34" type="text" /></td>
                </tr>
                <tr>
                    <td><input placeholder="a41" type="text" /></td>
                    <td><input placeholder="a42" type="text" /></td>
                    <td><input placeholder="a43" type="text" /></td>
                    <td><input placeholder="a44" type="text" /></td>
                </tr>
            </table>
            <!-- Buttons -->
            <div class="row">
                <button id="clear">Clear</button>
            </div>
            <!-- Tab Buttons -->
            <div class="tabs">
                <div class="tab-buttons">
                    <button class="tab-button active" data-tab="analytical-tab">Analytical (Exact)</button>
                    <button class="tab-button" data-tab="power-tab">Power Iteration (Approx)</button>
                </div>
                <!-- Analytical Tab -->
                <div class="tab-content active" id="analytical-tab">
                    <div class="row">
                        <button id="calculate-analytical">Calculate (Exact)</button>
                    </div>
                    <div class="col">
                        <label for="output-eigenvalues-analytical">Eigenvalues (Real Only):</label>
                        <textarea id="output-eigenvalues-analytical" readonly="" rows="3"></textarea>
                    </div>
                    <div class="col">
                        <label for="output-eigenvectors-analytical">Eigenvectors:</label>
                        <textarea id="output-eigenvectors-analytical" readonly="" rows="5"></textarea>
                    </div>
                </div>
                <!-- Power Iteration Tab -->
                <div class="tab-content" id="power-tab">
                    <div class="row">
                        <button id="calculate-power">Power Iteration</button>
                    </div>
                    <div class="col">
                        <label for="output-eigenvalue-power">Approx. Dominant Eigenvalue:</label>
                        <textarea id="output-eigenvalue-power" readonly="" rows="2"></textarea>
                    </div>
                    <div class="col">
                        <label for="output-eigenvector-power">Approx. Dominant Eigenvector:</label>
                        <textarea id="output-eigenvector-power" readonly="" rows="3"></textarea>
                    </div>
                </div>
            </div>
            <!-- Help Box -->
            <div class="help-box">
                <strong>Need Help?</strong>
                <ul>
                    <li>By default there are 16 entries (4√ó4). If you want a smaller matrix, just fill in the top-left n√ón block (e.g. 2√ó2 or 3√ó3).</li>
                    <li>Click "Calculate (Exact)" to see the real eigenvalues and corresponding eigenvectors.</li>
                    <li>Or switch to the <em>Power Iteration</em> tab for an approximate dominant eigenpair.</li>
                    <li>Click "Clear" to reset all inputs.</li>
                    <li>Complex eigenvalues are not displayed here.</li>
                </ul>
            </div>
        </div>
        <!-- Mathematical Background Section -->
        <section class="explanation-section">
            <div class="section-header">
                <h2>üìö Mathematical Background</h2>
            </div>
            <div class="explanation-content">
                <div class="explanation-card">
                    <h3>üî¢ Eigenvalues and Eigenvectors - Introduction</h3>
                    <p>
                        Eigenvalues and eigenvectors are fundamental concepts in linear algebra that reveal the intrinsic properties of
                        linear transformations represented by matrices. They describe special directions and scaling factors that remain
                        invariant under a transformation.
                    </p>
                    <p>
                        When a matrix <strong>A</strong> acts on a vector <strong>v</strong>, it typically changes both the direction
                        and magnitude of the vector. However, eigenvectors are special vectors that only get scaled (stretched or shrunk)
                        by the transformation‚Äîtheir direction remains unchanged. The corresponding eigenvalue indicates how much the
                        eigenvector is scaled.
                    </p>
                </div>
                <div class="explanation-card">
                    <h3>üìê Mathematical Definition</h3>
                    <p>For a square matrix <strong>A</strong> (n√ón), an eigenvalue Œª and its corresponding eigenvector <strong>v</strong> satisfy:</p>
                    <div class="formula-box">
                        <p><strong>A v = Œª v</strong></p>
                    </div>
                    <p>Where:</p>
                    <ul>
                        <li><strong>A</strong> is an n√ón square matrix</li>
                        <li><strong>v</strong> is a non-zero vector (the eigenvector)</li>
                        <li><strong>Œª</strong> (lambda) is a scalar (the eigenvalue)</li>
                    </ul>
                    <p>
                        This equation can be rewritten as:
                    </p>
                    <div class="formula-box">
                        <p><strong>(A - ŒªI) v = 0</strong></p>
                    </div>
                    <p>
                        Where <strong>I</strong> is the identity matrix. For non-trivial solutions (v ‚â† 0), the determinant must be zero:
                    </p>
                    <div class="formula-box">
                        <p><strong>det(A - ŒªI) = 0</strong></p>
                    </div>
                    <p>
                        This is called the <strong>characteristic equation</strong>. Expanding this determinant yields a polynomial
                        in Œª of degree n, called the <strong>characteristic polynomial</strong>.
                    </p>
                </div>
                <div class="explanation-card">
                    <h3>üéØ Geometric Interpretation</h3>
                    <p>
                        Geometrically, eigenvalues and eigenvectors reveal how a matrix transformation affects space:
                    </p>
                    <ul>
                        <li><strong>Eigenvectors</strong> point in directions that remain unchanged by the transformation (only scaled)</li>
                        <li><strong>Eigenvalues</strong> tell us the scaling factor along each eigenvector direction:
                            <ul>
                                <li>Œª &gt; 1: Stretching (expansion) along that direction</li>
                                <li>0 &lt; Œª &lt; 1: Compression along that direction</li>
                                <li>Œª = 1: No change in magnitude (direction preserved exactly)</li>
                                <li>Œª &lt; 0: Scaling with reflection (direction reversed)</li>
                                <li>Œª = 0: Collapse to zero (direction in null space)</li>
                            </ul>
                        </li>
                    </ul>
                    <p>
                        For a 2√ó2 matrix representing a transformation in the plane, if we have two perpendicular eigenvectors,
                        they form the principal axes of the transformation. The transformation stretches/compresses along these
                        axes by the corresponding eigenvalues.
                    </p>
                </div>
                <div class="explanation-card">
                    <h3>üî¨ Methods for Computing Eigenvalues</h3>
                    <div class="parameter-explanation">
                        <h4>Analytical (Exact) Method</h4>
                        <p>
                            The analytical method solves the characteristic equation directly:
                        </p>
                        <ol>
                            <li>Form the matrix (A - ŒªI)</li>
                            <li>Compute det(A - ŒªI) = 0</li>
                            <li>Solve the resulting polynomial equation for Œª</li>
                            <li>For each eigenvalue Œª·µ¢, solve (A - Œª·µ¢I)v = 0 to find the corresponding eigenvector</li>
                        </ol>
                        <p>
                            <strong>Advantages:</strong> Exact results, works well for small matrices (2√ó2, 3√ó3)
                        </p>
                        <p>
                            <strong>Limitations:</strong> Computationally expensive for large matrices; polynomial root-finding
                            can be numerically unstable; may produce complex eigenvalues
                        </p>
                    </div>
                    <div class="parameter-explanation">
                        <h4>Power Iteration (Approximation Method)</h4>
                        <p>
                            Power iteration is an iterative algorithm that finds the dominant eigenvalue (largest in absolute value)
                            and its corresponding eigenvector:
                        </p>
                        <ol>
                            <li>Start with a random vector <strong>v‚ÇÄ</strong></li>
                            <li>Repeatedly multiply by matrix A: <strong>v‚Çñ‚Çä‚ÇÅ = A v‚Çñ / ||A v‚Çñ||</strong></li>
                            <li>The sequence converges to the dominant eigenvector</li>
                            <li>The eigenvalue is approximated by the Rayleigh quotient: Œª = (v<sup>T</sup> A v) / (v<sup>T</sup> v)</li>
                        </ol>
                        <p>
                            <strong>Advantages:</strong> Simple to implement, memory efficient, works for very large sparse matrices
                        </p>
                        <p>
                            <strong>Limitations:</strong> Only finds the dominant eigenpair; convergence can be slow if eigenvalues
                            are close in magnitude; may fail if the dominant eigenvalue is not unique
                        </p>
                    </div>
                    <p><strong>Other Methods:</strong> QR algorithm, Jacobi method, Lanczos algorithm, Arnoldi iteration</p>
                </div>
                <div class="explanation-card">
                    <h3>‚≠ê Important Properties</h3>
                    <p>Eigenvalues and eigenvectors have several key properties:</p>
                    <ul>
                        <li><strong>Number of Eigenvalues:</strong> An n√ón matrix has exactly n eigenvalues (counting multiplicities),
                            though some may be complex</li>
                        <li><strong>Trace:</strong> The sum of all eigenvalues equals the trace of the matrix (sum of diagonal elements):
                            Œ£Œª·µ¢ = tr(A)</li>
                        <li><strong>Determinant:</strong> The product of all eigenvalues equals the determinant: Œ†Œª·µ¢ = det(A)</li>
                        <li><strong>Symmetric Matrices:</strong> Have all real eigenvalues and orthogonal eigenvectors</li>
                        <li><strong>Triangular Matrices:</strong> Eigenvalues are the diagonal elements</li>
                        <li><strong>Singular Matrices:</strong> Have at least one zero eigenvalue</li>
                        <li><strong>Orthogonal Matrices:</strong> All eigenvalues have magnitude 1</li>
                        <li><strong>Similar Matrices:</strong> Matrices related by A = PBP<sup>-1</sup> have identical eigenvalues</li>
                    </ul>
                </div>
                <div class="explanation-card">
                    <h3>üåü Applications</h3>
                    <p>Eigenvalues and eigenvectors appear throughout science and engineering:</p>
                    <ul>
                        <li><strong>Principal Component Analysis (PCA):</strong> Dimensionality reduction in data science by finding
                            principal directions (eigenvectors) of maximum variance (eigenvalues)</li>
                        <li><strong>Vibration Analysis:</strong> Natural frequencies (eigenvalues) and mode shapes (eigenvectors)
                            of mechanical systems</li>
                        <li><strong>Quantum Mechanics:</strong> Energy levels (eigenvalues) and wavefunctions (eigenvectors)
                            of the Schr√∂dinger equation</li>
                        <li><strong>Google PageRank:</strong> The importance of web pages is the dominant eigenvector of the
                            link matrix</li>
                        <li><strong>Stability Analysis:</strong> System stability determined by eigenvalues of the Jacobian matrix;
                            stable if all eigenvalues have negative real parts</li>
                        <li><strong>Image Compression:</strong> Singular Value Decomposition (SVD) uses eigenvalues for optimal
                            low-rank approximations</li>
                        <li><strong>Graph Theory:</strong> Spectral graph theory studies graph properties through eigenvalues of
                            adjacency or Laplacian matrices</li>
                        <li><strong>Markov Chains:</strong> Steady-state distributions are eigenvectors corresponding to eigenvalue 1</li>
                        <li><strong>Control Theory:</strong> Controllability and observability of linear systems</li>
                        <li><strong>Facial Recognition:</strong> Eigenfaces method for pattern recognition</li>
                    </ul>
                </div>
                <div class="explanation-card">
                    <h3>üìä Special Types of Matrices</h3>
                    <div class="parameter-explanation">
                        <h4>Symmetric Matrices</h4>
                        <p>
                            A symmetric matrix (A = A<sup>T</sup>) has particularly nice properties:
                        </p>
                        <ul>
                            <li>All eigenvalues are real numbers</li>
                            <li>Eigenvectors corresponding to distinct eigenvalues are orthogonal</li>
                            <li>Can be diagonalized by an orthogonal matrix: A = QŒõQ<sup>T</sup></li>
                            <li>Common in physics (covariance matrices, moment of inertia tensors)</li>
                        </ul>
                    </div>
                    <div class="parameter-explanation">
                        <h4>Positive Definite Matrices</h4>
                        <p>
                            A symmetric matrix where x<sup>T</sup>Ax &gt; 0 for all non-zero x:
                        </p>
                        <ul>
                            <li>All eigenvalues are strictly positive</li>
                            <li>Important in optimization (Hessian matrices)</li>
                            <li>Covariance matrices in statistics are positive semi-definite</li>
                        </ul>
                    </div>
                    <div class="parameter-explanation">
                        <h4>Diagonalizable Matrices</h4>
                        <p>
                            A matrix is diagonalizable if it can be written as A = PDP<sup>-1</sup>, where D is diagonal:
                        </p>
                        <ul>
                            <li>D contains the eigenvalues on its diagonal</li>
                            <li>Columns of P are the eigenvectors</li>
                            <li>Makes matrix powers easy to compute: A<sup>k</sup> = PD<sup>k</sup>P<sup>-1</sup></li>
                            <li>A matrix is diagonalizable if it has n linearly independent eigenvectors</li>
                        </ul>
                    </div>
                </div>
                <div class="explanation-card">
                    <h3>üîç Practical Example: 2√ó2 Matrix</h3>
                    <p>Consider the matrix:</p>
                    <div class="formula-box">
                        <p>A = [ 4 1 ]</p>
                        <p> [ 2 3 ]</p>
                    </div>
                    <p><strong>Step 1:</strong> Find characteristic polynomial:</p>
                    <div class="formula-box">
                        <p>det(A - ŒªI) = det([ 4-Œª 1 ]) = (4-Œª)(3-Œª) - 2 = Œª¬≤ - 7Œª + 10 = 0</p>
                        <p> [ 2 3-Œª ])</p>
                    </div>
                    <p><strong>Step 2:</strong> Solve for eigenvalues: Œª‚ÇÅ = 5, Œª‚ÇÇ = 2</p>
                    <p><strong>Step 3:</strong> Find eigenvectors by solving (A - Œª·µ¢I)v = 0</p>
                    <p>
                        For Œª‚ÇÅ = 5: v‚ÇÅ = [1, 1]<sup>T</sup> (or any scalar multiple)<br />
                        For Œª‚ÇÇ = 2: v‚ÇÇ = [1, -2]<sup>T</sup> (or any scalar multiple)
                    </p>
                    <p>
                        <strong>Interpretation:</strong> The transformation stretches vectors along v‚ÇÅ by factor 5 and
                        along v‚ÇÇ by factor 2.
                    </p>
                </div>
            </div>
        </section>
    </section>
    <footer>
        <div class="footer-columns">
            <div class="footer-column footer-about">
                <h2>About</h2>
                <p class="footer-message">Thanks for stopping by. This site is free to use; please be respectful and avoid misuse. For questions or collaboration, reach me on <a href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" title="LinkedIn Profile">LinkedIn</a> or <a href="https://github.com/djeada" title="GitHub Profile">GitHub</a>.</p>
                <p class="footer-signature">Built with care in Berlin (UTC+1).</p>
            </div>
            <div class="footer-column footer-links">
                <h2>Quick Links</h2>
                <ul class="footer-links-list">
                    <li><a href="https://adamdjellouli.com/index.html" title="Home">Home</a></li>
                    <li><a href="https://adamdjellouli.com/core/projects.html" title="Projects">Projects</a></li>
                    <li><a href="https://adamdjellouli.com/core/tools.html" title="Tools">Tools</a></li>
                    <li><a href="https://adamdjellouli.com/core/courses.html" title="Courses">Courses</a></li>
                    <li><a href="https://adamdjellouli.com/core/resume.html" title="Resume">Resume</a></li>
                    <li><a href="https://adamdjellouli.com/core/privacy_policy.html" title="Privacy Policy">Privacy Policy</a></li>
                    <li><a href="https://adamdjellouli.com/sitemap.xml" title="Sitemap">Sitemap</a></li>
                </ul>
            </div>
            <div class="footer-column footer-social">
                <h2>Follow</h2>
                <ul class="social-media">
                    <li>
                        <a aria-label="YouTube" class="fa fa-youtube" href="https://www.youtube.com/channel/UCGPoHTVjMN77wcGknXPHl1Q" rel="noopener" target="_blank" title="YouTube"></a>
                        <span class="social-label">YouTube</span>
                    </li>
                    <li>
                        <a aria-label="LinkedIn" class="fa fa-linkedin" href="https://www.linkedin.com/in/adam-djellouli-1bb54619a/" rel="noopener" target="_blank" title="LinkedIn"></a>
                        <span class="social-label">LinkedIn</span>
                    </li>
                    <li>
                        <a aria-label="Instagram" class="fa fa-instagram" href="https://www.instagram.com/linuxchallenges/" rel="noopener" target="_blank" title="Instagram"></a>
                        <span class="social-label">Instagram</span>
                    </li>
                    <li>
                        <a aria-label="GitHub" class="fa fa-github" href="https://github.com/djeada" title="GitHub"></a>
                        <span class="social-label">GitHub</span>
                    </li>
                </ul>
                <img alt="" aria-hidden="true" class="footer-mark" src="https://raw.githubusercontent.com/djeada/Personal-Website/master/images/symbol.png" />
            </div>
        </div>
        <div class="footer-bottom">
            <p id="copyright">
                ¬© Adam Djellouli. All rights reserved.
            </p>
        </div>
        <script>
            document.getElementById("copyright").innerHTML = "&copy; " + new Date().getFullYear() + " Adam Djellouli. All rights reserved.";
        </script>
        <script src="/app.js"></script>
    </footer>
</body>
<script src="app.js"></script>

</html>