{
    "category": "Statistics",
    "subcategories": [
        {
            "name": "Bayes' Theorem",
            "cards": [
                {
                    "front": "What is Bayes' Theorem?",
                    "back": "Bayes' Theorem is a fundamental formula in probability theory that allows you to update the probability of a hypothesis based on new evidence. It is written as: \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\] where: - $P(A|B)$ is the <b>posterior probability</b> (the probability of event A occurring given that B is true), - $P(B|A)$ is the <b>likelihood</b> (the probability of event B occurring given that A is true), - $P(A)$ is the <b>prior probability</b> of A, - $P(B)$ is the <b>marginal probability</b> of B. Bayes' Theorem is widely used in fields such as medical testing, where it helps calculate the probability of a disease given a positive test result."
                },
                {
                    "front": "What is an example of applying Bayes' Theorem in medical testing?",
                    "back": "Suppose a test for a certain disease has a 99% accuracy rate, meaning the probability of testing positive given the disease is 99% $P(Pos|Disease) = 0.99$. However, if the disease only affects 1% of the population, the <b>prior probability</b> of the disease $P(Disease) = 0.01$. If a person tests positive, Bayes' Theorem can be used to update the probability that they actually have the disease, factoring in the false positive rate and the disease prevalence. Bayes' Theorem in this case would provide a more accurate probability based on available data rather than assuming a positive test always means the presence of the disease."
                },
                {
                    "front": "How does Bayes' Theorem differ from classical probability?",
                    "back": "Classical probability often deals with frequencies of events, whereas Bayes' Theorem introduces the concept of <b>updating</b> a probability based on new evidence. Classical probability is static and does not consider past events, while Bayes' Theorem evolves with new data and is used to update <b>beliefs</b> or <b>hypotheses</b> dynamically."
                },
                {
                    "front": "What is Bayes' Theorem?",
                    "back": "Bayes' Theorem is a fundamental formula in probability theory that allows you to update the probability of a hypothesis based on new evidence. It is written as: \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\] where: - $P(A|B)$ is the <b>posterior probability</b> (the probability of event A occurring given that B is true), - $P(B|A)$ is the <b>likelihood</b> (the probability of event B occurring given that A is true), - $P(A)$ is the <b>prior probability</b> of A, - $P(B)$ is the <b>marginal probability</b> of B. Bayes' Theorem is widely used in fields such as medical testing, where it helps calculate the probability of a disease given a positive test result."
                },
                {
                    "front": "What is an example of applying Bayes' Theorem in medical testing?",
                    "back": "Suppose a test for a certain disease has a 99% accuracy rate, meaning the probability of testing positive given the disease is 99% $P(Pos|Disease) = 0.99$. However, if the disease only affects 1% of the population, the <b>prior probability</b> of the disease $P(Disease) = 0.01$. If a person tests positive, Bayes' Theorem can be used to update the probability that they actually have the disease, factoring in the false positive rate and the disease prevalence. Bayes' Theorem in this case would provide a more accurate probability based on available data rather than assuming a positive test always means the presence of the disease."
                },
                {
                    "front": "How does Bayes' Theorem differ from classical probability?",
                    "back": "Classical probability often deals with frequencies of events, whereas Bayes' Theorem introduces the concept of <b>updating</b> a probability based on new evidence. Classical probability is static and does not consider past events, while Bayes' Theorem evolves with new data and is used to update <b>beliefs</b> or <b>hypotheses</b> dynamically."
                }
            ]
        },
        {
            "name": "Conditional Probability",
            "cards": [
                {
                    "front": "What is conditional probability?",
                    "back": "Conditional probability is the probability of an event occurring given that another event has already occurred. It helps in understanding how the probability of one event is affected by the presence or absence of another event. The formula for conditional probability is: \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\] where $P(A|B)$ is the probability of A occurring given that B has occurred, and $P(A \\cap B)$ is the joint probability of A and B happening together."
                },
                {
                    "front": "What is an example of conditional probability in everyday life?",
                    "back": "Consider the probability of it raining given that the sky is cloudy. The probability of rain (A) is influenced by the presence of clouds (B). The conditional probability $P(A|B)$ will likely be higher than the unconditional probability of rain, as clouds increase the likelihood of rain."
                },
                {
                    "front": "How does conditional probability relate to independent events?",
                    "back": "If two events are <b>independent</b>, the occurrence of one does not affect the probability of the other, meaning: \\[ P(A|B) = P(A) \\] For independent events, the conditional probability is the same as the unconditional probability, as there is no relationship between A and B."
                },
                {
                    "front": "How do you calculate the probability of multiple dependent events?",
                    "back": "For dependent events, the probability of multiple events occurring in sequence (e.g., A then B) is the product of the first event's probability and the conditional probability of the second event given the first: \\[ P(A \\cap B) = P(A) \\times P(B|A) \\] This formula accounts for the fact that the occurrence of A affects the probability of B."
                },
                {
                    "front": "What is conditional probability?",
                    "back": "Conditional probability is the probability of an event occurring given that another event has already occurred. It helps in understanding how the probability of one event is affected by the presence or absence of another event. The formula for conditional probability is: \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\] where $P(A|B)$ is the probability of A occurring given that B has occurred, and $P(A \\cap B)$ is the joint probability of A and B happening together."
                },
                {
                    "front": "What is an example of conditional probability in everyday life?",
                    "back": "Consider the probability of it raining given that the sky is cloudy. The probability of rain (A) is influenced by the presence of clouds (B). The conditional probability $P(A|B)$ will likely be higher than the unconditional probability of rain, as clouds increase the likelihood of rain."
                },
                {
                    "front": "How does conditional probability relate to independent events?",
                    "back": "If two events are <b>independent</b>, the occurrence of one does not affect the probability of the other, meaning: \\[ P(A|B) = P(A) \\] For independent events, the conditional probability is the same as the unconditional probability, as there is no relationship between A and B."
                },
                {
                    "front": "How do you calculate the probability of multiple dependent events?",
                    "back": "For dependent events, the probability of multiple events occurring in sequence (e.g., A then B) is the product of the first event's probability and the conditional probability of the second event given the first: \\[ P(A \\cap B) = P(A) \\times P(B|A) \\] This formula accounts for the fact that the occurrence of A affects the probability of B."
                }
            ]
        },
        {
            "name": "Joint Probability",
            "cards": [
                {
                    "front": "What is joint probability?",
                    "back": "Joint probability is the probability that two or more events occur together. For two events A and B, the joint probability $P(A \\cap B)$ represents the likelihood that both A and B happen. If the events are <b>independent</b>, the joint probability is the product of their individual probabilities: \\[ P(A \\cap B) = P(A) \\times P(B) \\]"
                },
                {
                    "front": "What is an example of joint probability?",
                    "back": "Suppose you are rolling two dice. The probability of rolling a 6 on the first die and a 6 on the second die is the joint probability $P(6 \\cap 6)$. Since these events are independent, you can calculate this by multiplying the probabilities: \\[ P(6 \\cap 6) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36} \\]"
                },
                {
                    "front": "How does joint probability differ for dependent events?",
                    "back": "For dependent events, the joint probability is not simply the product of individual probabilities. Instead, you must use the conditional probability formula: \\[ P(A \\cap B) = P(A) \\times P(B|A) \\] This accounts for the fact that the occurrence of event A influences the probability of event B."
                },
                {
                    "front": "What is joint probability?",
                    "back": "Joint probability is the probability that two or more events occur together. For two events A and B, the joint probability $P(A \\cap B)$ represents the likelihood that both A and B happen. If the events are <b>independent</b>, the joint probability is the product of their individual probabilities: \\[ P(A \\cap B) = P(A) \\times P(B) \\]"
                },
                {
                    "front": "What is an example of joint probability?",
                    "back": "Suppose you are rolling two dice. The probability of rolling a 6 on the first die and a 6 on the second die is the joint probability $P(6 \\cap 6)$. Since these events are independent, you can calculate this by multiplying the probabilities: \\[ P(6 \\cap 6) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36} \\]"
                },
                {
                    "front": "How does joint probability differ for dependent events?",
                    "back": "For dependent events, the joint probability is not simply the product of individual probabilities. Instead, you must use the conditional probability formula: \\[ P(A \\cap B) = P(A) \\times P(B|A) \\] This accounts for the fact that the occurrence of event A influences the probability of event B."
                }
            ]
        },
        {
            "name": "Marginal Probability",
            "cards": [
                {
                    "front": "What is marginal probability?",
                    "back": "Marginal probability refers to the probability of a single event occurring, without regard to other events. It is derived from the joint probabilities by summing over all possible outcomes for other variables. For example, the marginal probability of A can be written as: \\[ P(A) = \\sum_{B} P(A \\cap B) \\]"
                },
                {
                    "front": "How does marginal probability relate to joint probability?",
                    "back": "Marginal probability is the result of <b>summing</b> or <b>integrating</b> over the joint probabilities of related events. For example, if A and B are two events, the marginal probability of A is obtained by summing the joint probabilities of A occurring with each possible outcome of B."
                },
                {
                    "front": "What is marginal probability?",
                    "back": "Marginal probability refers to the probability of a single event occurring, without regard to other events. It is derived from the joint probabilities by summing over all possible outcomes for other variables. For example, the marginal probability of A can be written as: \\[ P(A) = \\sum_{B} P(A \\cap B) \\]"
                },
                {
                    "front": "How does marginal probability relate to joint probability?",
                    "back": "Marginal probability is the result of <b>summing</b> or <b>integrating</b> over the joint probabilities of related events. For example, if A and B are two events, the marginal probability of A is obtained by summing the joint probabilities of A occurring with each possible outcome of B."
                }
            ]
        },
        {
            "name": "Independence",
            "cards": [
                {
                    "front": "What does it mean for two events to be independent?",
                    "back": "Two events are independent if the occurrence of one does not affect the probability of the other. Mathematically, events A and B are independent if: \\[ P(A \\cap B) = P(A) \\times P(B) \\] In this case, knowing that event B has occurred gives no additional information about the likelihood of A occurring, and vice versa."
                },
                {
                    "front": "How can you test if two events are independent?",
                    "back": "To test for independence, check if the joint probability $P(A \\cap B)$ equals the product of the individual probabilities $P(A) \\times P(B)$. If the equality holds, the events are independent; otherwise, they are dependent."
                },
                {
                    "front": "What does it mean for two events to be independent?",
                    "back": "Two events are independent if the occurrence of one does not affect the probability of the other. Mathematically, events A and B are independent if: \\[ P(A \\cap B) = P(A) \\times P(B) \\] In this case, knowing that event B has occurred gives no additional information about the likelihood of A occurring, and vice versa."
                },
                {
                    "front": "How can you test if two events are independent?",
                    "back": "To test for independence, check if the joint probability $P(A \\cap B)$ equals the product of the individual probabilities $P(A) \\times P(B)$. If the equality holds, the events are independent; otherwise, they are dependent."
                }
            ]
        },
        {
            "name": "Law of Total Probability",
            "cards": [
                {
                    "front": "What is the Law of Total Probability?",
                    "back": "The Law of Total Probability states that if you have a set of mutually exclusive events $B_1, B_2, ..., B_n$ that cover all possible outcomes, the probability of any event A can be expressed as: \\[ P(A) = \\sum_{i} P(A|B_i) P(B_i) \\] This law is useful for breaking down complex probability problems by considering all possible conditions."
                },
                {
                    "front": "What is the Law of Total Probability?",
                    "back": "The Law of Total Probability states that if you have a set of mutually exclusive events $B_1, B_2, ..., B_n$ that cover all possible outcomes, the probability of any event A can be expressed as: \\[ P(A) = \\sum_{i} P(A|B_i) P(B_i) \\] This law is useful for breaking down complex probability problems by considering all possible conditions."
                }
            ]
        },
        {
            "name": "Correlation",
            "cards": [
                {
                    "front": "What is correlation?",
                    "back": "<b>Correlation</b> is a statistical measure that describes the strength and direction of a linear relationship between two variables. It is quantified by the <b>correlation coefficient</b> (denoted by \\(r\\)), which ranges from -1 to 1: - <b>\\(r = 1\\)</b>: Perfect positive correlation. - <b>\\(r = -1\\)</b>: Perfect negative correlation. - <b>\\(r = 0\\)</b>: No linear correlation."
                },
                {
                    "front": "What is a positive correlation?",
                    "back": "A <b>positive correlation</b> occurs when an increase in one variable is associated with an increase in another variable. For example, in a dataset, if higher temperatures tend to correspond with higher ice cream sales, this indicates a positive correlation."
                },
                {
                    "front": "What is a negative correlation?",
                    "back": "A <b>negative correlation</b> occurs when an increase in one variable is associated with a decrease in another variable. For instance, if higher temperatures lead to lower heating costs, this reflects a negative correlation."
                },
                {
                    "front": "What is the difference between correlation and causation?",
                    "back": "<b>Correlation</b> indicates that two variables are related, but it does not imply that one variable causes the other. <b>Causation</b>, on the other hand, means that changes in one variable directly cause changes in the other. Correlation does not establish causality without further analysis."
                },
                {
                    "front": "How do you interpret the value of the Pearson correlation coefficient?",
                    "back": "The <b>Pearson correlation coefficient</b> (denoted \\(r\\)) measures the strength and direction of a linear relationship between two variables: - <b>\\(r = 1\\)</b>: Perfect positive linear relationship. - <b>\\(r = -1\\)</b>: Perfect negative linear relationship. - <b>\\(0.7 \\leq r < 1\\)</b>: Strong positive correlation. - <b>\\(0.3 \\leq r < 0.7\\)</b>: Moderate positive correlation. - <b>\\(0 < r < 0.3\\)</b>: Weak positive correlation. - <b>\\(r = 0\\)</b>: No correlation. The same scale applies for negative values."
                }
            ]
        },
        {
            "name": "Linear Regression",
            "cards": [
                {
                    "front": "What is simple linear regression?",
                    "back": "<b>Simple linear regression</b> is a statistical method used to model the relationship between two variables: one <b>independent variable</b> (predictor) and one <b>dependent variable</b> (outcome). The goal is to find the best-fitting straight line (regression line) that minimizes the distance between observed values and predicted values. The equation of the regression line is: \\[ Y = \\beta_0 + \\beta_1 X + \\epsilon \\] where \\(Y\\) is the dependent variable, \\(X\\) is the independent variable, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the slope, and \\(\\epsilon\\) is the error term."
                },
                {
                    "front": "How do you interpret the slope and intercept in linear regression?",
                    "back": "- The <b>slope</b> (\\(\\beta_1\\)) represents the change in the dependent variable (\\(Y\\)) for every one-unit increase in the independent variable (\\(X\\)). If \\(\\beta_1\\) is positive, \\(Y\\) increases as \\(X\\) increases; if \\(\\beta_1\\) is negative, \\(Y\\) decreases as \\(X\\) increases. - The <b>intercept</b> (\\(\\beta_0\\)) is the predicted value of \\(Y\\) when \\(X = 0\\). It indicates the starting point of the regression line on the Y-axis."
                },
                {
                    "front": "What is the residual in a regression model?",
                    "back": "A <b>residual</b> is the difference between an observed value and the value predicted by the regression model. It is calculated as: \\[ \\text{Residual} = Y_{\\text{observed}} - Y_{\\text{predicted}} \\] Residuals are used to evaluate the fit of the model, with smaller residuals indicating a better fit."
                },
                {
                    "front": "What is the objective of the least squares method in linear regression?",
                    "back": "The <b>least squares method</b> aims to minimize the sum of the squared residuals (the differences between observed and predicted values). By minimizing this quantity, the regression line is optimized to fit the data as closely as possible."
                }
            ]
        },
        {
            "name": "Multiple Regression",
            "cards": [
                {
                    "front": "What is multiple linear regression?",
                    "back": "<b>Multiple linear regression</b> is an extension of simple linear regression that models the relationship between a dependent variable and two or more independent variables. The regression equation is: \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n + \\epsilon \\] where \\(X_1, X_2, ..., X_n\\) are the independent variables, and \\(\\beta_1, \\beta_2, ..., \\beta_n\\) are their respective coefficients."
                },
                {
                    "front": "What does multicollinearity mean in multiple regression?",
                    "back": "<b>Multicollinearity</b> occurs when two or more independent variables in a multiple regression model are highly correlated with each other. This can make it difficult to determine the individual effect of each variable on the dependent variable, leading to inflated standard errors and unreliable coefficient estimates."
                },
                {
                    "front": "How can you detect multicollinearity?",
                    "back": "Multicollinearity can be detected using several methods: 1. <b>Variance Inflation Factor (VIF)</b>: A VIF value greater than 10 indicates high multicollinearity. 2. <b>Correlation matrix</b>: High correlations between independent variables suggest multicollinearity. 3. <b>Eigenvalues</b>: Small eigenvalues of the correlation matrix can indicate multicollinearity."
                },
                {
                    "front": "What is the adjusted R² in multiple regression?",
                    "back": "The <b>adjusted R²</b> is a modified version of the R² that accounts for the number of independent variables in the model. It adjusts for the fact that adding more variables can artificially increase the R², even if those variables do not improve the model. Adjusted R² provides a more accurate measure of the model's explanatory power."
                }
            ]
        },
        {
            "name": "Assumptions of Regression",
            "cards": [
                {
                    "front": "What are the key assumptions of linear regression?",
                    "back": "The key assumptions of linear regression are: 1. <b>Linearity</b>: The relationship between the independent and dependent variables is linear. 2. <b>Independence</b>: The observations are independent of each other. 3. <b>Homoscedasticity</b>: The variance of residuals is constant across all levels of the independent variables. 4. <b>Normality</b>: The residuals are normally distributed. 5. <b>No multicollinearity</b> (for multiple regression): The independent variables are not highly correlated with each other."
                },
                {
                    "front": "What is homoscedasticity?",
                    "back": "<b>Homoscedasticity</b> refers to the assumption that the variance of the residuals is constant across all levels of the independent variables. In other words, the spread of the residuals should be roughly the same regardless of the value of the independent variables. A violation of this assumption can lead to inefficient estimates in the regression model."
                },
                {
                    "front": "How do you check for normality of residuals in a regression model?",
                    "back": "To check for normality of residuals, you can: 1. <b>Plot a histogram</b> of the residuals: If the residuals are normally distributed, the histogram should resemble a bell curve. 2. <b>Use a Q-Q plot</b>: In a Q-Q (quantile-quantile) plot, the points should fall along a straight line if the residuals are normally distributed. 3. <b>Perform a normality test</b>: Tests like the Shapiro-Wilk test or Kolmogorov-Smirnov test can be used to assess the normality of residuals."
                }
            ]
        },
        {
            "name": "Coefficient of Determination (R²)",
            "cards": [
                {
                    "front": "What is the coefficient of determination (R²)?",
                    "back": "The <b>coefficient of determination (R²)</b> measures the proportion of the variance in the dependent variable that is explained by the independent variables in the model. It ranges from 0 to 1: - <b>R² = 1</b>: Perfect fit (the model explains 100% of the variance). - <b>R² = 0</b>: The model explains none of the variance."
                },
                {
                    "front": "How do you interpret R²?",
                    "back": "- A higher <b>R²</b> value indicates that a larger proportion of the variance in the dependent variable is explained by the independent variable(s). - For example, an R² of 0.80 means that 80% of the variation in the dependent variable is explained by the independent variable(s), and 20% is unexplained."
                },
                {
                    "front": "What are the limitations of R²?",
                    "back": "While <b>R²</b> indicates the goodness of fit of a model, it has limitations: - <b>R² increases</b> as more variables are added to the model, even if those variables do not improve the model’s predictive power. This can lead to overfitting. - It does not indicate whether the independent variables are meaningful predictors or whether the model assumptions are met. For multiple regression, <b>adjusted R²</b> is used to address these limitations."
                }
            ]
        },
        {
            "name": "Residual Analysis",
            "cards": [
                {
                    "front": "What is residual analysis in regression?",
                    "back": "<b>Residual analysis</b> involves examining the residuals (the differences between observed and predicted values) to evaluate the fit of a regression model. Residual analysis helps in identifying violations of assumptions like linearity, homoscedasticity, and normality, and can uncover outliers or influential data points."
                },
                {
                    "front": "How do you detect heteroscedasticity in residuals?",
                    "back": "<b>Heteroscedasticity</b> occurs when the variance of the residuals is not constant. To detect heteroscedasticity, you can: 1. <b>Plot residuals vs. predicted values</b>: If the spread of residuals increases or decreases as the predicted values change, heteroscedasticity may be present. 2. <b>Breusch-Pagan test</b>: A statistical test that can be used to detect heteroscedasticity. 3. <b>White’s test</b>: Another test for heteroscedasticity that does not assume a specific form for the relationship between the residual variance and predictors."
                }
            ]
        },
        {
            "name": "Logistic Regression",
            "cards": [
                {
                    "front": "What is logistic regression?",
                    "back": "<b>Logistic regression</b> is used when the dependent variable is binary (e.g., 0 or 1, yes or no). It models the probability that a certain event will occur, based on one or more independent variables. The logistic regression model uses the <b>logit function</b> to map predicted values to a probability between 0 and 1: \\[ \\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_n X_n \\] where \\(p\\) is the probability of the event occurring."
                },
                {
                    "front": "How do you interpret coefficients in logistic regression?",
                    "back": "In <b>logistic regression</b>, the coefficients (\\(\\beta\\)) represent the change in the <b>log-odds</b> of the dependent variable occurring for a one-unit change in the independent variable. The exponentiated coefficient (\\(e^{\\beta}\\)) gives the <b>odds ratio</b>, which can be interpreted as the change in the odds of the event occurring for a one-unit increase in the independent variable."
                },
                {
                    "front": "What is the difference between linear and logistic regression?",
                    "back": "- <b>Linear regression</b> is used to predict a continuous dependent variable, while <b>logistic regression</b> is used to predict a binary outcome. - In linear regression, the relationship between the independent and dependent variables is linear, whereas logistic regression models the probability of an event occurring using the logit function, producing outputs between 0 and 1."
                }
            ]
        },
        {
            "name": "Measures of Central Tendency",
            "cards": [
                {
                    "front": "What is the mean?",
                    "back": "The <b>mean</b> is the sum of all data values divided by the number of data points. It is the most commonly used measure of central tendency and represents the average of a dataset. The formula for the mean is: \\[ \\text{Mean} = \\frac{\\sum X_i}{n} \\] where \\( X_i \\) are the individual data points, and \\( n \\) is the number of data points."
                },
                {
                    "front": "What are some limitations of using the mean?",
                    "back": "The mean can be heavily influenced by outliers, or extremely high or low values, which can distort the representation of the central tendency. Additionally, the mean is not always appropriate for skewed data distributions, where the median may be a better measure."
                },
                {
                    "front": "What is the median?",
                    "back": "The <b>median</b> is the middle value of a dataset when the data is ordered from smallest to largest. If there is an even number of data points, the median is the average of the two middle values. Unlike the mean, the median is less affected by outliers and skewed data."
                },
                {
                    "front": "How do you calculate the mode?",
                    "back": "The <b>mode</b> is the value that appears most frequently in a dataset. A dataset can have no mode, one mode (unimodal), or multiple modes (bimodal, multimodal) if there are several values that occur with the same highest frequency."
                }
            ]
        },
        {
            "name": "Measures of Dispersion",
            "cards": [
                {
                    "front": "What is range?",
                    "back": "The <b>range</b> is the difference between the largest and smallest values in a dataset. It provides a simple measure of data dispersion, though it can be heavily influenced by outliers. The formula for the range is: \\[ \\text{Range} = \\text{Max} - \\text{Min} \\]"
                },
                {
                    "front": "How do you calculate variance?",
                    "back": "<b>Variance</b> measures the average squared deviation of each data point from the mean. It quantifies how spread out the data points are. The formula for variance is: \\[ \\text{Variance} (\\sigma^2) = \\frac{\\sum (X_i - \\mu)^2}{n} \\] where \\( X_i \\) are the data points, \\( \\mu \\) is the mean, and \\( n \\) is the number of data points."
                },
                {
                    "front": "What is standard deviation?",
                    "back": "<b>Standard deviation</b> is the square root of the variance. It is a widely used measure of dispersion that provides insight into the average distance of data points from the mean. A smaller standard deviation indicates that data points are clustered close to the mean, while a larger standard deviation suggests greater spread. The formula is: \\[ \\text{Standard Deviation} (\\sigma) = \\sqrt{\\frac{\\sum (X_i - \\mu)^2}{n}} \\]"
                },
                {
                    "front": "Why is standard deviation preferred over variance?",
                    "back": "Standard deviation is often preferred over variance because it is in the same units as the original data, making it easier to interpret. Variance, on the other hand, is in squared units, which can make the measure less intuitive."
                }
            ]
        },
        {
            "name": "Data Distribution",
            "cards": [
                {
                    "front": "What is a frequency distribution?",
                    "back": "A <b>frequency distribution</b> is a summary of how often different values or categories occur within a dataset. It can be visualized using tables or charts such as histograms, showing the frequency of each data point or category."
                },
                {
                    "front": "What is a histogram?",
                    "back": "A <b>histogram</b> is a type of bar chart that represents the distribution of numerical data. The data is divided into intervals, or bins, and the height of each bar represents the frequency of data points within that bin. Histograms are useful for identifying the shape of data distributions."
                },
                {
                    "front": "What is skewness in a distribution?",
                    "back": "<b>Skewness</b> refers to the asymmetry in the distribution of data. A distribution is said to be: - <b>Positively skewed</b> (right-skewed) if the tail on the right side is longer, indicating that there are more high outliers. - <b>Negatively skewed</b> (left-skewed) if the tail on the left side is longer, indicating that there are more low outliers. If the distribution is symmetrical, skewness is zero."
                },
                {
                    "front": "What is kurtosis?",
                    "back": "<b>Kurtosis</b> measures the \"tailedness\" of a distribution, or the tendency of data points to cluster in the tails or near the mean. Distributions with high kurtosis have more data points in the tails (leptokurtic), while those with low kurtosis have fewer points in the tails (platykurtic). A normal distribution has a kurtosis of 3 (mesokurtic)."
                }
            ]
        },
        {
            "name": "Percentiles and Quartiles",
            "cards": [
                {
                    "front": "What is a percentile?",
                    "back": "A <b>percentile</b> is a measure that indicates the value below which a given percentage of data points fall. For example, the 90th percentile is the value below which 90% of the data points lie. Percentiles are useful for comparing individual data points to the overall dataset."
                },
                {
                    "front": "How do you calculate quartiles?",
                    "back": "<b>Quartiles</b> divide a dataset into four equal parts, each containing 25% of the data. The <b>first quartile (Q1)</b> is the 25th percentile, the <b>second quartile (Q2)</b> is the median or 50th percentile, and the <b>third quartile (Q3)</b> is the 75th percentile. Quartiles help in understanding the spread and distribution of data."
                },
                {
                    "front": "What is the interquartile range (IQR)?",
                    "back": "The <b>interquartile range (IQR)</b> is the range between the first quartile (Q1) and the third quartile (Q3). It measures the spread of the middle 50% of the data and is a useful measure of dispersion that is not affected by outliers. The formula is: \\[ \\text{IQR} = Q3 - Q1 \\]"
                }
            ]
        },
        {
            "name": "Z-scores",
            "cards": [
                {
                    "front": "What is a Z-score?",
                    "back": "A <b>Z-score</b> represents how many standard deviations a data point is from the mean of a dataset. It is used to standardize data, allowing for comparisons across different datasets or variables with different units. The formula is: \\[ Z = \\frac{X - \\mu}{\\sigma} \\] where \\( X \\) is the data point, \\( \\mu \\) is the mean, and \\( \\sigma \\) is the standard deviation."
                },
                {
                    "front": "Why are Z-scores useful?",
                    "back": "Z-scores are useful for standardizing data, which allows for comparison between data points from different distributions. For example, you can use Z-scores to compare exam scores across different subjects, even if the exams have different means and standard deviations."
                },
                {
                    "front": "What does a positive or negative Z-score indicate?",
                    "back": "A <b>positive Z-score</b> indicates that the data point is above the mean, while a <b>negative Z-score</b> indicates that the data point is below the mean. A Z-score of 0 means that the data point is exactly at the mean."
                }
            ]
        },
        {
            "name": "Outliers",
            "cards": [
                {
                    "front": "What is an outlier?",
                    "back": "An <b>outlier</b> is a data point that differs significantly from the rest of the data. Outliers can be caused by measurement errors, variability in the data, or rare occurrences. They can have a significant impact on statistical measures such as the mean and variance."
                },
                {
                    "front": "How do you identify outliers?",
                    "back": "Outliers can be identified using various methods: - <b>Z-score method</b>: Data points with Z-scores greater than 3 or less than -3 are often considered outliers. - <b>IQR method</b>: Data points that are below \\( Q1 - 1.5 \\times \\text{IQR} \\) or above \\( Q3 + 1.5 \\times \\text{IQR} \\) are considered outliers."
                },
                {
                    "front": "What is the impact\n\n of outliers on data analysis?",
                    "back": "Outliers can skew the results of data analysis by inflating or deflating measures like the mean and standard deviation. It is important to identify and address outliers, as they may represent errors or rare but significant data points."
                }
            ]
        },
        {
            "name": "Graphical Summaries",
            "cards": [
                {
                    "front": "What is a bar plot?",
                    "back": "A <b>bar plot</b> is a graphical representation of categorical data where the length of each bar corresponds to the frequency or count of each category. Bar plots are useful for comparing different categories or groups within a dataset."
                },
                {
                    "front": "What is a box plot?",
                    "back": "A <b>box plot</b> (or box-and-whisker plot) is a graphical summary that shows the distribution of a dataset based on five summary statistics: minimum, first quartile (Q1), median, third quartile (Q3), and maximum. The \"whiskers\" extend to the smallest and largest values, and any points outside this range may be considered outliers."
                },
                {
                    "front": "What is the purpose of using a histogram?",
                    "back": "A <b>histogram</b> helps visualize the distribution of numerical data by showing the frequency of data points within predefined intervals or bins. It provides insight into the shape, center, and spread of the data, as well as whether the data is skewed or symmetric."
                }
            ]
        },
        {
            "name": "Hypothesis Testing",
            "cards": [
                {
                    "front": "What is a null hypothesis?",
                    "back": "The <b>null hypothesis</b> (denoted \\(H_0\\)) is a statement that there is no effect or no difference, and it serves as the default assumption in hypothesis testing. It is the hypothesis that researchers aim to test or reject. For example, in a test comparing two means, the null hypothesis might state that the means are equal: \\[ H_0: \\mu_1 = \\mu_2 \\]"
                },
                {
                    "front": "What is an alternative hypothesis?",
                    "back": "The <b>alternative hypothesis</b> (denoted \\(H_a\\) or \\(H_1\\)) is the statement that contradicts the null hypothesis. It proposes that there is an effect or a difference. For example, in the same test comparing two means, the alternative hypothesis might state: \\[ H_a: \\mu_1 \\neq \\mu_2 \\] The alternative hypothesis is what researchers aim to support through evidence."
                },
                {
                    "front": "What are the steps in hypothesis testing?",
                    "back": "The basic steps in hypothesis testing are: 1. <b>State the null and alternative hypotheses</b>. 2. <b>Choose a significance level</b> (\\(\\alpha\\)), commonly set at 0.05. 3. <b>Select the appropriate test</b> (e.g., t-test, z-test, chi-square test). 4. <b>Calculate the test statistic</b> based on the sample data. 5. <b>Determine the p-value</b> or critical value for the test statistic. 6. <b>Make a decision</b>: Reject or fail to reject the null hypothesis based on the comparison of the p-value and the significance level. 7. <b>Interpret the results</b> in the context of the original research question."
                },
                {
                    "front": "When should you reject the null hypothesis?",
                    "back": "The null hypothesis is rejected if the p-value is less than or equal to the significance level (\\(\\alpha\\)), indicating that the observed data is unlikely to occur if the null hypothesis were true. For example, if \\(\\alpha = 0.05\\) and the p-value is 0.03, you would reject the null hypothesis."
                },
                {
                    "front": "What is a one-tailed test?",
                    "back": "A <b>one-tailed test</b> is a hypothesis test where the alternative hypothesis specifies a direction of the effect (e.g., greater than or less than). It tests whether the parameter is either larger or smaller than the null hypothesis value, but not both. For example: \\[ H_a: \\mu_1 > \\mu_2 \\] This test is used when the research question has a specific directional expectation."
                },
                {
                    "front": "What is a two-tailed test?",
                    "back": "A <b>two-tailed test</b> is a hypothesis test where the alternative hypothesis does not specify a direction, meaning it checks for any difference from the null hypothesis value in either direction. For example: \\[ H_a: \\mu_1 \\neq \\mu_2 \\] It tests for both possibilities (greater or less), and is used when there is no specific directional assumption in the research."
                }
            ]
        },
        {
            "name": "Confidence Intervals",
            "cards": [
                {
                    "front": "What is a confidence interval?",
                    "back": "A <b>confidence interval</b> is a range of values, derived from the sample data, that is likely to contain the true population parameter with a specified level of confidence. For example, a 95% confidence interval means that if the experiment were repeated many times, approximately 95% of the intervals would contain the true population parameter."
                },
                {
                    "front": "How do you interpret a 95% confidence interval?",
                    "back": "A 95% confidence interval indicates that you are 95% confident that the true population parameter lies within the calculated range. It does not mean that there is a 95% chance the parameter is within the interval; rather, it reflects the confidence in the method used to estimate the interval."
                },
                {
                    "front": "What is the formula for a confidence interval for the mean?",
                    "back": "The formula for a confidence interval for the population mean, assuming a normally distributed population and known standard deviation, is: \\[ \\text{CI} = \\bar{X} \\pm Z \\times \\frac{\\sigma}{\\sqrt{n}} \\] where: - \\(\\bar{X}\\) is the sample mean, - \\(Z\\) is the critical value from the standard normal distribution corresponding to the desired confidence level (e.g., 1.96 for 95% confidence), - \\(\\sigma\\) is the population standard deviation (or sample standard deviation if \\(\\sigma\\) is unknown), - \\(n\\) is the sample size."
                },
                {
                    "front": "What factors affect the width of a confidence interval?",
                    "back": "The width of a confidence interval depends on: 1. <b>Sample size</b>: Larger sample sizes result in narrower confidence intervals. 2. <b>Confidence level</b>: Higher confidence levels (e.g., 99% vs. 95%) result in wider intervals. 3. <b>Standard deviation</b>: Larger variability (standard deviation) increases the width of the confidence interval."
                },
                {
                    "front": "What is the relationship between confidence intervals and hypothesis testing?",
                    "back": "Confidence intervals and hypothesis testing are closely related. If the value specified in the null hypothesis lies outside the confidence interval, the null hypothesis can be rejected at the corresponding significance level. For example, if a 95% confidence interval for a mean does not include the null hypothesis value, you would reject the null hypothesis at \\(\\alpha = 0.05\\)."
                }
            ]
        },
        {
            "name": "Type I and Type II Errors",
            "cards": [
                {
                    "front": "What is a Type I error?",
                    "back": "A <b>Type I error</b> occurs when the null hypothesis is rejected when it is actually true. This is also known as a \"false positive\" or rejecting a true null hypothesis. The probability of making a Type I error is denoted by \\(\\alpha\\), which is the significance level of the test (e.g., \\(\\alpha = 0.05\\) means a 5% chance of a Type I error)."
                },
                {
                    "front": "What is a Type II error?",
                    "back": "A <b>Type II error</b> occurs when the null hypothesis is not rejected when it is actually false. This is also known as a \"false negative\" or failing to reject a false null hypothesis. The probability of making a Type II error is denoted by \\(\\beta\\)."
                },
                {
                    "front": "What is the relationship between Type I and Type II errors?",
                    "back": "There is an inverse relationship between Type I and Type II errors. Reducing the risk of a Type I error (lowering \\(\\alpha\\)) increases the risk of a Type II error (\\(\\beta\\)), and vice versa. Balancing the two types of errors often involves choosing an appropriate significance level based on the context of the research."
                },
                {
                    "front": "How can you reduce Type I and Type II errors?",
                    "back": "You can reduce Type I and Type II errors by: 1. <b>Increasing the sample size</b>: This increases the power of the test, reducing \\(\\beta\\). 2. <b>Adjusting the significance level</b>: Lowering \\(\\alpha\\) reduces Type I errors, though it may increase Type II errors. 3. <b>Improving the precision of measurements</b>: Better data collection reduces variability, which can lower both types of errors."
                }
            ]
        },
        {
            "name": "P-values",
            "cards": [
                {
                    "front": "What is a p-value?",
                    "back": "A <b>p-value</b> is the probability of obtaining results as extreme as, or more extreme than, the observed data under the assumption that the null hypothesis is true. It quantifies the strength of evidence against the null hypothesis. A smaller p-value indicates stronger evidence to reject the null hypothesis."
                },
                {
                    "front": "How do you interpret a p-value?",
                    "back": "- If the <b>p-value</b> is less than or equal to the significance level (\\(\\alpha\\)), you reject the null hypothesis. - If the p-value is greater than \\(\\alpha\\), you fail to reject the null hypothesis. For example, with \\(\\alpha = 0.05\\), a p-value of 0.02 suggests significant evidence against the null hypothesis."
                },
                {
                    "front": "What are some common misconceptions about p-values?",
                    "back": "Common misconceptions include: - A <b>p-value</b> does not measure the probability that the null hypothesis is true. - A <b>p-value</b> does not indicate the size or importance of an effect. - A <b>p-value</b> greater than 0.05 does not \"prove\" that the null hypothesis is true; it only suggests insufficient evidence to reject it."
                }
            ]
        },
        {
            "name": "Significance Levels",
            "cards": [
                {
                    "front": "What is a significance level?",
                    "back": "The <b>significance level</b> (denoted \\(\\alpha\\)) is the threshold used to decide whether to reject the null hypothesis. It represents the probability of making a Type I error (rejecting a true null hypothesis). Common significance levels include 0.05, 0.01, and 0.10."
                },
                {
                    "front": "How do you choose an appropriate significance level?",
                    "back": "The choice of <b>significance level</b> depends on the context of the research: - In fields like medicine, a lower \\(\\alpha\\) (e.g., 0.01) may be used to minimize the risk of Type I errors (false positives). - In exploratory research, a higher \\(\\alpha\\) (e.g., 0.10) may be acceptable to balance the risk of Type II errors (false negatives)."
                }
            ]
        },
        {
            "name": "Power of a Test",
            "cards": [
                {
                    "front": "What is the power of a test?",
                    "back": "The <b>power</b> of a test is the probability that the test correctly rejects the null hypothesis when it is false (i.e., it avoids a Type II error). Power is calculated as \\(1 - \\beta\\), where \\(\\beta\\) is the probability of a Type II error. High power means the test is more likely to detect an effect if it exists."
                },
                {
                    "front": "What factors affect the power of a test?",
                    "back": "Factors that affect the power of a test include: 1. <b>Sample size</b>: Larger sample sizes increase power. 2. <b>Effect size</b>: Larger effects are easier to detect, increasing power. 3. <b>Significance level (\\(\\alpha\\))</b>: A higher \\(\\alpha\\) increases power but also increases the chance of a Type I error. 4. <b>Variance</b>: Lower variability in the data increases power."
                },
                {
                    "front": "Why is the power of a test important?",
                    "back": "The power of a test is important because it determines the likelihood of detecting an effect if one truly exists. Low-power tests have a higher risk of producing false negatives (Type II errors), potentially missing important findings. Power analysis is often conducted before an experiment to ensure sufficient sample size."
                }
            ]
        },
        {
            "name": "Time Series Components",
            "cards": [
                {
                    "front": "What are the main components of a time series?",
                    "back": "A time series can be decomposed into three main components: 1. <b>Trend</b>: The long-term direction of the series (upward, downward, or flat). 2. <b>Seasonality</b>: Regular, repeating patterns that occur over specific intervals (e.g., quarterly sales increases). 3. <b>Residual (Noise)</b>: Random fluctuations that are not explained by trend or seasonality."
                },
                {
                    "front": "What is an example of seasonality in time series data?",
                    "back": "An example of seasonality would be retail sales that peak every December due to holiday shopping. This repeating annual pattern in sales data is a typical seasonal component."
                },
                {
                    "front": "How can a trend affect a time series?",
                    "back": "A <b>trend</b> represents the long-term movement in the data over time. It can be upward (increasing values), downward (decreasing values), or stationary (no consistent change). For example, a rising trend in stock prices over several years indicates an overall upward movement despite short-term fluctuations."
                }
            ]
        },
        {
            "name": "Stationarity",
            "cards": [
                {
                    "front": "What is a stationary time series?",
                    "back": "A <b>stationary time series</b> is one where the statistical properties (mean, variance, and autocorrelation) are constant over time. A stationary series does not exhibit trends or seasonality and is essential for many time series models, including ARIMA."
                },
                {
                    "front": "How do you test for stationarity?",
                    "back": "The <b>Augmented Dickey-Fuller (ADF) test</b> is commonly used to test for stationarity. If the p-value of the test is less than a chosen significance level (e.g., 0.05), the null hypothesis (that the series is non-stationary) can be rejected, indicating that the series is stationary."
                },
                {
                    "front": "How do you make a time series stationary?",
                    "back": "To make a time series stationary, you can: 1. <b>Differencing</b>: Subtracting each observation from the previous one to remove trends. 2. <b>De-trending</b>: Removing the trend component. 3. <b>Log transformation</b>: Reducing variance by applying a logarithmic transformation to the data. 4. <b>Seasonal differencing</b>: Subtracting observations from the corresponding value in the previous season to remove seasonality."
                }
            ]
        },
        {
            "name": "Autocorrelation and Partial Autocorrelation",
            "cards": [
                {
                    "front": "What is autocorrelation?",
                    "back": "<b>Autocorrelation</b> is the correlation of a time series with a lagged version of itself. It measures how current values of the series relate to past values. Positive autocorrelation indicates that high values tend to follow high values, and negative autocorrelation indicates that high values follow low values."
                },
                {
                    "front": "What is a partial autocorrelation function (PACF)?",
                    "back": "The <b>partial autocorrelation function (PACF)</b> measures the correlation between the current time series value and its lagged values, controlling for the values of the time series at shorter lags. PACF helps identify the number of autoregressive (AR) terms needed in an ARIMA model."
                },
                {
                    "front": "What are ACF and PACF plots used for?",
                    "back": "<b>ACF (Autocorrelation Function) plots</b> show how the correlation between time series values decreases as the lag increases, while <b>PACF plots</b> show the partial correlation at each lag, adjusting for earlier lags. These plots are used to identify the appropriate parameters for ARIMA models."
                }
            ]
        },
        {
            "name": "Moving Averages",
            "cards": [
                {
                    "front": "What is a simple moving average?",
                    "back": "A <b>simple moving average (SMA)</b> is the unweighted mean of a fixed number of past observations. It smooths out fluctuations in a time series by averaging over a sliding window of previous values, making it easier to identify trends. The formula is: \\[ \\text{SMA}_t = \\frac{1}{n} \\sum_{i=t-n+1}^{t} X_i \\] where \\(n\\) is the window size."
                },
                {
                    "front": "What is an exponential moving average (EMA)?",
                    "back": "An <b>exponential moving average (EMA)</b> gives more weight to recent observations compared to older ones, making it more responsive to changes in the time series. The EMA is calculated recursively, using a smoothing factor that controls how much weight is given to recent data points."
                },
                {
                    "front": "How are moving averages used in time series forecasting?",
                    "back": "<b>Moving averages</b> smooth out short-term fluctuations in time series data, making it easier to identify underlying trends and seasonality. In forecasting, they are often used to estimate future values by extrapolating current trends or to remove noise from the data."
                }
            ]
        },
        {
            "name": "ARIMA Models",
            "cards": [
                {
                    "front": "What does ARIMA stand for?",
                    "back": "<b>ARIMA</b> stands for <b>AutoRegressive Integrated Moving Average</b>: 1. <b>AR (AutoRegressive)</b>: Uses past values (lags) to predict future values. 2. <b>I (Integrated)</b>: Involves differencing the data to make it stationary. 3. <b>MA (Moving Average)</b>: Uses past forecast errors to improve predictions. ARIMA models are commonly used for time series forecasting when the data shows no strong seasonal component."
                },
                {
                    "front": "What are the parameters of an ARIMA model?",
                    "back": "An ARIMA model is defined by three parameters: 1. <b>p</b>: The number of autoregressive (AR) terms. 2. <b>d</b>: The number of differences needed to make the series stationary. 3. <b>q</b>: The number of moving average (MA) terms. The notation ARIMA(p, d, q) specifies how many terms are included for each component."
                },
                {
                    "front": "What is the difference between ARIMA and SARIMA?",
                    "back": "<b>SARIMA (Seasonal ARIMA)</b> extends ARIMA by incorporating seasonality into the model. SARIMA includes additional parameters for seasonal autoregressive, seasonal differencing, and seasonal moving average components, denoted by (P, D, Q, m), where \\(m\\) is the length of the seasonal cycle. The full SARIMA model is expressed as ARIMA(p, d, q)(P, D, Q)_m."
                }
            ]
        },
        {
            "name": "Seasonal Decomposition",
            "cards": [
                {
                    "front": "What is seasonal decomposition of time series?",
                    "back": "<b>Seasonal decomposition</b> breaks down a time series into its main components: <b>trend</b>, <b>seasonality</b>, and <b>residuals</b> (random fluctuations). Methods like <b>STL (Seasonal-Trend Decomposition using Loess)</b> are commonly used to separate these components, making it easier to understand and model the series."
                },
                {
                    "front": "Why is it important to decompose a time series?",
                    "back": "Decomposing a time series allows you to better understand its structure by separating the trend, seasonal, and noise components. This is useful for improving forecasts and identifying underlying patterns, especially when the series has complex seasonal effects."
                }
            ]
        },
        {
            "name": "Forecasting",
            "cards": [
                {
                    "front": "What is time series forecasting?",
                    "back": "<b>Time series forecasting</b> involves predicting future values based on historical time series data. Techniques like <b>ARIMA</b>, <b>SARIMA</b>, <b>Exponential Smoothing</b>, and <b>Prophet</b> are commonly used to generate forecasts by modeling the trend, seasonality, and noise in the data."
                },
                {
                    "front": "What is exponential smoothing?",
                    "back": "<b>Exponential smoothing</b> is a time series forecasting method that assigns exponentially decreasing weights to past observations. The most common forms are: 1. <b>Simple Exponential Smoothing (SES)</b>: For series with no trend or seasonality. 2. <b>Holt’s Linear Trend Model</b>: For series with a trend but no seasonality. 3. <b>Holt-Winters Exponential Smoothing</b>: For series with both trend and seasonality."
                },
                {
                    "front": "When should you use ARIMA vs Exponential Smoothing for forecasting?",
                    "back": "- <b>ARIMA</b> is preferred for non-seasonal data that requires differencing to achieve stationarity and for data with autocorrelated residuals. - <b>Exponential Smoothing</b> (especially Holt-Winters) is more suited to data with a clear trend and seasonal components that are not autocorrelated. The choice depends on the characteristics of the time series and the goal of the forecasting."
                }
            ]
        },
        {
            "name": "Evaluation Metrics",
            "cards": [
                {
                    "front": "What is Mean Absolute Error (MAE)?",
                    "back": "<b>Mean Absolute Error (MAE)</b> is the average of the absolute differences between forecasted and actual values. It gives a linear measure of the magnitude of the errors, without considering their direction. The formula is: \\[ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y}_i | \\] where \\(y_i\\) are the actual values and \\(\\hat{y}_i\\) are the forecasted values."
                },
                {
                    "front": "What is Root Mean Squared Error (RMSE)?",
                    "back": "<b>Root Mean Squared Error (RMSE)</b> is the square root of the average squared differences between forecasted and actual values. RMSE gives more weight to larger errors, making it sensitive to outliers. The formula is: \\[ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\]"
                },
                {
                    "front": "What is Mean Absolute Percentage Error (MAPE)?",
                    "back": "<b>Mean Absolute Percentage Error (MAPE)</b> expresses the accuracy of a forecast as a percentage, by taking the absolute difference between actual and forecasted values relative to the actual values. The formula is: \\[ \\text{MAPE} = \\frac{100}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\] MAPE is useful when comparing forecasting errors across different time series."
                },
                {
                    "front": "How do you choose the best model for time series forecasting?",
                    "back": "The best model for time series forecasting is chosen based on several criteria, including: 1. <b>Low forecasting error</b>: Measured using metrics like MAE, RMSE, or MAPE. 2. <b>Fit to the data</b>: Evaluating how well the model captures the trend, seasonality, and residual components. 3. <b>Simplicity</b>: A simpler model with good performance may be preferred over a more complex model. 4. <b>Domain knowledge</b>: Understanding the context and characteristics of the data helps in choosing the right model (e.g., seasonal patterns)."
                }
            ]
        }
    ]
}